{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SSNE Miniproject 4\n",
    "### 318703 Tomasz Owienko\n",
    "### 318718 Anna Schäfer\n",
    "### Grupa piątek"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e11a7bd6121478"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-12T17:28:29.914492469Z",
     "start_time": "2024-05-12T17:28:27.232363223Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, Callable\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.utilities.types import TRAIN_DATALOADERS, EVAL_DATALOADERS\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n"
     ]
    },
    {
     "data": {
      "text/plain": "123"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 123\n",
    "pl.seed_everything(RANDOM_SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T17:28:29.923109303Z",
     "start_time": "2024-05-12T17:28:29.916423687Z"
    }
   },
   "id": "77b016a920782844",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.set_float32_matmul_precision('medium')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T17:28:29.965054661Z",
     "start_time": "2024-05-12T17:28:29.925109230Z"
    }
   },
   "id": "1d9a0540a7f6c891",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class ImagesDataModule(pl.LightningDataModule):\n",
    "    class FastDataset(Dataset):\n",
    "        def __init__(self, data, labels, num_classes):\n",
    "            self.dataset = data\n",
    "            self.labels = labels\n",
    "            self.number_classes = num_classes\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dataset)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return self.dataset[index], self.labels[index]\n",
    "\n",
    "    def __init__(self, path: str, transform: Callable[[Any], torch.Tensor], *, val_fraction: float,\n",
    "                 test_fraction: float, in_memory=False):\n",
    "        super().__init__()\n",
    "        assert 0 <= val_fraction + test_fraction <= 1\n",
    "        assert val_fraction * test_fraction >= 0\n",
    "\n",
    "        self.image_folder = ImageFolder(path, transform=transform)\n",
    "        self.dataset: ImagesDataModule.FastDataset | None = None\n",
    "        self._val_fraction = val_fraction\n",
    "        self._test_fraction = test_fraction\n",
    "        self._in_memory = in_memory\n",
    "\n",
    "        self._train = self._val = self._test = None\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        if self._in_memory:\n",
    "            loader = DataLoader(self.image_folder, batch_size=len(self.image_folder))\n",
    "            data = next(iter(loader))\n",
    "            dataset = ImagesDataModule.FastDataset(data[0], data[1], num_classes=len(self.image_folder.classes))\n",
    "        else:\n",
    "            dataset = self.image_folder\n",
    "\n",
    "        val_size = int(len(dataset) * self._val_fraction)\n",
    "        test_size = int(len(dataset) * self._test_fraction)\n",
    "        train_size = len(dataset) - val_size - test_size\n",
    "\n",
    "        self._train, self._val, self._test = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(self._train, batch_size=512, shuffle=True, num_workers=12 if not self._in_memory else 0,\n",
    "                          pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(self._val, batch_size=512, shuffle=False, num_workers=12 if not self._in_memory else 0,\n",
    "                          pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(self._test, batch_size=64, shuffle=False, num_workers=8 if not self._in_memory else 0,\n",
    "                          pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T17:28:29.988673492Z",
     "start_time": "2024-05-12T17:28:29.939704191Z"
    }
   },
   "id": "7b994e620275aa56"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# region unet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SiLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 128))\n",
    "        self.down1 = (Down(128, 256))\n",
    "        self.down2 = (Down(256, 512))\n",
    "        self.down3 = (Down(512, 1024))\n",
    "        self.down4 = (Down(1024, 2048))\n",
    "        self.up1 = (Up(2048, 1024))\n",
    "        self.up2 = (Up(1024, 512))\n",
    "        self.up3 = (Up(512, 256))\n",
    "        self.up4 = (Up(256, 128))\n",
    "        self.outc = (OutConv(128, n_channels))\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return x\n",
    "\n",
    "# endregion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T17:28:29.988840097Z",
     "start_time": "2024-05-12T17:28:29.986446430Z"
    }
   },
   "id": "6912dc3083ed8d72"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# region pl-module\n",
    "\n",
    "class DiffusionModel(pl.LightningModule):\n",
    "    def __init__(self, unet: nn.Module, betas_min, betas_max, n_steps, *, device=device):\n",
    "        super().__init__()\n",
    "        self._device = device\n",
    "        self.unet = unet\n",
    "        self._frechet = FrechetInceptionDistance(normalize=True).to(device)\n",
    "        self._loss = torch.nn.MSELoss()\n",
    "\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "        self.beta_t = ((betas_max - betas_min) * torch.arange(0, n_steps + 1,\n",
    "                                                              dtype=torch.float32) / n_steps + betas_min).to(device)\n",
    "        self.sqrt_beta_t = (torch.sqrt(self.beta_t)).to(device)\n",
    "        self.alpha_t = (1 - self.beta_t).to(device)\n",
    "        self.log_alpha_t = torch.log(self.alpha_t).to(device)\n",
    "        self.alphabar_t = torch.cumsum(self.log_alpha_t, dim=0).exp().to(device)\n",
    "\n",
    "        self.sqrtab = torch.sqrt(self.alphabar_t).to(device)\n",
    "        self.oneover_sqrta = (1 / torch.sqrt(self.alpha_t)).to(device)\n",
    "\n",
    "        self.sqrtmab = torch.sqrt(1 - self.alphabar_t).to(device)\n",
    "        self.mab_over_sqrtmab = ((1 - self.alpha_t) / self.sqrtmab).to(device)\n",
    "\n",
    "    def forward(self, x) -> Any:\n",
    "        timestep = torch.randint(1, self.n_steps, (x.shape[0],)).to(self.device)\n",
    "        noise = torch.randn_like(x)\n",
    "\n",
    "        x_noisy = (\n",
    "                self.sqrtab[timestep, None, None, None] * x\n",
    "                + self.sqrtmab[timestep, None, None, None] * noise\n",
    "        )\n",
    "\n",
    "        noise_pred = self.unet(x_noisy, timestep / self.n_steps)\n",
    "\n",
    "        return self._loss(noise, noise_pred)\n",
    "\n",
    "    def generate(self, n_images: int, size) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn(n_images, *size).to(self.device)\n",
    "\n",
    "            for i in range(self.n_steps, 0, -1):\n",
    "                z = torch.randn(n_images, *size).to(self.device) if i > 1 else 0\n",
    "                eps = self.unet(x, i / self.n_steps)\n",
    "                x = (\n",
    "                        self.oneover_sqrta[i] * (x - eps * self.mab_over_sqrtmab[i])\n",
    "                        + self.sqrt_beta_t[i] * z\n",
    "                )\n",
    "\n",
    "            x = (x + 1) / 2\n",
    "            return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        loss = self.forward(x)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimizer\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        with torch.no_grad():\n",
    "            preds = self.generate(64, (3, 32, 32))\n",
    "            grid = torchvision.utils.make_grid(preds, nrow=4)\n",
    "            torchvision.utils.save_image(grid, f\"./generated/sample_{self.current_epoch}.png\")\n",
    "            gridn = torchvision.utils.make_grid(preds)\n",
    "            torchvision.utils.save_image(gridn, f\"./generated/sample_{self.current_epoch}_n.png\")\n",
    "        # \n",
    "        #     images, _ = batch\n",
    "        #     distance = self.calc_frechet(images=images)\n",
    "        #     self.log(f\"val_frechet\", distance)\n",
    "        #     return distance\n",
    "\n",
    "    def calc_frechet(self, images):\n",
    "        generated = self.generate(n_images=len(images), size=(3, 32, 32)).to(self._device)\n",
    "        self._frechet.update((images + 1) / 2, real=True)\n",
    "        self._frechet.update(generated, real=False)\n",
    "        return self._frechet.compute()\n",
    "\n",
    "# endregion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T17:28:29.988924099Z",
     "start_time": "2024-05-12T17:28:29.986535454Z"
    }
   },
   "id": "3ce18c0886b66520",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5,), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "dm = ImagesDataModule('data/trafic_32', transform, val_fraction=0.005, test_fraction=0.)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T17:28:32.873975360Z",
     "start_time": "2024-05-12T17:28:29.986585508Z"
    }
   },
   "id": "54ab308b81a9eb30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                     | Params\n",
      "------------------------------------------------------\n",
      "0 | unet     | UNet                     | 124 M \n",
      "1 | _frechet | FrechetInceptionDistance | 23.9 M\n",
      "2 | _loss    | MSELoss                  | 0     \n",
      "------------------------------------------------------\n",
      "124 M     Trainable params\n",
      "23.9 M    Non-trainable params\n",
      "147 M     Total params\n",
      "591.891   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d9a2742c8cb4ebb8bb43850925d74c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f087c986d0f44ab0be37378f94c68fd3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f68dda5793e14059a6a8c1eee297d132"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09a9baefd161481193471d28b409bcb8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c7170662d34491180dd75e092ae9a7b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CHECKPOINT: str | None = None\n",
    "\n",
    "if CHECKPOINT:\n",
    "    model = DiffusionModel.load_from_checkpoint(\n",
    "        CHECKPOINT,\n",
    "        unet=UNet(3),\n",
    "        betas_min=1e-4, betas_max=0.02, n_steps=1000\n",
    "    ).to(device)\n",
    "else:\n",
    "    model = DiffusionModel(UNet(3), betas_min=1e-4, betas_max=0.02, n_steps=1000).to(device)\n",
    "\n",
    "best_frechet_callback = ModelCheckpoint(\n",
    "    save_top_k=3,\n",
    "    monitor=\"val_frechet\",\n",
    "    mode=\"min\",\n",
    "    filename=\"checkpoint_best_frechet-{epoch:04d}-{train_loss:.5f}-{val_frechet:.4f}\",\n",
    ")\n",
    "\n",
    "last_epoch_callback = ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "    monitor=\"epoch\",\n",
    "    mode=\"max\",\n",
    "    filename=\"checkpoint_last-{epoch:04d}-{train_loss:.5f}\",\n",
    ")\n",
    "\n",
    "periodic_callback = ModelCheckpoint(\n",
    "    save_top_k=-1,\n",
    "    every_n_epochs=20,\n",
    "    filename=\"checkpoint_periodic-{epoch:04d}-{train_loss:.5f}\",\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=500,\n",
    "    callbacks=[\n",
    "        # best_frechet_callback,\n",
    "        last_epoch_callback,\n",
    "        periodic_callback\n",
    "    ],\n",
    "    check_val_every_n_epoch=1\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=dm, ckpt_path=CHECKPOINT)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-12T17:28:32.877826322Z"
    }
   },
   "id": "b7167a6f534aae75"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# NOTE: for some reason (spent 3h figuring out why), if training was resumed from a checkpoint, \n",
    "# the model has to be re-loaded before evaluation - in other case, results are essentially garbage\n",
    "\n",
    "LOGS_PATH = Path(\"lightning_logs\")\n",
    "CHECKPOINTS_PATH = max(LOGS_PATH.glob(\"./*\"), key=lambda x: int(x.name.split(\"_\")[-1])) / \"checkpoints\"\n",
    "print(f\"Using checkpoints from {CHECKPOINTS_PATH} ({len([f for f in CHECKPOINTS_PATH.glob('./*')])} checkpoints)\")\n",
    "\n",
    "# best_frechet_checkpoint = min((f for f in CHECKPOINTS_PATH.glob('./*') if not f.stem.startswith(\"checkpoint_last\")),  key=lambda x: float(x.stem.split('=')[-1]))\n",
    "last_epoch_checkpoint = max((f for f in CHECKPOINTS_PATH.glob('./*') if f.stem.startswith(\"checkpoint_last\")),\n",
    "                            key=lambda x: int(x.stem.split('-')[1].split('=')[-1]))\n",
    "# print(f\"Best Frechet: {best_frechet_checkpoint}\")\n",
    "print(f\"Last epoch: {last_epoch_checkpoint}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1d42ad40346f3ce5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "\n",
    "fig, axes = plt.subplots(1, 1)\n",
    "\n",
    "for path, name, ax in zip(\n",
    "        (\n",
    "                # best_frechet_checkpoint, \n",
    "                last_epoch_checkpoint,\n",
    "        ),\n",
    "        (\n",
    "                # \"Best Frechet\", \n",
    "                \"Last epoch\",\n",
    "        ),\n",
    "        [axes]\n",
    "):\n",
    "    m = DiffusionModel.load_from_checkpoint(path, unet=UNet(3), betas_min=1e-4, betas_max=0.02, n_steps=1000).to(device)\n",
    "\n",
    "    m.eval()\n",
    "    preds = m.generate(64, (3, 32, 32)).cpu()\n",
    "    ax.set_title(f\"{name}\\n{path}\")\n",
    "    ax.imshow((torchvision.utils.make_grid(preds).permute(1, 2, 0)))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c014ccb88bb4c65e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
