{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import RichProgressBar, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "from torch.optim import Adam\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from typing import Literal, Callable, Any\n",
    "import re\n",
    "from functools import partial\n",
    "\n",
    "from torch import Tensor\n",
    "from pytorch_lightning.utilities.types import TRAIN_DATALOADERS\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 123\n",
    "pl.seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location not palace excellent hotel booke dthe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>respite definitely not place stay looking ultr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stunning truly memorable spot right beach nusa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solid business hotel near embassy stayed hotel...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nice place make sure lock money warning money ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16387</th>\n",
       "      <td>great base explore new york stayed 4 nights en...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16388</th>\n",
       "      <td>wonderful advert paris wonderful introduction ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16389</th>\n",
       "      <td>ideal relaxing holdiay rachel jay green liverp...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16390</th>\n",
       "      <td>watch food, husband went resort 4 nights chris...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16391</th>\n",
       "      <td>fantastic hotel central barcelona family just ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16392 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rating\n",
       "0      location not palace excellent hotel booke dthe...       4\n",
       "1      respite definitely not place stay looking ultr...       3\n",
       "2      stunning truly memorable spot right beach nusa...       4\n",
       "3      solid business hotel near embassy stayed hotel...       3\n",
       "4      nice place make sure lock money warning money ...       3\n",
       "...                                                  ...     ...\n",
       "16387  great base explore new york stayed 4 nights en...       4\n",
       "16388  wonderful advert paris wonderful introduction ...       4\n",
       "16389  ideal relaxing holdiay rachel jay green liverp...       3\n",
       "16390  watch food, husband went resort 4 nights chris...       2\n",
       "16391  fantastic hotel central barcelona family just ...       4\n",
       "\n",
       "[16392 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train_data.csv\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Klasyfikacja na podstawie reprezentacji TFIDF\n",
    "\n",
    "Szybkie przeuczenie nawet po dodaniu regularyzacji i ważenia klas w funkcji straty, bardzo słabe wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        review\n",
       "rating        \n",
       "0         1137\n",
       "1         1434\n",
       "2         1747\n",
       "3         4831\n",
       "4         7243"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = df_train.groupby(\"rating\").count()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    df_train.review, df_train.rating, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFIDFClassifier(\n",
       "  (lin1): Linear(in_features=10000, out_features=4000, bias=True)\n",
       "  (act1): LeakyReLU(negative_slope=0.01)\n",
       "  (lin2): Linear(in_features=4000, out_features=1000, bias=True)\n",
       "  (act2): LeakyReLU(negative_slope=0.01)\n",
       "  (lin3): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (act3): LeakyReLU(negative_slope=0.01)\n",
       "  (lin4): Linear(in_features=500, out_features=50, bias=True)\n",
       "  (act4): LeakyReLU(negative_slope=0.01)\n",
       "  (lin5): Linear(in_features=50, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TFIDFClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TFIDFClassifier, self).__init__()\n",
    "        self.lin1 = nn.Linear(10000, 4000)\n",
    "        self.act1 = nn.LeakyReLU()\n",
    "        self.lin2 = nn.Linear(4000, 1000)\n",
    "        self.act2 = nn.LeakyReLU()\n",
    "        self.lin3 = nn.Linear(1000, 500)\n",
    "        self.act3 = nn.LeakyReLU()\n",
    "        self.lin4 = nn.Linear(500, 50)\n",
    "        self.act4 = nn.LeakyReLU()\n",
    "        self.lin5 = nn.Linear(50, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.lin4(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.lin5(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "tfidf_model = TFIDFClassifier().to(device)\n",
    "tfidf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_train = CountVectorizer()\n",
    "x_vectorized_train = count_vectorizer_train.fit_transform(x_train.values)\n",
    "tfidf_transformer_train = TfidfTransformer()\n",
    "x_transformed_train = tfidf_transformer_train.fit_transform(x_vectorized_train)[\n",
    "    :, :10000\n",
    "]\n",
    "\n",
    "count_vectorizer_val = CountVectorizer()\n",
    "x_vectorized_val = count_vectorizer_val.fit_transform(x_val.values)\n",
    "tfidf_transformer_val = TfidfTransformer()\n",
    "x_transformed_val = tfidf_transformer_val.fit_transform(x_vectorized_val)[:, :10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(\n",
    "    torch.from_numpy(x_transformed_train.todense()).to(torch.float),\n",
    "    torch.tensor(y_train.values),\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    torch.from_numpy(x_transformed_val.todense()).to(torch.float),\n",
    "    torch.tensor(y_val.values),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()  # *********#\n",
    "    for imgs, labels in data_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        output = model(imgs)\n",
    "        pred = output.max(1, keepdim=True)[1]  # get the index of the max logit\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += imgs.shape[0]\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 1.61 val_acc: 0.107\n",
      "Epoch 1 loss 1.61 val_acc: 0.107\n",
      "Epoch 2 loss 1.61 val_acc: 0.441\n",
      "Epoch 3 loss 1.61 val_acc: 0.441\n",
      "Epoch 4 loss 1.61 val_acc: 0.441\n",
      "Epoch 5 loss 1.61 val_acc: 0.441\n",
      "Epoch 6 loss 1.61 val_acc: 0.293\n",
      "Epoch 7 loss 1.61 val_acc: 0.441\n",
      "Epoch 8 loss 1.61 val_acc: 0.441\n",
      "Epoch 9 loss 1.61 val_acc: 0.441\n",
      "Final Training Accuracy: 0.44217218137254904\n",
      "Final Validation Accuracy: 0.44129307715767\n",
      "Max Validation Accuracy: 0.44129307715767\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(\n",
    "    weight=torch.tensor(1 / class_counts.values).squeeze().to(torch.float).to(device)\n",
    ")\n",
    "optimizer = Adam(tfidf_model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "\n",
    "iters = []\n",
    "losses = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "for n in range(10):\n",
    "    epoch_losses = []\n",
    "    for x, labels in iter(train_loader):\n",
    "        x, labels = x.to(device), labels.to(device)\n",
    "        tfidf_model.train()\n",
    "        out = tfidf_model(x).squeeze()\n",
    "\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        epoch_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    loss_mean = np.array(epoch_losses).mean()\n",
    "    iters.append(n)\n",
    "    losses.append(loss_mean)\n",
    "    test_acc = get_accuracy(tfidf_model, val_loader)\n",
    "    print(f\"Epoch {n} loss {loss_mean:.3} val_acc: {test_acc:.3}\")\n",
    "    train_acc.append(\n",
    "        get_accuracy(tfidf_model, train_loader)\n",
    "    )  # compute training accuracy\n",
    "    val_acc.append(test_acc)  # compute validation accuracy\n",
    "\n",
    "\n",
    "print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
    "print(\"Max Validation Accuracy: {}\".format(max(val_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Klasyfikacja za pomocą modelu LLM\n",
    "\n",
    "TODO wnioski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Klasyfikacja za pomocą dostrojonego modelu BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Szybkie przeuczenie, ale na ogół dobre wyniki\n",
    "\n",
    "Testowane modyfikacje:\n",
    "- Mniejszy model - przeuczenie następuje wolniej, ale nie osiąga lepszych wyników\n",
    "- Regularyzacja L2 - nie jest w stanie zapobiec przeuczeniu\n",
    "- Regresja zamiast klasyfikacji - dużo wolniejsze przeuczenie, wyniki podobne bądź nieco gorsze\n",
    "- Model RoBERTa - podobne wyniki\n",
    "- Preferencje dla klas mniejszościowych w `DataLoader` - początkowo lepszy balans accuracy między klasami, ale w późnych epokach zawsze dąży rozkładu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_t = str | bytes | os.PathLike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = Path(\"./data/train_data.csv\")\n",
    "NLTK_DIR = Path(\"./nltk\")\n",
    "MODEL_DIR = Path(\"./models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzuElEQVR4nO3df1RU953/8dcoP1QKNwKBkQ1GklDUovmBFqE/NEVRU0Kz7ta2pKxtrJoYNTR63Fh3N6TbQGs3aCuJUWvVii7taWI23bZUTCKp9TeRjRhD0xMTMGVEmnEAQ0Hxfv9ovd+M4A9GZGa8z8c59xzvve+583n7yamvfubeGYdpmqYAAABsbIC/BwAAAOBvBCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7If4eQLA4f/68/vznPysyMlIOh8PfwwEAAFfBNE21trYqISFBAwZceh2IQHSV/vznPysxMdHfwwAAAD5oaGjQLbfccsnzBKKrFBkZKelvf6FRUVF+Hg0AALgaLS0tSkxMtP4dvxQC0VW68DFZVFQUgQgAgCBzpdtduKkaAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYXoi/BwAAAIJbfX29mpubr+kasbGxGj58eB+NqPcIRAAAwGf19fUaOXKU2ts/uqbrDB48RG+/fcxvoYhABAAAfNbc3Kz29o+U/tCTiho2wqdrtDS+p/0/fUrNzc0EIgAAELyiho1Q9PAUfw/DZ9xUDQAAbI9ABAAAbI9ABAAAbI9ABAAAbI9ABAAAbM+vgWjEiBFyOBzdtkcffVSSZJqmCgsLlZCQoMGDB2vSpEk6evSo1zU6Ojq0cOFCxcbGKiIiQrm5uTpx4oRXjdvtVn5+vgzDkGEYys/P1+nTp/urTQAAEOD8GogOHjyoxsZGa6usrJQkffnLX5YkrVixQiUlJSotLdXBgwfldDo1ZcoUtba2WtcoKCjQ9u3bVV5ert27d6utrU05OTnq6uqyavLy8lRTU6OKigpVVFSopqZG+fn5/dssAAAIWH79HqKbb77Za//73/++br/9dk2cOFGmaWrVqlVavny5ZsyYIUnavHmz4uPjtW3bNs2bN08ej0cbNmzQli1bNHnyZElSWVmZEhMTtXPnTk2dOlXHjh1TRUWF9u3bp/T0dEnS+vXrlZGRobq6OqWkBO93JgAAgL4RMPcQdXZ2qqysTA899JAcDoeOHz8ul8ul7OxsqyY8PFwTJ07Unj17JEnV1dU6e/asV01CQoJSU1Otmr1798owDCsMSdKECRNkGIZV05OOjg61tLR4bQAA4MYUMIHopZde0unTp/WNb3xDkuRyuSRJ8fHxXnXx8fHWOZfLpbCwMA0dOvSyNXFxcd3eLy4uzqrpSXFxsXXPkWEYSkxM9Lk3AAAQ2AImEG3YsEHTp09XQkKC13GHw+G1b5pmt2MXu7imp/orXWfZsmXyeDzW1tDQcDVtAACAIBQQgej999/Xzp079a1vfcs65nQ6JanbKk5TU5O1auR0OtXZ2Sm3233ZmpMnT3Z7z1OnTnVbffq48PBwRUVFeW0AAODGFBCBaOPGjYqLi9MXv/hF61hSUpKcTqf15Jn0t/uMqqqqlJmZKUlKS0tTaGioV01jY6Nqa2utmoyMDHk8Hh04cMCq2b9/vzwej1UDAADsze+/dn/+/Hlt3LhRs2bNUkjI/x+Ow+FQQUGBioqKlJycrOTkZBUVFWnIkCHKy8uTJBmGodmzZ2vx4sWKiYlRdHS0lixZojFjxlhPnY0aNUrTpk3TnDlztHbtWknS3LlzlZOTwxNmAABAUgAEop07d6q+vl4PPfRQt3NLly5Ve3u75s+fL7fbrfT0dO3YsUORkZFWzcqVKxUSEqKZM2eqvb1dWVlZ2rRpkwYOHGjVbN26VYsWLbKeRsvNzVVpaen1bw4AAAQFh2mapr8HEQxaWlpkGIY8Hg/3EwEA8HdvvPGG0tLSNGX5RkUP9+2Tlw/r61T59DdVXV2te+65p0/Hd7X/fgfEPUQAAAD+RCACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC25/dA9MEHH+jrX/+6YmJiNGTIEN11112qrq62zpumqcLCQiUkJGjw4MGaNGmSjh496nWNjo4OLVy4ULGxsYqIiFBubq5OnDjhVeN2u5Wfny/DMGQYhvLz83X69On+aBEAAAQ4vwYit9utz3zmMwoNDdVvf/tbvfXWW3rmmWd00003WTUrVqxQSUmJSktLdfDgQTmdTk2ZMkWtra1WTUFBgbZv367y8nLt3r1bbW1tysnJUVdXl1WTl5enmpoaVVRUqKKiQjU1NcrPz+/PdgEAQIAK8eeb/+AHP1BiYqI2btxoHRsxYoT1Z9M0tWrVKi1fvlwzZsyQJG3evFnx8fHatm2b5s2bJ4/How0bNmjLli2aPHmyJKmsrEyJiYnauXOnpk6dqmPHjqmiokL79u1Tenq6JGn9+vXKyMhQXV2dUlJSuo2to6NDHR0d1n5LS8v1+CsAAAABwK8rRC+//LLGjRunL3/5y4qLi9Pdd9+t9evXW+ePHz8ul8ul7Oxs61h4eLgmTpyoPXv2SJKqq6t19uxZr5qEhASlpqZaNXv37pVhGFYYkqQJEybIMAyr5mLFxcXWx2uGYSgxMbFPewcAAIHDr4Ho3Xff1Zo1a5ScnKzf/e53evjhh7Vo0SL97Gc/kyS5XC5JUnx8vNfr4uPjrXMul0thYWEaOnToZWvi4uK6vX9cXJxVc7Fly5bJ4/FYW0NDw7U1CwAAApZfPzI7f/68xo0bp6KiIknS3XffraNHj2rNmjX6l3/5F6vO4XB4vc40zW7HLnZxTU/1l7tOeHi4wsPDr7oXAAAQvPy6QjRs2DCNHj3a69ioUaNUX18vSXI6nZLUbRWnqanJWjVyOp3q7OyU2+2+bM3Jkye7vf+pU6e6rT4BAAD78Wsg+sxnPqO6ujqvY3/84x916623SpKSkpLkdDpVWVlpne/s7FRVVZUyMzMlSWlpaQoNDfWqaWxsVG1trVWTkZEhj8ejAwcOWDX79++Xx+OxagAAgH359SOzb3/728rMzFRRUZFmzpypAwcOaN26dVq3bp2kv33MVVBQoKKiIiUnJys5OVlFRUUaMmSI8vLyJEmGYWj27NlavHixYmJiFB0drSVLlmjMmDHWU2ejRo3StGnTNGfOHK1du1aSNHfuXOXk5PT4hBkAALAXvwai8ePHa/v27Vq2bJm++93vKikpSatWrdKDDz5o1SxdulTt7e2aP3++3G630tPTtWPHDkVGRlo1K1euVEhIiGbOnKn29nZlZWVp06ZNGjhwoFWzdetWLVq0yHoaLTc3V6Wlpf3XLAAACFgO0zRNfw8iGLS0tMgwDHk8HkVFRfl7OAAABIQ33nhDaWlpmrJ8o6KH+/apy4f1dap8+puqrq7WPffc06fju9p/v/3+0x0AAAD+RiACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC259dAVFhYKIfD4bU5nU7rvGmaKiwsVEJCggYPHqxJkybp6NGjXtfo6OjQwoULFRsbq4iICOXm5urEiRNeNW63W/n5+TIMQ4ZhKD8/X6dPn+6PFgEAQBDw+wrRpz71KTU2NlrbkSNHrHMrVqxQSUmJSktLdfDgQTmdTk2ZMkWtra1WTUFBgbZv367y8nLt3r1bbW1tysnJUVdXl1WTl5enmpoaVVRUqKKiQjU1NcrPz+/XPgEAQOAK8fsAQkK8VoUuME1Tq1at0vLlyzVjxgxJ0ubNmxUfH69t27Zp3rx58ng82rBhg7Zs2aLJkydLksrKypSYmKidO3dq6tSpOnbsmCoqKrRv3z6lp6dLktavX6+MjAzV1dUpJSWl/5oFAAABye8rRO+8844SEhKUlJSkr371q3r33XclScePH5fL5VJ2drZVGx4erokTJ2rPnj2SpOrqap09e9arJiEhQampqVbN3r17ZRiGFYYkacKECTIMw6rpSUdHh1paWrw2AABwY/JrIEpPT9fPfvYz/e53v9P69evlcrmUmZmpv/zlL3K5XJKk+Ph4r9fEx8db51wul8LCwjR06NDL1sTFxXV777i4OKumJ8XFxdY9R4ZhKDEx8Zp6BQAAgcuvgWj69On6p3/6J40ZM0aTJ0/Wr3/9a0l/+2jsAofD4fUa0zS7HbvYxTU91V/pOsuWLZPH47G2hoaGq+oJAAAEH79/ZPZxERERGjNmjN555x3rvqKLV3GampqsVSOn06nOzk653e7L1pw8ebLbe506darb6tPHhYeHKyoqymsDAAA3poAKRB0dHTp27JiGDRumpKQkOZ1OVVZWWuc7OztVVVWlzMxMSVJaWppCQ0O9ahobG1VbW2vVZGRkyOPx6MCBA1bN/v375fF4rBoAAGBvfn3KbMmSJbr//vs1fPhwNTU16Xvf+55aWlo0a9YsORwOFRQUqKioSMnJyUpOTlZRUZGGDBmivLw8SZJhGJo9e7YWL16smJgYRUdHa8mSJdZHcJI0atQoTZs2TXPmzNHatWslSXPnzlVOTg5PmAEAAEl+DkQnTpzQ1772NTU3N+vmm2/WhAkTtG/fPt16662SpKVLl6q9vV3z58+X2+1Wenq6duzYocjISOsaK1euVEhIiGbOnKn29nZlZWVp06ZNGjhwoFWzdetWLVq0yHoaLTc3V6Wlpf3bLAAACFgO0zRNfw8iGLS0tMgwDHk8Hu4nAgDg79544w2lpaVpyvKNih7u2ycvH9bXqfLpb6q6ulr33HNPn47vav/99vsXMwIAcCX19fVqbm6+pmvExsZq+PDhfTQi3GgIRACAgFZfX6+RI0epvf2ja7rO4MFD9PbbxwhF6BGBCAAQ0Jqbm9Xe/pHSH3pSUcNG+HSNlsb3tP+nT6m5uZlAhB4RiAAAQSFq2Aif71EBriSgvocIAADAHwhEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9nwKRLfddpv+8pe/dDt++vRp3Xbbbdc8KAAAgP7kUyB677331NXV1e14R0eHPvjgg2seFAAAQH8K6U3xyy+/bP35d7/7nQzDsPa7urr0yiuvaMSIEX02OAAAgP7Qq0D0wAMPSJIcDodmzZrldS40NFQjRozQM88802eDAwAA6A+9CkTnz5+XJCUlJengwYOKjY29LoMCAADoTz7dQ3T8+PE+D0PFxcVyOBwqKCiwjpmmqcLCQiUkJGjw4MGaNGmSjh496vW6jo4OLVy4ULGxsYqIiFBubq5OnDjhVeN2u5Wfny/DMGQYhvLz83X69Ok+HT8AAAhevVoh+rhXXnlFr7zyipqamqyVowt++tOf9upaBw8e1Lp16zR27Fiv4ytWrFBJSYk2bdqkT37yk/re976nKVOmqK6uTpGRkZKkgoIC/epXv1J5ebliYmK0ePFi5eTkqLq6WgMHDpQk5eXl6cSJE6qoqJAkzZ07V/n5+frVr37la/sAAOAG4tMK0VNPPaXs7Gy98soram5ultvt9tp6o62tTQ8++KDWr1+voUOHWsdN09SqVau0fPlyzZgxQ6mpqdq8ebM++ugjbdu2TZLk8Xi0YcMGPfPMM5o8ebLuvvtulZWV6ciRI9q5c6ck6dixY6qoqNBPfvITZWRkKCMjQ+vXr9f//u//qq6u7pLj6ujoUEtLi9cGAABuTD4Foueff16bNm3S/v379dJLL2n79u1eW288+uij+uIXv6jJkyd7HT9+/LhcLpeys7OtY+Hh4Zo4caL27NkjSaqurtbZs2e9ahISEpSammrV7N27V4ZhKD093aqZMGGCDMOwanpSXFxsfcRmGIYSExN71RcAAAgePgWizs5OZWZmXvObl5eX64033lBxcXG3cy6XS5IUHx/vdTw+Pt4653K5FBYW5rWy1FNNXFxct+vHxcVZNT1ZtmyZPB6PtTU0NPSuOQAAEDR8CkTf+ta3rI+tfNXQ0KDHHntMZWVlGjRo0CXrHA6H175pmt2OXezimp7qr3Sd8PBwRUVFeW0AAODG5NNN1X/961+1bt067dy5U2PHjlVoaKjX+ZKSkiteo7q6Wk1NTUpLS7OOdXV16fXXX1dpaal1f4/L5dKwYcOsmqamJmvVyOl0qrOzU26322uVqKmpyVrBcjqdOnnyZLf3P3XqVLfVJwAAYE8+rRC9+eabuuuuuzRgwADV1tbq8OHD1lZTU3NV18jKytKRI0dUU1NjbePGjdODDz6ompoa3XbbbXI6naqsrLRe09nZqaqqKivspKWlKTQ01KumsbFRtbW1Vk1GRoY8Ho8OHDhg1ezfv18ej6dPPvYDAADBz6cVotdee+2a3zgyMlKpqalexyIiIhQTE2MdLygoUFFRkZKTk5WcnKyioiINGTJEeXl5kiTDMDR79mwtXrxYMTExio6O1pIlSzRmzBjrJu1Ro0Zp2rRpmjNnjtauXSvpb4/d5+TkKCUl5Zr7AAAAwc/n7yHqD0uXLlV7e7vmz58vt9ut9PR07dixw/oOIklauXKlQkJCNHPmTLW3tysrK0ubNm2yvoNIkrZu3apFixZZT6Pl5uaqtLS03/sBAACByadAdO+99172huRXX33Vp8Hs2rXLa9/hcKiwsFCFhYWXfM2gQYO0evVqrV69+pI10dHRKisr82lMAADgxudTILrrrru89s+ePauamhrV1tZ2+9FXAACAQOdTIFq5cmWPxwsLC9XW1nZNAwIAAOhvPj1ldilf//rXe/07ZgAAAP7Wp4Fo7969l/2SRQAAgEDk00dmM2bM8No3TVONjY06dOiQ/v3f/71PBgYAANBffApEhmF47Q8YMEApKSn67ne/6/VDqwAAAMHAp0C0cePGvh4HAACA31zTFzNWV1fr2LFjcjgcGj16tO6+++6+GhcAAEC/8SkQNTU16atf/ap27dqlm266SaZpyuPx6N5771V5ebluvvnmvh4nAADAdePTU2YLFy5US0uLjh49qg8//FBut1u1tbVqaWnRokWL+nqMAAAA15VPK0QVFRXauXOnRo0aZR0bPXq0nn32WW6qBgAAQcenFaLz588rNDS02/HQ0FCdP3/+mgcFAADQn3wKRF/4whf02GOP6c9//rN17IMPPtC3v/1tZWVl9dngAAAA+oNPgai0tFStra0aMWKEbr/9dt1xxx1KSkpSa2vrZX91HgAAIBD5dA9RYmKi3njjDVVWVurtt9+WaZoaPXq0Jk+e3NfjAwAAuO56tUL06quvavTo0WppaZEkTZkyRQsXLtSiRYs0fvx4fepTn9Lvf//76zJQAACA66VXgWjVqlWaM2eOoqKiup0zDEPz5s1TSUlJnw0OAACgP/QqEP3f//2fpk2bdsnz2dnZqq6uvuZBAQAA9KdeBaKTJ0/2+Lj9BSEhITp16tQ1DwoAAKA/9SoQ/cM//IOOHDlyyfNvvvmmhg0bds2DAgAA6E+9CkT33Xef/uM//kN//etfu51rb2/Xk08+qZycnD4bHAAAQH/o1WP3//Zv/6YXX3xRn/zkJ7VgwQKlpKTI4XDo2LFjevbZZ9XV1aXly5dfr7ECAABcF70KRPHx8dqzZ48eeeQRLVu2TKZpSpIcDoemTp2q5557TvHx8ddloAAAANdLr7+Y8dZbb9VvfvMbud1u/elPf5JpmkpOTtbQoUOvx/gAAACuO5++qVqShg4dqvHjx/flWAAAAPzCp98yAwAAuJEQiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO35NRCtWbNGY8eOVVRUlKKiopSRkaHf/va31nnTNFVYWKiEhAQNHjxYkyZN0tGjR72u0dHRoYULFyo2NlYRERHKzc3ViRMnvGrcbrfy8/NlGIYMw1B+fr5Onz7dHy0CAIAg4NdAdMstt+j73/++Dh06pEOHDukLX/iCvvSlL1mhZ8WKFSopKVFpaakOHjwop9OpKVOmqLW11bpGQUGBtm/frvLycu3evVttbW3KyclRV1eXVZOXl6eamhpVVFSooqJCNTU1ys/P7/d+AQBAYArx55vff//9XvtPP/201qxZo3379mn06NFatWqVli9frhkzZkiSNm/erPj4eG3btk3z5s2Tx+PRhg0btGXLFk2ePFmSVFZWpsTERO3cuVNTp07VsWPHVFFRoX379ik9PV2StH79emVkZKiurk4pKSn92zQAAAg4AXMPUVdXl8rLy3XmzBllZGTo+PHjcrlcys7OtmrCw8M1ceJE7dmzR5JUXV2ts2fPetUkJCQoNTXVqtm7d68Mw7DCkCRNmDBBhmFYNT3p6OhQS0uL1wYAAG5Mfg9ER44c0Sc+8QmFh4fr4Ycf1vbt2zV69Gi5XC5JUnx8vFd9fHy8dc7lciksLExDhw69bE1cXFy3942Li7NqelJcXGzdc2QYhhITE6+pTwAAELj8HohSUlJUU1Ojffv26ZFHHtGsWbP01ltvWecdDodXvWma3Y5d7OKanuqvdJ1ly5bJ4/FYW0NDw9W2BAAAgozfA1FYWJjuuOMOjRs3TsXFxbrzzjv1ox/9SE6nU5K6reI0NTVZq0ZOp1OdnZ1yu92XrTl58mS39z116lS31aePCw8Pt55+u7ABAIAbk98D0cVM01RHR4eSkpLkdDpVWVlpnevs7FRVVZUyMzMlSWlpaQoNDfWqaWxsVG1trVWTkZEhj8ejAwcOWDX79++Xx+OxagAAgL359Smz73znO5o+fboSExPV2tqq8vJy7dq1SxUVFXI4HCooKFBRUZGSk5OVnJysoqIiDRkyRHl5eZIkwzA0e/ZsLV68WDExMYqOjtaSJUs0ZswY66mzUaNGadq0aZozZ47Wrl0rSZo7d65ycnJ4wgwAAEjycyA6efKk8vPz1djYKMMwNHbsWFVUVGjKlCmSpKVLl6q9vV3z58+X2+1Wenq6duzYocjISOsaK1euVEhIiGbOnKn29nZlZWVp06ZNGjhwoFWzdetWLVq0yHoaLTc3V6Wlpf3bLAAACFh+DUQbNmy47HmHw6HCwkIVFhZesmbQoEFavXq1Vq9efcma6OholZWV+TpMAABwgwu4e4gAAAD6G4EIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYnl8DUXFxscaPH6/IyEjFxcXpgQceUF1dnVeNaZoqLCxUQkKCBg8erEmTJuno0aNeNR0dHVq4cKFiY2MVERGh3NxcnThxwqvG7XYrPz9fhmHIMAzl5+fr9OnT17tFAAAQBPwaiKqqqvToo49q3759qqys1Llz55Sdna0zZ85YNStWrFBJSYlKS0t18OBBOZ1OTZkyRa2trVZNQUGBtm/frvLycu3evVttbW3KyclRV1eXVZOXl6eamhpVVFSooqJCNTU1ys/P79d+AQBAYArx55tXVFR47W/cuFFxcXGqrq7W5z//eZmmqVWrVmn58uWaMWOGJGnz5s2Kj4/Xtm3bNG/ePHk8Hm3YsEFbtmzR5MmTJUllZWVKTEzUzp07NXXqVB07dkwVFRXat2+f0tPTJUnr169XRkaG6urqlJKS0r+NAwCAgBJQ9xB5PB5JUnR0tCTp+PHjcrlcys7OtmrCw8M1ceJE7dmzR5JUXV2ts2fPetUkJCQoNTXVqtm7d68Mw7DCkCRNmDBBhmFYNRfr6OhQS0uL1wYAAG5MAROITNPU448/rs9+9rNKTU2VJLlcLklSfHy8V218fLx1zuVyKSwsTEOHDr1sTVxcXLf3jIuLs2ouVlxcbN1vZBiGEhMTr61BAAAQsAImEC1YsEBvvvmm/vu//7vbOYfD4bVvmma3Yxe7uKan+stdZ9myZfJ4PNbW0NBwNW0AAIAgFBCBaOHChXr55Zf12muv6ZZbbrGOO51OSeq2itPU1GStGjmdTnV2dsrtdl+25uTJk93e99SpU91Wny4IDw9XVFSU1wYAAG5Mfg1EpmlqwYIFevHFF/Xqq68qKSnJ63xSUpKcTqcqKyutY52dnaqqqlJmZqYkKS0tTaGhoV41jY2Nqq2ttWoyMjLk8Xh04MABq2b//v3yeDxWDQAAsC+/PmX26KOPatu2bfqf//kfRUZGWitBhmFo8ODBcjgcKigoUFFRkZKTk5WcnKyioiINGTJEeXl5Vu3s2bO1ePFixcTEKDo6WkuWLNGYMWOsp85GjRqladOmac6cOVq7dq0kae7cucrJyeEJMwAA4N9AtGbNGknSpEmTvI5v3LhR3/jGNyRJS5cuVXt7u+bPny+326309HTt2LFDkZGRVv3KlSsVEhKimTNnqr29XVlZWdq0aZMGDhxo1WzdulWLFi2ynkbLzc1VaWnp9W0QAAAEBb8GItM0r1jjcDhUWFiowsLCS9YMGjRIq1ev1urVqy9ZEx0drbKyMl+GCQAAbnABcVM1AACAPxGIAACA7RGIAACA7RGIAACA7fn1pmoACBT19fVqbm6+pmvExsZq+PDhfTQiAP2JQATA9urr6zVy5Ci1t390TdcZPHiI3n77GKEICEIEIgC219zcrPb2j5T+0JOKGjbCp2u0NL6n/T99Ss3NzQQiIAgRiADg76KGjVD0cL69HrAjbqoGAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2x2+ZAVdQX1+v5ubma75ObGwsP/oJAAGKQARcRn19vUaOHKX29o+u+VqDBw/R228fIxQBQAAiEAGX0dzcrPb2j5T+0JOKGjbC5+u0NL6n/T99Ss3NzQQiAAhABCLgKkQNG6Ho4Sn+HgYA4DrhpmoAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7/HRHAODX1AEA8C8CkZ/xa+oAAPgfgcjP+DV1AAD8j0AUIPg1dQAA/IebqgEAgO35NRC9/vrruv/++5WQkCCHw6GXXnrJ67xpmiosLFRCQoIGDx6sSZMm6ejRo141HR0dWrhwoWJjYxUREaHc3FydOHHCq8btdis/P1+GYcgwDOXn5+v06dPXuTsAABAs/BqIzpw5ozvvvFOlpaU9nl+xYoVKSkpUWlqqgwcPyul0asqUKWptbbVqCgoKtH37dpWXl2v37t1qa2tTTk6Ourq6rJq8vDzV1NSooqJCFRUVqqmpUX5+/nXvDwAABAe/3kM0ffp0TZ8+vcdzpmlq1apVWr58uWbMmCFJ2rx5s+Lj47Vt2zbNmzdPHo9HGzZs0JYtWzR58mRJUllZmRITE7Vz505NnTpVx44dU0VFhfbt26f09HRJ0vr165WRkaG6ujqlpPR8305HR4c6Ojqs/ZaWlr5sHQAABJCAvYfo+PHjcrlcys7Oto6Fh4dr4sSJ2rNnjySpurpaZ8+e9apJSEhQamqqVbN3714ZhmGFIUmaMGGCDMOwanpSXFxsfcRmGIYSExP7ukUAABAgAjYQuVwuSVJ8fLzX8fj4eOucy+VSWFiYhg4detmauLi4btePi4uzanqybNkyeTwea2toaLimfgAAQOAK+MfuHQ6H175pmt2OXezimp7qr3Sd8PBwhYeH93K0AAAgGAXsCpHT6ZSkbqs4TU1N1qqR0+lUZ2en3G73ZWtOnjzZ7fqnTp3qtvoEAADsKWADUVJSkpxOpyorK61jnZ2dqqqqUmZmpiQpLS1NoaGhXjWNjY2qra21ajIyMuTxeHTgwAGrZv/+/fJ4PFYNAACwN79+ZNbW1qY//elP1v7x48dVU1Oj6OhoDR8+XAUFBSoqKlJycrKSk5NVVFSkIUOGKC8vT5JkGIZmz56txYsXKyYmRtHR0VqyZInGjBljPXU2atQoTZs2TXPmzNHatWslSXPnzlVOTs4lnzADAAD24tdAdOjQId17773W/uOPPy5JmjVrljZt2qSlS5eqvb1d8+fPl9vtVnp6unbs2KHIyEjrNStXrlRISIhmzpyp9vZ2ZWVladOmTRo4cKBVs3XrVi1atMh6Gi03N/eS330EAADsx6+BaNKkSTJN85LnHQ6HCgsLVVhYeMmaQYMGafXq1Vq9evUla6Kjo1VWVnYtQwUAADewgL2HCAAAoL8QiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO3ZKhA999xzSkpK0qBBg5SWlqbf//73/h4SAAAIALYJRD//+c9VUFCg5cuX6/Dhw/rc5z6n6dOnq76+3t9DAwAAfmabQFRSUqLZs2frW9/6lkaNGqVVq1YpMTFRa9as8ffQAACAn4X4ewD9obOzU9XV1XriiSe8jmdnZ2vPnj09vqajo0MdHR3WvsfjkSS1tLT06dja2tokSR++X6dzHe0+X6fF9beVrurqauuavhgwYIDOnz/v8+v76hqBMpa6ujpJzE8gj6UvrtEX8xxIc9xX1wmUawTS/EiB8/cSKP+t9OX8tLW19fm/sxeuZ5rm5QtNG/jggw9MSeYf/vAHr+NPP/20+clPfrLH1zz55JOmJDY2NjY2NrYbYGtoaLhsVrDFCtEFDofDa980zW7HLli2bJkef/xxa//8+fP68MMPFRMTc8nX+KKlpUWJiYlqaGhQVFRUn103kNzoPdJf8LvRe7zR+5Nu/B7pz3emaaq1tVUJCQmXrbNFIIqNjdXAgQPlcrm8jjc1NSk+Pr7H14SHhys8PNzr2E033XS9hqioqKgb8j/yj7vRe6S/4Hej93ij9yfd+D3Sn28Mw7hijS1uqg4LC1NaWpoqKyu9jldWViozM9NPowIAAIHCFitEkvT4448rPz9f48aNU0ZGhtatW6f6+no9/PDD/h4aAADwM9sEoq985Sv6y1/+ou9+97tqbGxUamqqfvOb3+jWW2/167jCw8P15JNPdvt47kZyo/dIf8HvRu/xRu9PuvF7pL/rz2GaV3oODQAA4MZmi3uIAAAALodABAAAbI9ABAAAbI9ABAAAbI9A1A+ee+45JSUladCgQUpLS9Pvf//7y9ZXVVUpLS1NgwYN0m233abnn3++n0bqm970t2vXLjkcjm7b22+/3Y8j7p3XX39d999/vxISEuRwOPTSSy9d8TXBNIe97S/Y5rC4uFjjx49XZGSk4uLi9MADD1i/vXQ5wTKHvvQXbHO4Zs0ajR071vrSvoyMDP32t7+97GuCZf6k3vcXbPN3seLiYjkcDhUUFFy2rr/nkEB0nf385z9XQUGBli9frsOHD+tzn/ucpk+frvr6+h7rjx8/rvvuu0+f+9zndPjwYX3nO9/RokWL9MILL/TzyK9Ob/u7oK6uTo2NjdaWnJzcTyPuvTNnzujOO+9UaWnpVdUH2xz2tr8LgmUOq6qq9Oijj2rfvn2qrKzUuXPnlJ2drTNnzlzyNcE0h770d0GwzOEtt9yi73//+zp06JAOHTqkL3zhC/rSl76ko0eP9lgfTPMn9b6/C4Jl/j7u4MGDWrduncaOHXvZOr/MYZ/8eiou6dOf/rT58MMPex0bOXKk+cQTT/RYv3TpUnPkyJFex+bNm2dOmDDhuo3xWvS2v9dee82UZLrd7n4YXd+TZG7fvv2yNcE2hx93Nf0F+xw2NTWZksyqqqpL1gTzHF5Nf8E+h6ZpmkOHDjV/8pOf9HgumOfvgsv1F6zz19raaiYnJ5uVlZXmxIkTzccee+yStf6YQ1aIrqPOzk5VV1crOzvb63h2drb27NnT42v27t3brX7q1Kk6dOiQzp49e93G6gtf+rvg7rvv1rBhw5SVlaXXXnvteg6z3wXTHF6LYJ1Dj8cjSYqOjr5kTTDP4dX0d0EwzmFXV5fKy8t15swZZWRk9FgTzPN3Nf1dEGzz9+ijj+qLX/yiJk+efMVaf8whgeg6am5uVldXV7cfkI2Pj+/2Q7MXuFyuHuvPnTun5ubm6zZWX/jS37Bhw7Ru3Tq98MILevHFF5WSkqKsrCy9/vrr/THkfhFMc+iLYJ5D0zT1+OOP67Of/axSU1MvWResc3i1/QXjHB45ckSf+MQnFB4erocffljbt2/X6NGje6wNxvnrTX/BOH/l5eV64403VFxcfFX1/phD2/x0hz85HA6vfdM0ux27Un1PxwNFb/pLSUlRSkqKtZ+RkaGGhgb913/9lz7/+c9f13H2p2Cbw94I5jlcsGCB3nzzTe3evfuKtcE4h1fbXzDOYUpKimpqanT69Gm98MILmjVrlqqqqi4ZGoJt/nrTX7DNX0NDgx577DHt2LFDgwYNuurX9fccskJ0HcXGxmrgwIHdVkuampq6Jd8LnE5nj/UhISGKiYm5bmP1hS/99WTChAl65513+np4fhNMc9hXgmEOFy5cqJdfflmvvfaabrnllsvWBuMc9qa/ngT6HIaFhemOO+7QuHHjVFxcrDvvvFM/+tGPeqwNxvnrTX89CeT5q66uVlNTk9LS0hQSEqKQkBBVVVXpxz/+sUJCQtTV1dXtNf6YQwLRdRQWFqa0tDRVVlZ6Ha+srFRmZmaPr8nIyOhWv2PHDo0bN06hoaHXbay+8KW/nhw+fFjDhg3r6+H5TTDNYV8J5Dk0TVMLFizQiy++qFdffVVJSUlXfE0wzaEv/fUkkOewJ6ZpqqOjo8dzwTR/l3K5/noSyPOXlZWlI0eOqKamxtrGjRunBx98UDU1NRo4cGC31/hlDq/b7dowTdM0y8vLzdDQUHPDhg3mW2+9ZRYUFJgRERHme++9Z5qmaT7xxBNmfn6+Vf/uu++aQ4YMMb/97W+bb731lrlhwwYzNDTU/OUvf+mvFi6rt/2tXLnS3L59u/nHP/7RrK2tNZ944glTkvnCCy/4q4Uram1tNQ8fPmwePnzYlGSWlJSYhw8fNt9//33TNIN/DnvbX7DN4SOPPGIahmHu2rXLbGxstLaPPvrIqgnmOfSlv2Cbw2XLlpmvv/66efz4cfPNN980v/Od75gDBgwwd+zYYZpmcM+fafa+v2Cbv55c/JRZIMwhgagfPPvss+att95qhoWFmffcc4/X47CzZs0yJ06c6FW/a9cu8+677zbDwsLMESNGmGvWrOnnEfdOb/r7wQ9+YN5+++3moEGDzKFDh5qf/exnzV//+td+GPXVu/CI68XbrFmzTNMM/jnsbX/BNoc99SbJ3Lhxo1UTzHPoS3/BNocPPfSQ9b8xN998s5mVlWWFBdMM7vkzzd73F2zz15OLA1EgzKHDNP9+lxIAAIBNcQ8RAACwPQIRAACwPQIRAACwPQIRAACwPQIRAACwPQIRAACwPQIRAACwPQIRAACwPQIRANsbMWKEVq1a5e9hAPAjAhEA29i0aZNuuummbscPHjyouXPn9v+AAASMEH8PAAD6Qmdnp8LCwnx67c0339zHowEQbFghAhCUJk2apAULFujxxx9XbGyspkyZopKSEo0ZM0YRERFKTEzU/Pnz1dbWJknatWuXvvnNb8rj8cjhcMjhcKiwsFBS94/MHA6HfvKTn+gf//EfNWTIECUnJ+vll1/2ev+XX35ZycnJGjx4sO69915t3rxZDodDp0+f7qe/AQB9iUAEIGht3rxZISEh+sMf/qC1a9dqwIAB+vGPf6za2lpt3rxZr776qpYuXSpJyszM1KpVqxQVFaXGxkY1NjZqyZIll7z2U089pZkzZ+rNN9/UfffdpwcffFAffvihJOm9997TP//zP+uBBx5QTU2N5s2bp+XLl/dLzwCuDz4yAxC07rjjDq1YscLaHzlypPXnpKQk/ed//qceeeQRPffccwoLC5NhGHI4HHI6nVe89je+8Q197WtfkyQVFRVp9erVOnDggKZNm6bnn39eKSkp+uEPfyhJSklJUW1trZ5++uk+7hBAfyEQAQha48aN89p/7bXXVFRUpLfeekstLS06d+6c/vrXv+rMmTOKiIjo1bXHjh1r/TkiIkKRkZFqamqSJNXV1Wn8+PFe9Z/+9Kd97AJAIOAjMwBB6+Mh5/3339d9992n1NRUvfDCC6qurtazzz4rSTp79myvrx0aGuq173A4dP78eUmSaZpyOBxe503T7PV7AAgcrBABuCEcOnRI586d0zPPPKMBA/72//V+8YtfeNWEhYWpq6vrmt9r5MiR+s1vftPt/QEEL1aIANwQbr/9dp07d06rV6/Wu+++qy1btuj555/3qhkxYoTa2tr0yiuvqLm5WR999JFP7zVv3jy9/fbb+td//Vf98Y9/1C9+8Qtt2rRJkrqtHAEIDgQiADeEu+66SyUlJfrBD36g1NRUbd26VcXFxV41mZmZevjhh/WVr3xFN998s9cN2b2RlJSkX/7yl3rxxRc1duxYrVmzxnrKLDw8/Jp7AdD/HCYffAPANXv66af1/PPPq6Ghwd9DAeAD7iECAB8899xzGj9+vGJiYvSHP/xBP/zhD7VgwQJ/DwuAjwhEAOCDd955R9/73vf04Ycfavjw4Vq8eLGWLVvm72EB8BEfmQEAANvjpmoAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7/w+JRDv2zAsS0gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(TRAIN_PATH)\n",
    "sns.histplot(df_raw[\"rating\"])\n",
    "cls_counts = np.histogram(df_raw[\"rating\"], bins=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: Path_t,\n",
    "        tokenizer: BertTokenizer,\n",
    "        batch_size: int,\n",
    "        val_fraction: float = 0.0,\n",
    "        truncation_strategy: Literal[\"truncate\"] = \"truncate\",\n",
    "        max_seq_len: int = 512,\n",
    "        clean_fn: Callable[[str], str] = lambda x: x,\n",
    "        n_first: int | None = None,  # just for testing purposes\n",
    "    ):\n",
    "        super(TextClassificationDataModule, self).__init__()\n",
    "        assert 0 <= val_fraction <= 1\n",
    "\n",
    "        self._data_path = data_path\n",
    "        self._clean_fn = clean_fn\n",
    "        self._tokenizer = tokenizer\n",
    "        self._encode_fn = partial(\n",
    "            tokenizer.encode_plus,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_seq_len,\n",
    "            truncation=True if truncation_strategy == \"truncate\" else False,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        self.val_fraction = val_fraction\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self._n_first = n_first\n",
    "\n",
    "        self._encoded: list[dict[str, Tensor]]\n",
    "        self._train: Dataset\n",
    "        self._val: Dataset\n",
    "        self._test: Dataset\n",
    "\n",
    "    def setup(self, stage: Literal[\"fit\", \"test\"]) -> None:\n",
    "        if stage == \"fit\":\n",
    "            df_raw = pd.read_csv(self._data_path)\n",
    "            reviews = df_raw[\"review\"].apply(self._clean_fn).values[: self._n_first]\n",
    "            self._encoded = [self._encode_fn(review) for review in reviews]\n",
    "            ratings = df_raw[\"rating\"].values[: self._n_first]\n",
    "            dataset = TensorDataset(\n",
    "                *(\n",
    "                    torch.cat([item[k] for item in self._encoded], dim=0)\n",
    "                    for k in (\"input_ids\", \"attention_mask\")\n",
    "                ),\n",
    "                torch.tensor(ratings),\n",
    "            )\n",
    "            val_size = int(len(dataset) * self.val_fraction)\n",
    "            train_size = len(dataset) - val_size\n",
    "\n",
    "            self._train, self._val = torch.utils.data.random_split(\n",
    "                dataset, [train_size, val_size]\n",
    "            )\n",
    "\n",
    "        if stage == \"test\":\n",
    "            df_raw = pd.read_csv(self._data_path, usecols=[0], names=['review'], header=None)\n",
    "            reviews = df_raw[\"review\"].apply(self._clean_fn).values[: self._n_first]\n",
    "            self._encoded = [self._encode_fn(review) for review in reviews]\n",
    "            self._test = TensorDataset(\n",
    "                *(\n",
    "                    torch.cat([item[k] for item in self._encoded], dim=0)\n",
    "                    for k in (\"input_ids\", \"attention_mask\")\n",
    "                )\n",
    "            )\n",
    "    def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            # self._train, batch_size=self.batch_size, pin_memory=True, sampler=WeightedRandomSampler(weights=1/cls_counts, num_samples=len(self._train), replacement=True)\n",
    "            self._train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self._val, batch_size=self.batch_size, shuffle=False, pin_memory=True\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self._test, batch_size=self.batch_size, shuffle=False, pin_memory=True\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self._test, batch_size=self.batch_size, shuffle=False, pin_memory=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: BertForSequenceClassification,\n",
    "        lr: float,\n",
    "        weight_decay: float = 0.0,\n",
    "        warmup_steps: int = 0,\n",
    "        freeze_encoder: bool = False,\n",
    "    ):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        num_classes = model.num_labels\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.model = model\n",
    "        self._lr = lr\n",
    "        self._weight_decay = weight_decay\n",
    "        self._warmup_steps = warmup_steps\n",
    "        self._freeze_encoder = freeze_encoder\n",
    "\n",
    "        if freeze_encoder:\n",
    "            for param in self.model.base_model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "\n",
    "        self.flat_metrics = {\n",
    "            \"accuracy\": MulticlassAccuracy(num_classes=num_classes, average=\"micro\").to(\n",
    "                device\n",
    "            ),\n",
    "            \"precision\": MulticlassPrecision(\n",
    "                num_classes=num_classes, average=\"micro\"\n",
    "            ).to(device),\n",
    "            \"recall\": MulticlassRecall(num_classes=num_classes, average=\"micro\").to(\n",
    "                device\n",
    "            ),\n",
    "            \"f1\": MulticlassF1Score(num_classes=num_classes, average=\"micro\").to(\n",
    "                device\n",
    "            ),\n",
    "        }\n",
    "        self.class_metrics = {\n",
    "            \"accuracy\": MulticlassAccuracy(num_classes=num_classes, average=\"none\").to(\n",
    "                device\n",
    "            ),\n",
    "            \"precision\": MulticlassPrecision(\n",
    "                num_classes=num_classes, average=\"none\"\n",
    "            ).to(device),\n",
    "            \"recall\": MulticlassRecall(num_classes=num_classes, average=\"none\").to(\n",
    "                device\n",
    "            ),\n",
    "            \"f1\": MulticlassF1Score(num_classes=num_classes, average=\"none\").to(device),\n",
    "        }\n",
    "        self.confusion_matrix = MulticlassConfusionMatrix(\n",
    "            num_classes=num_classes, normalize=\"pred\"\n",
    "        ).to(device)\n",
    "\n",
    "    def configure_optimizers(self) -> Any:\n",
    "        self.trainer.fit_loop.setup_data()\n",
    "        total_devices = getattr(self.hparams, \"n_gpus\", 1) * getattr(\n",
    "            self.hparams, \"n_nodes\", 1\n",
    "        )\n",
    "        train_batches = len(self.trainer.train_dataloader) // total_devices\n",
    "        train_steps = (\n",
    "            self.trainer.max_epochs * train_batches\n",
    "        ) // self.trainer.accumulate_grad_batches\n",
    "        # will not work with AdamW (plus it is deprecated anyway)\n",
    "        # https://discuss.huggingface.co/t/runtimeerror-element-0-of-tensors-does-not-require-grad-and-does-not-have-a-grad-fn/47965/2\n",
    "        optimizer = Adam(\n",
    "            self.model.parameters(),\n",
    "            lr=self._lr,\n",
    "            eps=1e-8,\n",
    "            weight_decay=self._weight_decay,\n",
    "        )\n",
    "        lr_scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer=optimizer,\n",
    "            num_warmup_steps=self._warmup_steps,\n",
    "            num_training_steps=train_steps,\n",
    "        )\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: tuple[Tensor, Tensor, Tensor], batch_idx: int\n",
    "    ) -> dict[str, Tensor]:\n",
    "        input_ids, input_mask, labels = batch\n",
    "        output = self.model(\n",
    "            input_ids, token_type_ids=None, attention_mask=input_mask, labels=labels\n",
    "        )\n",
    "        loss = output.loss\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: tuple[Tensor, Tensor, Tensor], batch_idx: int\n",
    "    ) -> dict[str, Tensor]:\n",
    "        with torch.no_grad():\n",
    "            input_ids, input_mask, labels = batch\n",
    "            output = self.model(\n",
    "                input_ids, token_type_ids=None, attention_mask=input_mask, labels=labels\n",
    "            )\n",
    "            loss = output.loss\n",
    "\n",
    "            preds = output.logits\n",
    "            self.log(\"val_loss\", loss, prog_bar=True)\n",
    "            self.log_dict(\n",
    "                {\n",
    "                    name: metric(preds, labels)\n",
    "                    for name, metric in self.flat_metrics.items()\n",
    "                },\n",
    "                prog_bar=True,\n",
    "            )\n",
    "            self.log_dict(\n",
    "                {\n",
    "                    f\"{name}_{c}\": v\n",
    "                    for name, metric_values in {\n",
    "                        _name: metric(preds, labels)\n",
    "                        for _name, metric in self.class_metrics.items()\n",
    "                    }.items()\n",
    "                    for c, v in enumerate(metric_values)\n",
    "                },\n",
    "                prog_bar=True,\n",
    "            )\n",
    "            self.confusion_matrix(preds, labels)\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        with torch.no_grad():\n",
    "            confusion_matrix = self.confusion_matrix.compute()\n",
    "\n",
    "            df_cm = pd.DataFrame(\n",
    "                confusion_matrix.cpu().numpy(), index=range(5), columns=range(5)\n",
    "            )\n",
    "            fig, ax = plt.subplots(figsize=(10, 7))\n",
    "            sns.heatmap(\n",
    "                df_cm,\n",
    "                ax=ax,\n",
    "                annot=True,\n",
    "                cmap=\"Greens\",\n",
    "                vmin=0,\n",
    "                vmax=1,\n",
    "                annot_kws={\"size\": 6},\n",
    "                fmt=\".3f\",\n",
    "            )\n",
    "            ax.set_xlabel(\"True class\")\n",
    "            ax.set_ylabel(\"Predicted class\")\n",
    "            self.logger.experiment.add_figure(\n",
    "                \"Confusion matrix\", fig, self.current_epoch\n",
    "            )\n",
    "\n",
    "    def predict_step(self, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> Any:\n",
    "        with torch.no_grad():\n",
    "            input_ids, input_mask = batch\n",
    "            return self.model(\n",
    "                input_ids, token_type_ids=None, attention_mask=input_mask\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"distilbert/distilbert-base-uncased\",\n",
    "# \"prajjwal1/bert-medium\",\n",
    "# \"prajjwal1/bert-small\",\n",
    "# \"prajjwal1/bert-mini\",\n",
    "# \"bert-large-uncased-whole-word-masking\",\n",
    "# \"bert-base-uncased\",\n",
    "# \"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "# \"bert-large-uncased\",\n",
    "\n",
    "bert_version = \"bert-base-uncased\"\n",
    "batch_size = 32\n",
    "lr = 5e-5\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    bert_version, do_lower_case=True, cache_dir=MODEL_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to nltk...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\", download_dir=NLTK_DIR)\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n",
    "    punctuations = \"@#!?+&*[]-%.:/();$=><|{}^\" + \"'`\" + \"_\"\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p, \"\")  # Removing punctuations\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = TextClassificationDataModule(\n",
    "    data_path=Path(TRAIN_PATH),\n",
    "    tokenizer=tokenizer,\n",
    "    val_fraction=0.2,\n",
    "    batch_size=batch_size,\n",
    "    clean_fn=clean_text,\n",
    "    max_seq_len=512,\n",
    ")\n",
    "dm.prepare_data()\n",
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (model): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       "  )\n",
       "  (confusion_matrix): MulticlassConfusionMatrix()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier(\n",
    "    model=BertForSequenceClassification.from_pretrained(\n",
    "        bert_version,\n",
    "        num_labels=5,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "        cache_dir=MODEL_DIR,\n",
    "    ),\n",
    "    lr=lr,\n",
    "    weight_decay=weight_decay,\n",
    "    warmup_steps=0,\n",
    "    freeze_encoder=False,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model            │ BertForSequenceClassification │  109 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ confusion_matrix │ MulticlassConfusionMatrix     │      0 │\n",
       "└───┴──────────────────┴───────────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model            │ BertForSequenceClassification │  109 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ confusion_matrix │ MulticlassConfusionMatrix     │      0 │\n",
       "└───┴──────────────────┴───────────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 109 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 109 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 437                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 109 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 109 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 437                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a58ec9e2eb499fa2bbed1d572f1633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connecto\n",
       "r.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connecto\n",
       "r.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "10 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "10 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "20 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "20 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "10 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "10 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "10 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "10 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "10 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "10 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "10 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "10 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "10 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "10 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning:\n",
       "Detected KeyboardInterrupt, attempting graceful shutdown...\n",
       "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning:\n",
       "Detected KeyboardInterrupt, attempting graceful shutdown...\n",
       "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_val_acc_callback = ModelCheckpoint(\n",
    "    monitor=\"accuracy\",\n",
    "    filename=\"checkpoint_best_acc-{epoch:02d}-{step:03d}-{accuracy:.5f}\",\n",
    "    save_top_k=3,\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    gradient_clip_val=1,\n",
    "    callbacks=[\n",
    "        best_val_acc_callback,\n",
    "        RichProgressBar()\n",
    "    ],\n",
    "    precision=\"bf16-mixed\",\n",
    "    val_check_interval=0.25,\n",
    ")\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = Path(\"./data/test_data.csv\")\n",
    "test_dm = TextClassificationDataModule(\n",
    "    data_path=TEST_PATH,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=1,\n",
    "    clean_fn=clean_text\n",
    ")\n",
    "test_dm.prepare_data()\n",
    "test_dm.setup(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb3a2326574473799c3428092813537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7344, -2.9219, -1.1562,  3.2656,  3.5000]], dtype=torch.bfloat16))]), logits=tensor([[-3.7344, -2.9219, -1.1562,  3.2656,  3.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.1250,  2.4531,  1.1016, -1.7578, -3.0938]], dtype=torch.bfloat16))]), logits=tensor([[ 2.1250,  2.4531,  1.1016, -1.7578, -3.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3125, -0.9688,  1.4688,  2.4844, -0.2070]], dtype=torch.bfloat16))]), logits=tensor([[-3.3125, -0.9688,  1.4688,  2.4844, -0.2070]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5156, -2.9688, -1.5000,  3.0156,  3.8594]], dtype=torch.bfloat16))]), logits=tensor([[-3.5156, -2.9688, -1.5000,  3.0156,  3.8594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4844, -3.1562, -1.9219,  2.9062,  4.6562]], dtype=torch.bfloat16))]), logits=tensor([[-3.4844, -3.1562, -1.9219,  2.9062,  4.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 4.0312,  2.0312, -0.1768, -2.2656, -2.4219]], dtype=torch.bfloat16))]), logits=tensor([[ 4.0312,  2.0312, -0.1768, -2.2656, -2.4219]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.0029,  0.3086, -0.5977, -0.5312, -0.0518]], dtype=torch.bfloat16))]), logits=tensor([[-0.0029,  0.3086, -0.5977, -0.5312, -0.0518]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4062, -3.0625, -1.8984,  2.9219,  4.3438]], dtype=torch.bfloat16))]), logits=tensor([[-3.4062, -3.0625, -1.8984,  2.9219,  4.3438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.8672,  2.1406,  1.2812, -1.0391, -2.8750]], dtype=torch.bfloat16))]), logits=tensor([[ 0.8672,  2.1406,  1.2812, -1.0391, -2.8750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6094, -2.5469, -0.9727,  2.8906,  3.1094]], dtype=torch.bfloat16))]), logits=tensor([[-3.6094, -2.5469, -0.9727,  2.8906,  3.1094]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1875, -0.8555,  1.0547,  2.1094,  0.1006]], dtype=torch.bfloat16))]), logits=tensor([[-3.1875, -0.8555,  1.0547,  2.1094,  0.1006]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0938, -0.5508,  1.7031,  1.9531, -0.6445]], dtype=torch.bfloat16))]), logits=tensor([[-3.0938, -0.5508,  1.7031,  1.9531, -0.6445]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.6289,  1.8047,  0.9375, -0.7930, -2.2969]], dtype=torch.bfloat16))]), logits=tensor([[ 0.6289,  1.8047,  0.9375, -0.7930, -2.2969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1875, -0.9609,  1.5938,  2.2969, -0.3262]], dtype=torch.bfloat16))]), logits=tensor([[-3.1875, -0.9609,  1.5938,  2.2969, -0.3262]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0000, -2.7031, -2.1875,  2.0000,  4.6875]], dtype=torch.bfloat16))]), logits=tensor([[-3.0000, -2.7031, -2.1875,  2.0000,  4.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -3.0625, -1.7344,  3.0469,  4.2188]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -3.0625, -1.7344,  3.0469,  4.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.2812,  2.4375,  0.3281, -2.2031, -2.8438]], dtype=torch.bfloat16))]), logits=tensor([[ 3.2812,  2.4375,  0.3281, -2.2031, -2.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.6211,  1.5859,  1.5312, -0.0376, -2.3594]], dtype=torch.bfloat16))]), logits=tensor([[-0.6211,  1.5859,  1.5312, -0.0376, -2.3594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -2.9688, -1.5469,  2.9531,  3.9531]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -2.9688, -1.5469,  2.9531,  3.9531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0781, -1.0156,  0.7539,  2.0469,  0.5000]], dtype=torch.bfloat16))]), logits=tensor([[-3.0781, -1.0156,  0.7539,  2.0469,  0.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7500, -3.0000, -2.4375,  2.2031,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.7500, -3.0000, -2.4375,  2.2031,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.4531,  2.2656,  0.5781, -1.7578, -2.7656]], dtype=torch.bfloat16))]), logits=tensor([[ 2.4531,  2.2656,  0.5781, -1.7578, -2.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4219, -2.6406, -1.3906,  2.4375,  3.8594]], dtype=torch.bfloat16))]), logits=tensor([[-3.4219, -2.6406, -1.3906,  2.4375,  3.8594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.6562,  2.5781,  0.9375, -2.0156, -3.1875]], dtype=torch.bfloat16))]), logits=tensor([[ 2.6562,  2.5781,  0.9375, -2.0156, -3.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8906, -3.0000, -2.4219,  2.2812,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.8906, -3.0000, -2.4219,  2.2812,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9219, -0.8984,  0.1338,  1.4922,  1.1719]], dtype=torch.bfloat16))]), logits=tensor([[-2.9219, -0.8984,  0.1338,  1.4922,  1.1719]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5469, -1.0938, -0.7070,  1.1562,  2.0938]], dtype=torch.bfloat16))]), logits=tensor([[-2.5469, -1.0938, -0.7070,  1.1562,  2.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6250, -2.9062, -2.4844,  2.0000,  5.2500]], dtype=torch.bfloat16))]), logits=tensor([[-2.6250, -2.9062, -2.4844,  2.0000,  5.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.8398,  1.6797,  1.9609, -0.0933, -2.6406]], dtype=torch.bfloat16))]), logits=tensor([[-0.8398,  1.6797,  1.9609, -0.0933, -2.6406]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.3203,  0.9844,  1.3516,  0.3613, -1.6484]], dtype=torch.bfloat16))]), logits=tensor([[-1.3203,  0.9844,  1.3516,  0.3613, -1.6484]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0312, -2.9844, -2.3281,  2.3438,  5.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.0312, -2.9844, -2.3281,  2.3438,  5.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.1338,  2.1562,  1.7891, -0.6523, -3.0625]], dtype=torch.bfloat16))]), logits=tensor([[ 0.1338,  2.1562,  1.7891, -0.6523, -3.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4688, -2.9375, -1.6406,  2.6250,  4.2188]], dtype=torch.bfloat16))]), logits=tensor([[-3.4688, -2.9375, -1.6406,  2.6250,  4.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.1328,  1.6406,  2.2031,  0.0552, -2.8594]], dtype=torch.bfloat16))]), logits=tensor([[-1.1328,  1.6406,  2.2031,  0.0552, -2.8594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4844, -1.4453,  0.7344,  2.5938,  0.8633]], dtype=torch.bfloat16))]), logits=tensor([[-3.4844, -1.4453,  0.7344,  2.5938,  0.8633]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8125, -1.5547, -0.8164,  1.4688,  2.4844]], dtype=torch.bfloat16))]), logits=tensor([[-2.8125, -1.5547, -0.8164,  1.4688,  2.4844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0625, -2.9375, -2.2656,  2.3906,  4.8438]], dtype=torch.bfloat16))]), logits=tensor([[-3.0625, -2.9375, -2.2656,  2.3906,  4.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.6875,  2.3438,  1.1875, -1.5078, -3.0625]], dtype=torch.bfloat16))]), logits=tensor([[ 1.6875,  2.3438,  1.1875, -1.5078, -3.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7969, -2.7969, -2.3750,  1.9766,  5.0938]], dtype=torch.bfloat16))]), logits=tensor([[-2.7969, -2.7969, -2.3750,  1.9766,  5.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3750, -2.0469, -0.5625,  2.3438,  2.5156]], dtype=torch.bfloat16))]), logits=tensor([[-3.3750, -2.0469, -0.5625,  2.3438,  2.5156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7031, -0.3027,  1.0469,  1.4844, -0.2578]], dtype=torch.bfloat16))]), logits=tensor([[-2.7031, -0.3027,  1.0469,  1.4844, -0.2578]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8281, -3.0312, -2.4531,  2.3281,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.8281, -3.0312, -2.4531,  2.3281,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5000, -3.2031, -1.8594,  3.1250,  4.5000]], dtype=torch.bfloat16))]), logits=tensor([[-3.5000, -3.2031, -1.8594,  3.1250,  4.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4219, -1.1406,  1.3594,  2.5625,  0.0171]], dtype=torch.bfloat16))]), logits=tensor([[-3.4219, -1.1406,  1.3594,  2.5625,  0.0171]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.4062,  2.2188,  0.0767, -2.1094, -2.6094]], dtype=torch.bfloat16))]), logits=tensor([[ 3.4062,  2.2188,  0.0767, -2.1094, -2.6094]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2500, -3.0469, -2.0781,  2.6875,  4.6875]], dtype=torch.bfloat16))]), logits=tensor([[-3.2500, -3.0469, -2.0781,  2.6875,  4.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.3574,  2.4219,  2.0312, -1.0703, -3.5625]], dtype=torch.bfloat16))]), logits=tensor([[ 0.3574,  2.4219,  2.0312, -1.0703, -3.5625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6719, -2.7969, -1.3516,  2.9219,  3.6875]], dtype=torch.bfloat16))]), logits=tensor([[-3.6719, -2.7969, -1.3516,  2.9219,  3.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7344, -2.7188, -0.8516,  3.2500,  3.0781]], dtype=torch.bfloat16))]), logits=tensor([[-3.7344, -2.7188, -0.8516,  3.2500,  3.0781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4375, -3.0156, -1.8047,  2.8594,  4.2500]], dtype=torch.bfloat16))]), logits=tensor([[-3.4375, -3.0156, -1.8047,  2.8594,  4.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8594, -1.0547, -0.0217,  1.5703,  1.3281]], dtype=torch.bfloat16))]), logits=tensor([[-2.8594, -1.0547, -0.0217,  1.5703,  1.3281]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9375, -0.5664,  1.2656,  1.9688, -0.3457]], dtype=torch.bfloat16))]), logits=tensor([[-2.9375, -0.5664,  1.2656,  1.9688, -0.3457]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8906, -2.4375, -0.5312,  3.0938,  2.7031]], dtype=torch.bfloat16))]), logits=tensor([[-3.8906, -2.4375, -0.5312,  3.0938,  2.7031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.4590,  1.9844,  1.3672, -0.6875, -2.7031]], dtype=torch.bfloat16))]), logits=tensor([[ 0.4590,  1.9844,  1.3672, -0.6875, -2.7031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6875, -2.8281, -1.2344,  2.9375,  3.6250]], dtype=torch.bfloat16))]), logits=tensor([[-3.6875, -2.8281, -1.2344,  2.9375,  3.6250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.6328,  1.7500,  1.8516, -0.1777, -2.6719]], dtype=torch.bfloat16))]), logits=tensor([[-0.6328,  1.7500,  1.8516, -0.1777, -2.6719]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7500, -1.5312, -0.7422,  1.8594,  2.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.7500, -1.5312, -0.7422,  1.8594,  2.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4531, -3.0469, -2.0625,  2.7344,  4.6562]], dtype=torch.bfloat16))]), logits=tensor([[-3.4531, -3.0469, -2.0625,  2.7344,  4.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.0859,  1.6641,  2.2188,  0.0493, -2.8438]], dtype=torch.bfloat16))]), logits=tensor([[-1.0859,  1.6641,  2.2188,  0.0493, -2.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0156, -1.8984, -0.8477,  1.8438,  2.7344]], dtype=torch.bfloat16))]), logits=tensor([[-3.0156, -1.8984, -0.8477,  1.8438,  2.7344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5938, -2.8750, -2.5000,  1.9922,  5.2500]], dtype=torch.bfloat16))]), logits=tensor([[-2.5938, -2.8750, -2.5000,  1.9922,  5.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.3438,  0.5703,  2.2500,  0.8867, -1.8047]], dtype=torch.bfloat16))]), logits=tensor([[-2.3438,  0.5703,  2.2500,  0.8867, -1.8047]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4219, -3.1250, -2.0625,  2.8281,  4.6562]], dtype=torch.bfloat16))]), logits=tensor([[-3.4219, -3.1250, -2.0625,  2.8281,  4.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1719, -3.0469, -2.2344,  2.5156,  4.9375]], dtype=torch.bfloat16))]), logits=tensor([[-3.1719, -3.0469, -2.2344,  2.5156,  4.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3438, -2.4219, -1.4844,  2.0625,  3.9531]], dtype=torch.bfloat16))]), logits=tensor([[-3.3438, -2.4219, -1.4844,  2.0625,  3.9531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.2500,  0.3301,  1.7812,  1.1484, -1.5469]], dtype=torch.bfloat16))]), logits=tensor([[-2.2500,  0.3301,  1.7812,  1.1484, -1.5469]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8906, -0.6484,  1.2422,  2.0000, -0.3105]], dtype=torch.bfloat16))]), logits=tensor([[-2.8906, -0.6484,  1.2422,  2.0000, -0.3105]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9375, -3.0312, -2.3906,  2.3281,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.9375, -3.0312, -2.3906,  2.3281,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1719, -3.0781, -2.1875,  2.5781,  4.8125]], dtype=torch.bfloat16))]), logits=tensor([[-3.1719, -3.0781, -2.1875,  2.5781,  4.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4219, -1.6875,  0.6289,  2.7656,  1.1172]], dtype=torch.bfloat16))]), logits=tensor([[-3.4219, -1.6875,  0.6289,  2.7656,  1.1172]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3438, -2.9219, -2.0156,  2.6250,  4.5000]], dtype=torch.bfloat16))]), logits=tensor([[-3.3438, -2.9219, -2.0156,  2.6250,  4.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.1562,  2.4219,  1.6016, -1.2891, -3.3594]], dtype=torch.bfloat16))]), logits=tensor([[ 1.1562,  2.4219,  1.6016, -1.2891, -3.3594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.4609,  1.5469,  2.2969,  0.1729, -2.7812]], dtype=torch.bfloat16))]), logits=tensor([[-1.4609,  1.5469,  2.2969,  0.1729, -2.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7031, -3.0938, -1.3828,  3.2656,  3.8438]], dtype=torch.bfloat16))]), logits=tensor([[-3.7031, -3.0938, -1.3828,  3.2656,  3.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9531, -1.1797,  0.1318,  2.0000,  1.1328]], dtype=torch.bfloat16))]), logits=tensor([[-2.9531, -1.1797,  0.1318,  2.0000,  1.1328]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.1562,  2.2031,  0.6992, -1.6328, -2.7188]], dtype=torch.bfloat16))]), logits=tensor([[ 2.1562,  2.2031,  0.6992, -1.6328, -2.7188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9375, -2.7969, -2.2500,  2.1406,  4.7812]], dtype=torch.bfloat16))]), logits=tensor([[-2.9375, -2.7969, -2.2500,  2.1406,  4.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7031, -2.8125, -0.8047,  3.3906,  2.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.7031, -2.8125, -0.8047,  3.3906,  2.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0781, -0.7344,  1.3594,  1.9375, -0.2441]], dtype=torch.bfloat16))]), logits=tensor([[-3.0781, -0.7344,  1.3594,  1.9375, -0.2441]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.7500, -0.5234,  3.4844,  2.7969]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.7500, -0.5234,  3.4844,  2.7969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1406, -2.8281, -2.1875,  2.3906,  4.6875]], dtype=torch.bfloat16))]), logits=tensor([[-3.1406, -2.8281, -2.1875,  2.3906,  4.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7812, -0.2871,  1.3906,  1.8438, -0.7148]], dtype=torch.bfloat16))]), logits=tensor([[-2.7812, -0.2871,  1.3906,  1.8438, -0.7148]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.3184,  1.9141,  1.3984, -0.5898, -2.6094]], dtype=torch.bfloat16))]), logits=tensor([[ 0.3184,  1.9141,  1.3984, -0.5898, -2.6094]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5469, -3.0469, -1.7109,  3.0469,  4.1562]], dtype=torch.bfloat16))]), logits=tensor([[-3.5469, -3.0469, -1.7109,  3.0469,  4.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -2.9531, -1.0078,  3.3906,  3.3594]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -2.9531, -1.0078,  3.3906,  3.3594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.3906, -0.1738,  3.2656,  2.2500]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.3906, -0.1738,  3.2656,  2.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4219, -3.2031, -2.0312,  2.8750,  4.8125]], dtype=torch.bfloat16))]), logits=tensor([[-3.4219, -3.2031, -2.0312,  2.8750,  4.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4375, -3.0469, -1.9062,  2.8594,  4.4375]], dtype=torch.bfloat16))]), logits=tensor([[-3.4375, -3.0469, -1.9062,  2.8594,  4.4375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.5703,  1.3984,  2.2344,  0.4062, -2.6406]], dtype=torch.bfloat16))]), logits=tensor([[-1.5703,  1.3984,  2.2344,  0.4062, -2.6406]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4219, -3.1406, -1.9609,  2.9844,  4.5000]], dtype=torch.bfloat16))]), logits=tensor([[-3.4219, -3.1406, -1.9609,  2.9844,  4.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.9219,  1.6094, -0.3672, -2.0000, -1.9375]], dtype=torch.bfloat16))]), logits=tensor([[ 3.9219,  1.6094, -0.3672, -2.0000, -1.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -2.6250, -0.8711,  3.0469,  3.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -2.6250, -0.8711,  3.0469,  3.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2500, -3.1406, -2.1875,  2.7812,  4.8438]], dtype=torch.bfloat16))]), logits=tensor([[-3.2500, -3.1406, -2.1875,  2.7812,  4.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.1875,  0.7227,  1.9844,  0.9570, -1.9375]], dtype=torch.bfloat16))]), logits=tensor([[-2.1875,  0.7227,  1.9844,  0.9570, -1.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 4.0312,  2.0938, -0.1455, -2.2969, -2.4844]], dtype=torch.bfloat16))]), logits=tensor([[ 4.0312,  2.0938, -0.1455, -2.2969, -2.4844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2031, -3.1562, -2.2656,  2.7344,  4.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.2031, -3.1562, -2.2656,  2.7344,  4.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4688, -3.1094, -1.9062,  2.7812,  4.5312]], dtype=torch.bfloat16))]), logits=tensor([[-3.4688, -3.1094, -1.9062,  2.7812,  4.5312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2500, -3.1406, -2.2500,  2.6875,  4.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.2500, -3.1406, -2.2500,  2.6875,  4.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.2656,  2.3125,  0.2656, -2.1562, -2.7031]], dtype=torch.bfloat16))]), logits=tensor([[ 3.2656,  2.3125,  0.2656, -2.1562, -2.7031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0625, -3.0000, -2.2656,  2.3750,  4.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.0625, -3.0000, -2.2656,  2.3750,  4.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.9062, -2.4844, -0.4434,  3.2188,  2.6406]], dtype=torch.bfloat16))]), logits=tensor([[-3.9062, -2.4844, -0.4434,  3.2188,  2.6406]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3594, -3.1562, -1.9844,  2.7969,  4.6250]], dtype=torch.bfloat16))]), logits=tensor([[-3.3594, -3.1562, -1.9844,  2.7969,  4.6250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7031, -2.3438, -0.0393,  3.1875,  2.0938]], dtype=torch.bfloat16))]), logits=tensor([[-3.7031, -2.3438, -0.0393,  3.1875,  2.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.1250,  0.6172,  1.6250,  0.8945, -1.4609]], dtype=torch.bfloat16))]), logits=tensor([[-2.1250,  0.6172,  1.6250,  0.8945, -1.4609]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.0469,  2.3594,  0.3867, -2.0625, -2.7656]], dtype=torch.bfloat16))]), logits=tensor([[ 3.0469,  2.3594,  0.3867, -2.0625, -2.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.1670,  1.9141,  1.7109, -0.4219, -2.7812]], dtype=torch.bfloat16))]), logits=tensor([[-0.1670,  1.9141,  1.7109, -0.4219, -2.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.8828, -0.2793,  0.0430,  0.8164,  0.4668]], dtype=torch.bfloat16))]), logits=tensor([[-1.8828, -0.2793,  0.0430,  0.8164,  0.4668]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.5000,  1.0547,  1.9297,  0.7109, -2.4531]], dtype=torch.bfloat16))]), logits=tensor([[-1.5000,  1.0547,  1.9297,  0.7109, -2.4531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.1108,  2.0312,  1.9297, -0.4336, -3.0625]], dtype=torch.bfloat16))]), logits=tensor([[-0.1108,  2.0312,  1.9297, -0.4336, -3.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8281, -2.5156, -0.1621,  3.4531,  2.3281]], dtype=torch.bfloat16))]), logits=tensor([[-3.8281, -2.5156, -0.1621,  3.4531,  2.3281]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.2500,  0.7109,  2.1406,  0.9375, -1.9844]], dtype=torch.bfloat16))]), logits=tensor([[-2.2500,  0.7109,  2.1406,  0.9375, -1.9844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5156, -1.3750,  1.2891,  2.6719,  0.3867]], dtype=torch.bfloat16))]), logits=tensor([[-3.5156, -1.3750,  1.2891,  2.6719,  0.3867]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.8828,  0.8086,  1.7969,  0.7539, -1.8984]], dtype=torch.bfloat16))]), logits=tensor([[-1.8828,  0.8086,  1.7969,  0.7539, -1.8984]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.4531,  2.2656,  0.0708, -2.1719, -2.6250]], dtype=torch.bfloat16))]), logits=tensor([[ 3.4531,  2.2656,  0.0708, -2.1719, -2.6250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.8906, -1.0312,  3.3281,  3.4062]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.8906, -1.0312,  3.3281,  3.4062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8594, -2.7188, -0.4141,  3.5469,  2.6094]], dtype=torch.bfloat16))]), logits=tensor([[-3.8594, -2.7188, -0.4141,  3.5469,  2.6094]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4062, -2.8125, -2.5000,  1.8125,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.4062, -2.8125, -2.5000,  1.8125,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.3594,  2.0469,  2.0625, -0.4043, -3.1250]], dtype=torch.bfloat16))]), logits=tensor([[-0.3594,  2.0469,  2.0625, -0.4043, -3.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1719, -3.0781, -2.2656,  2.6250,  4.8125]], dtype=torch.bfloat16))]), logits=tensor([[-3.1719, -3.0781, -2.2656,  2.6250,  4.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6562, -2.9844, -1.4766,  2.9688,  3.9531]], dtype=torch.bfloat16))]), logits=tensor([[-3.6562, -2.9844, -1.4766,  2.9688,  3.9531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3906, -3.1094, -2.0781,  2.7656,  4.7188]], dtype=torch.bfloat16))]), logits=tensor([[-3.3906, -3.1094, -2.0781,  2.7656,  4.7188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3594, -3.1719, -2.1406,  2.8438,  4.8750]], dtype=torch.bfloat16))]), logits=tensor([[-3.3594, -3.1719, -2.1406,  2.8438,  4.8750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.8516,  2.2500,  0.8906, -1.5234, -2.8438]], dtype=torch.bfloat16))]), logits=tensor([[ 1.8516,  2.2500,  0.8906, -1.5234, -2.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7188, -2.9375, -2.4688,  2.1094,  5.2500]], dtype=torch.bfloat16))]), logits=tensor([[-2.7188, -2.9375, -2.4688,  2.1094,  5.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2969, -3.1094, -2.1406,  2.6250,  4.8125]], dtype=torch.bfloat16))]), logits=tensor([[-3.2969, -3.1094, -2.1406,  2.6250,  4.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.9219,  2.3906,  0.4473, -2.0469, -2.8281]], dtype=torch.bfloat16))]), logits=tensor([[ 2.9219,  2.3906,  0.4473, -2.0469, -2.8281]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.5547,  1.3750,  2.1250,  0.2949, -2.4844]], dtype=torch.bfloat16))]), logits=tensor([[-1.5547,  1.3750,  2.1250,  0.2949, -2.4844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.8906, -1.1562,  3.0625,  3.5781]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.8906, -1.1562,  3.0625,  3.5781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1406, -3.1250, -2.2656,  2.6250,  5.0000]], dtype=torch.bfloat16))]), logits=tensor([[-3.1406, -3.1250, -2.2656,  2.6250,  5.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 4.0000,  1.2500, -0.4824, -1.9219, -1.7031]], dtype=torch.bfloat16))]), logits=tensor([[ 4.0000,  1.2500, -0.4824, -1.9219, -1.7031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.2305,  2.0938,  1.7344, -0.6758, -3.0156]], dtype=torch.bfloat16))]), logits=tensor([[ 0.2305,  2.0938,  1.7344, -0.6758, -3.0156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -2.7969, -1.2266,  2.7812,  3.6875]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -2.7969, -1.2266,  2.7812,  3.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.9844,  0.7344,  1.7734,  0.9766, -1.8672]], dtype=torch.bfloat16))]), logits=tensor([[-1.9844,  0.7344,  1.7734,  0.9766, -1.8672]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.0469,  2.2188,  0.7422, -1.6094, -2.7812]], dtype=torch.bfloat16))]), logits=tensor([[ 2.0469,  2.2188,  0.7422, -1.6094, -2.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.8438,  2.1719,  0.8672, -1.4531, -2.7656]], dtype=torch.bfloat16))]), logits=tensor([[ 1.8438,  2.1719,  0.8672, -1.4531, -2.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4062, -1.3594,  1.2188,  2.8125,  0.1914]], dtype=torch.bfloat16))]), logits=tensor([[-3.4062, -1.3594,  1.2188,  2.8125,  0.1914]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.3125,  0.6055,  2.0156,  0.8789, -1.7188]], dtype=torch.bfloat16))]), logits=tensor([[-2.3125,  0.6055,  2.0156,  0.8789, -1.7188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6875, -2.1250,  0.2129,  2.9531,  1.8125]], dtype=torch.bfloat16))]), logits=tensor([[-3.6875, -2.1250,  0.2129,  2.9531,  1.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1875, -2.7969, -1.8672,  2.3594,  4.2500]], dtype=torch.bfloat16))]), logits=tensor([[-3.1875, -2.7969, -1.8672,  2.3594,  4.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.7969,  1.3203, -0.4746, -1.8203, -1.6641]], dtype=torch.bfloat16))]), logits=tensor([[ 3.7969,  1.3203, -0.4746, -1.8203, -1.6641]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5625, -3.1094, -1.8047,  3.0312,  4.2812]], dtype=torch.bfloat16))]), logits=tensor([[-3.5625, -3.1094, -1.8047,  3.0312,  4.2812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.3711,  2.5312,  2.2188, -1.1875, -3.8438]], dtype=torch.bfloat16))]), logits=tensor([[ 0.3711,  2.5312,  2.2188, -1.1875, -3.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -2.9688, -1.6172,  2.9375,  4.0312]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -2.9688, -1.6172,  2.9375,  4.0312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0938, -2.9375, -2.1562,  2.3438,  4.7812]], dtype=torch.bfloat16))]), logits=tensor([[-3.0938, -2.9375, -2.1562,  2.3438,  4.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1875, -3.0625, -1.9375,  2.5469,  4.6250]], dtype=torch.bfloat16))]), logits=tensor([[-3.1875, -3.0625, -1.9375,  2.5469,  4.6250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7344, -2.6406, -0.8516,  3.1875,  2.9844]], dtype=torch.bfloat16))]), logits=tensor([[-3.7344, -2.6406, -0.8516,  3.1875,  2.9844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1406, -3.0938, -2.1562,  2.5938,  4.8750]], dtype=torch.bfloat16))]), logits=tensor([[-3.1406, -3.0938, -2.1562,  2.5938,  4.8750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8125, -2.6875, -0.8047,  3.1406,  3.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.8125, -2.6875, -0.8047,  3.1406,  3.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4844, -3.1406, -1.9688,  2.8750,  4.5938]], dtype=torch.bfloat16))]), logits=tensor([[-3.4844, -3.1406, -1.9688,  2.8750,  4.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.5156,  2.4375,  0.2539, -2.2812, -2.8438]], dtype=torch.bfloat16))]), logits=tensor([[ 3.5156,  2.4375,  0.2539, -2.2812, -2.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.3906,  0.0138,  1.3125,  1.1719, -0.6758]], dtype=torch.bfloat16))]), logits=tensor([[-2.3906,  0.0138,  1.3125,  1.1719, -0.6758]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9688, -3.0312, -2.3750,  2.3281,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.9688, -3.0312, -2.3750,  2.3281,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6094, -2.8594, -2.4531,  1.9531,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.6094, -2.8594, -2.4531,  1.9531,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6562, -3.1250, -1.7344,  3.1094,  4.2812]], dtype=torch.bfloat16))]), logits=tensor([[-3.6562, -3.1250, -1.7344,  3.1094,  4.2812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4688, -2.0625, -0.7031,  2.5312,  2.5938]], dtype=torch.bfloat16))]), logits=tensor([[-3.4688, -2.0625, -0.7031,  2.5312,  2.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.3125,  0.6445,  2.3906,  1.0078, -2.1406]], dtype=torch.bfloat16))]), logits=tensor([[-2.3125,  0.6445,  2.3906,  1.0078, -2.1406]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2188, -3.1094, -2.2031,  2.6875,  4.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.2188, -3.1094, -2.2031,  2.6875,  4.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5625, -2.7812, -2.4062,  1.9062,  4.9688]], dtype=torch.bfloat16))]), logits=tensor([[-2.5625, -2.7812, -2.4062,  1.9062,  4.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0781, -0.6641,  1.3906,  2.0938, -0.3613]], dtype=torch.bfloat16))]), logits=tensor([[-3.0781, -0.6641,  1.3906,  2.0938, -0.3613]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.5469,  2.3438,  0.6719, -1.8516, -2.8750]], dtype=torch.bfloat16))]), logits=tensor([[ 2.5469,  2.3438,  0.6719, -1.8516, -2.8750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.1318,  2.3438,  2.1406, -0.9414, -3.6719]], dtype=torch.bfloat16))]), logits=tensor([[ 0.1318,  2.3438,  2.1406, -0.9414, -3.6719]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.9531, -1.1875,  3.0000,  3.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.9531, -1.1875,  3.0000,  3.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.1406,  0.3965,  1.4219,  0.9727, -1.2344]], dtype=torch.bfloat16))]), logits=tensor([[-2.1406,  0.3965,  1.4219,  0.9727, -1.2344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.8320,  1.7812,  2.2656, -0.3145, -3.2812]], dtype=torch.bfloat16))]), logits=tensor([[-0.8320,  1.7812,  2.2656, -0.3145, -3.2812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.1221,  2.0156,  1.8438, -0.3965, -2.9688]], dtype=torch.bfloat16))]), logits=tensor([[-0.1221,  2.0156,  1.8438, -0.3965, -2.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.8750, -0.9922,  3.2500,  3.2969]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.8750, -0.9922,  3.2500,  3.2969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3750, -2.9688, -1.8672,  2.5781,  4.3750]], dtype=torch.bfloat16))]), logits=tensor([[-3.3750, -2.9688, -1.8672,  2.5781,  4.3750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.1406,  0.7344,  2.4062,  0.7383, -2.2500]], dtype=torch.bfloat16))]), logits=tensor([[-2.1406,  0.7344,  2.4062,  0.7383, -2.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0000, -2.9844, -2.2344,  2.3125,  4.9375]], dtype=torch.bfloat16))]), logits=tensor([[-3.0000, -2.9844, -2.2344,  2.3125,  4.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1875, -3.0781, -2.2188,  2.6094,  4.9375]], dtype=torch.bfloat16))]), logits=tensor([[-3.1875, -3.0781, -2.2188,  2.6094,  4.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.6562,  2.3281,  0.0991, -2.2812, -2.7031]], dtype=torch.bfloat16))]), logits=tensor([[ 3.6562,  2.3281,  0.0991, -2.2812, -2.7031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7188, -2.9375, -2.4219,  2.1094,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.7188, -2.9375, -2.4219,  2.1094,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.8125,  1.2734,  2.3750,  0.4082, -2.5938]], dtype=torch.bfloat16))]), logits=tensor([[-1.8125,  1.2734,  2.3750,  0.4082, -2.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8125, -2.6094, -0.9297,  2.9844,  3.2188]], dtype=torch.bfloat16))]), logits=tensor([[-3.8125, -2.6094, -0.9297,  2.9844,  3.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.9062,  2.1094, -0.1445, -2.2656, -2.4531]], dtype=torch.bfloat16))]), logits=tensor([[ 3.9062,  2.1094, -0.1445, -2.2656, -2.4531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1406, -3.1406, -2.2500,  2.6406,  4.9375]], dtype=torch.bfloat16))]), logits=tensor([[-3.1406, -3.1406, -2.2500,  2.6406,  4.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6406, -1.5391,  0.7344,  2.7031,  0.9766]], dtype=torch.bfloat16))]), logits=tensor([[-3.6406, -1.5391,  0.7344,  2.7031,  0.9766]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6406,  0.1016,  2.0312,  1.4844, -1.4922]], dtype=torch.bfloat16))]), logits=tensor([[-2.6406,  0.1016,  2.0312,  1.4844, -1.4922]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7188, -2.9375, -2.4531,  2.0781,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.7188, -2.9375, -2.4531,  2.0781,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.4531,  2.0000, -0.1367, -2.0625, -2.2812]], dtype=torch.bfloat16))]), logits=tensor([[ 3.4531,  2.0000, -0.1367, -2.0625, -2.2812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6406, -2.0000,  0.0554,  2.7812,  1.8125]], dtype=torch.bfloat16))]), logits=tensor([[-3.6406, -2.0000,  0.0554,  2.7812,  1.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6094, -3.0312, -1.6953,  3.0000,  4.1875]], dtype=torch.bfloat16))]), logits=tensor([[-3.6094, -3.0312, -1.6953,  3.0000,  4.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2656, -3.0938, -2.1406,  2.5938,  4.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.2656, -3.0938, -2.1406,  2.5938,  4.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3906, -3.0469, -2.0469,  2.7500,  4.5938]], dtype=torch.bfloat16))]), logits=tensor([[-3.3906, -3.0469, -2.0469,  2.7500,  4.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8906, -2.9688, -2.3750,  2.2969,  4.9062]], dtype=torch.bfloat16))]), logits=tensor([[-2.8906, -2.9688, -2.3750,  2.2969,  4.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.6406,  2.4062,  0.1895, -2.3125, -2.8125]], dtype=torch.bfloat16))]), logits=tensor([[ 3.6406,  2.4062,  0.1895, -2.3125, -2.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1875, -3.1250, -2.2344,  2.5469,  5.0000]], dtype=torch.bfloat16))]), logits=tensor([[-3.1875, -3.1250, -2.2344,  2.5469,  5.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.7031,  2.3281,  0.0850, -2.3125, -2.7031]], dtype=torch.bfloat16))]), logits=tensor([[ 3.7031,  2.3281,  0.0850, -2.3125, -2.7031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1250, -3.0781, -2.2500,  2.5469,  4.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.1250, -3.0781, -2.2500,  2.5469,  4.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5938, -2.9844, -1.1875,  3.2188,  3.5781]], dtype=torch.bfloat16))]), logits=tensor([[-3.5938, -2.9844, -1.1875,  3.2188,  3.5781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0000, -0.4629,  1.9219,  1.8984, -0.9180]], dtype=torch.bfloat16))]), logits=tensor([[-3.0000, -0.4629,  1.9219,  1.8984, -0.9180]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 4.8065e-04,  1.9844e+00,  1.7031e+00, -5.7422e-01, -2.9375e+00]],\n",
       "        dtype=torch.bfloat16))]), logits=tensor([[ 4.8065e-04,  1.9844e+00,  1.7031e+00, -5.7422e-01, -2.9375e+00]],\n",
       "        dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.6992,  1.7500,  0.7891, -0.8477, -2.0781]], dtype=torch.bfloat16))]), logits=tensor([[ 0.6992,  1.7500,  0.7891, -0.8477, -2.0781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8438, -0.2207,  1.4531,  1.8125, -0.7656]], dtype=torch.bfloat16))]), logits=tensor([[-2.8438, -0.2207,  1.4531,  1.8125, -0.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4844, -3.0469, -1.8203,  2.9688,  4.2812]], dtype=torch.bfloat16))]), logits=tensor([[-3.4844, -3.0469, -1.8203,  2.9688,  4.2812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1406, -3.0781, -2.2500,  2.5938,  4.8750]], dtype=torch.bfloat16))]), logits=tensor([[-3.1406, -3.0781, -2.2500,  2.5938,  4.8750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7344, -2.2969,  0.0815,  3.3125,  1.9141]], dtype=torch.bfloat16))]), logits=tensor([[-3.7344, -2.2969,  0.0815,  3.3125,  1.9141]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.9062, -0.9766,  3.2969,  3.3281]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.9062, -0.9766,  3.2969,  3.3281]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.0216,  1.2812,  0.7266, -0.4141, -1.6641]], dtype=torch.bfloat16))]), logits=tensor([[ 0.0216,  1.2812,  0.7266, -0.4141, -1.6641]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7812, -2.3750, -0.5195,  2.9531,  2.6406]], dtype=torch.bfloat16))]), logits=tensor([[-3.7812, -2.3750, -0.5195,  2.9531,  2.6406]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5938, -0.9375,  0.2354,  1.4844,  0.9336]], dtype=torch.bfloat16))]), logits=tensor([[-2.5938, -0.9375,  0.2354,  1.4844,  0.9336]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7969, -2.5312, -0.1641,  3.4375,  2.2812]], dtype=torch.bfloat16))]), logits=tensor([[-3.7969, -2.5312, -0.1641,  3.4375,  2.2812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -2.5156, -0.2656,  3.2656,  2.2500]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -2.5156, -0.2656,  3.2656,  2.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4375, -0.0674,  1.3203,  1.3984, -0.9180]], dtype=torch.bfloat16))]), logits=tensor([[-2.4375, -0.0674,  1.3203,  1.3984, -0.9180]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.5938,  1.6094, -0.4219, -1.9219, -1.8047]], dtype=torch.bfloat16))]), logits=tensor([[ 3.5938,  1.6094, -0.4219, -1.9219, -1.8047]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.7969, -0.0391, -0.0260,  0.5625,  0.5195]], dtype=torch.bfloat16))]), logits=tensor([[-1.7969, -0.0391, -0.0260,  0.5625,  0.5195]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.6094,  2.3438,  0.7070, -1.8672, -2.9062]], dtype=torch.bfloat16))]), logits=tensor([[ 2.6094,  2.3438,  0.7070, -1.8672, -2.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0625, -3.0938, -2.3281,  2.4531,  5.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.0625, -3.0938, -2.3281,  2.4531,  5.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.9219,  2.3438,  0.4160, -2.0469, -2.7656]], dtype=torch.bfloat16))]), logits=tensor([[ 2.9219,  2.3438,  0.4160, -2.0469, -2.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.9375,  2.4219,  0.5664, -2.0781, -2.9062]], dtype=torch.bfloat16))]), logits=tensor([[ 2.9375,  2.4219,  0.5664, -2.0781, -2.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.3906,  2.2031,  0.1069, -2.1406, -2.5625]], dtype=torch.bfloat16))]), logits=tensor([[ 3.3906,  2.2031,  0.1069, -2.1406, -2.5625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7344, -2.7500, -1.3047,  2.9062,  3.6875]], dtype=torch.bfloat16))]), logits=tensor([[-3.7344, -2.7500, -1.3047,  2.9062,  3.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.0156,  2.2188,  0.2344, -2.0000, -2.6094]], dtype=torch.bfloat16))]), logits=tensor([[ 3.0156,  2.2188,  0.2344, -2.0000, -2.6094]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5781, -2.7969, -2.4688,  1.8359,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.5781, -2.7969, -2.4688,  1.8359,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5938, -1.5312,  0.9336,  2.7812,  0.6953]], dtype=torch.bfloat16))]), logits=tensor([[-3.5938, -1.5312,  0.9336,  2.7812,  0.6953]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4375, -3.2031, -1.9609,  2.9688,  4.6250]], dtype=torch.bfloat16))]), logits=tensor([[-3.4375, -3.2031, -1.9609,  2.9688,  4.6250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9062, -0.4316,  1.4062,  1.6719, -0.4277]], dtype=torch.bfloat16))]), logits=tensor([[-2.9062, -0.4316,  1.4062,  1.6719, -0.4277]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7969, -2.2188,  0.2695,  3.2500,  1.7656]], dtype=torch.bfloat16))]), logits=tensor([[-3.7969, -2.2188,  0.2695,  3.2500,  1.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5625, -2.8438, -2.4531,  1.8828,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.5625, -2.8438, -2.4531,  1.8828,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9844, -3.0938, -2.4219,  2.4531,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.9844, -3.0938, -2.4219,  2.4531,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4688, -1.7969,  0.0447,  2.4531,  1.6875]], dtype=torch.bfloat16))]), logits=tensor([[-3.4688, -1.7969,  0.0447,  2.4531,  1.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.2812,  2.3281,  1.3438, -1.2891, -3.1250]], dtype=torch.bfloat16))]), logits=tensor([[ 1.2812,  2.3281,  1.3438, -1.2891, -3.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0625, -2.8750, -2.0000,  2.2031,  4.5000]], dtype=torch.bfloat16))]), logits=tensor([[-3.0625, -2.8750, -2.0000,  2.2031,  4.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.8906,  2.2344,  1.5078, -1.0078, -3.1719]], dtype=torch.bfloat16))]), logits=tensor([[ 0.8906,  2.2344,  1.5078, -1.0078, -3.1719]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.4531,  2.1719,  1.7656, -0.7227, -3.2500]], dtype=torch.bfloat16))]), logits=tensor([[ 0.4531,  2.1719,  1.7656, -0.7227, -3.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0000, -0.4707,  1.5078,  1.8047, -0.5312]], dtype=torch.bfloat16))]), logits=tensor([[-3.0000, -0.4707,  1.5078,  1.8047, -0.5312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8438, -2.8750, -0.8359,  3.3125,  3.2500]], dtype=torch.bfloat16))]), logits=tensor([[-3.8438, -2.8750, -0.8359,  3.3125,  3.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4688, -2.7188, -1.6016,  2.6250,  3.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.4688, -2.7188, -1.6016,  2.6250,  3.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4375, -3.1250, -1.8047,  2.9688,  4.3438]], dtype=torch.bfloat16))]), logits=tensor([[-3.4375, -3.1250, -1.8047,  2.9688,  4.3438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5000, -1.7812, -0.0156,  2.7344,  1.6953]], dtype=torch.bfloat16))]), logits=tensor([[-3.5000, -1.7812, -0.0156,  2.7344,  1.6953]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6406, -2.7656, -0.9688,  3.1094,  3.2344]], dtype=torch.bfloat16))]), logits=tensor([[-3.6406, -2.7656, -0.9688,  3.1094,  3.2344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.5195,  1.7344,  1.7969, -0.1758, -2.6406]], dtype=torch.bfloat16))]), logits=tensor([[-0.5195,  1.7344,  1.7969, -0.1758, -2.6406]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.5977,  1.7734,  1.9219, -0.1719, -2.7969]], dtype=torch.bfloat16))]), logits=tensor([[-0.5977,  1.7734,  1.9219, -0.1719, -2.7969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.5078,  1.7266,  0.3633, -1.2344, -2.0312]], dtype=torch.bfloat16))]), logits=tensor([[ 1.5078,  1.7266,  0.3633, -1.2344, -2.0312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.9219,  2.1250, -0.1416, -2.2812, -2.4375]], dtype=torch.bfloat16))]), logits=tensor([[ 3.9219,  2.1250, -0.1416, -2.2812, -2.4375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7188, -2.3906, -0.6797,  2.8281,  2.8750]], dtype=torch.bfloat16))]), logits=tensor([[-3.7188, -2.3906, -0.6797,  2.8281,  2.8750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7344, -2.9219, -2.4531,  2.1094,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.7344, -2.9219, -2.4531,  2.1094,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0469, -3.0312, -2.2812,  2.3125,  5.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.0469, -3.0312, -2.2812,  2.3125,  5.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4375, -3.1719, -1.9844,  2.9531,  4.5625]], dtype=torch.bfloat16))]), logits=tensor([[-3.4375, -3.1719, -1.9844,  2.9531,  4.5625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3750, -3.1562, -2.0938,  2.8594,  4.6875]], dtype=torch.bfloat16))]), logits=tensor([[-3.3750, -3.1562, -2.0938,  2.8594,  4.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.6406,  2.2812,  1.1406, -1.4375, -2.9531]], dtype=torch.bfloat16))]), logits=tensor([[ 1.6406,  2.2812,  1.1406, -1.4375, -2.9531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.8750,  2.2969,  1.0156, -1.5547, -2.9062]], dtype=torch.bfloat16))]), logits=tensor([[ 1.8750,  2.2969,  1.0156, -1.5547, -2.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5469, -2.9062, -2.5000,  2.0000,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.5469, -2.9062, -2.5000,  2.0000,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4375, -1.7656, -0.0879,  2.5469,  1.7734]], dtype=torch.bfloat16))]), logits=tensor([[-3.4375, -1.7656, -0.0879,  2.5469,  1.7734]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1094, -3.1250, -2.3438,  2.6094,  5.0312]], dtype=torch.bfloat16))]), logits=tensor([[-3.1094, -3.1250, -2.3438,  2.6094,  5.0312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6094, -2.6562, -1.2656,  2.6875,  3.5938]], dtype=torch.bfloat16))]), logits=tensor([[-3.6094, -2.6562, -1.2656,  2.6875,  3.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5625, -1.8750,  0.5430,  2.9844,  1.2109]], dtype=torch.bfloat16))]), logits=tensor([[-3.5625, -1.8750,  0.5430,  2.9844,  1.2109]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6250, -0.0791,  1.1641,  1.3359, -0.5820]], dtype=torch.bfloat16))]), logits=tensor([[-2.6250, -0.0791,  1.1641,  1.3359, -0.5820]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3438, -3.1562, -2.1094,  2.9062,  4.7188]], dtype=torch.bfloat16))]), logits=tensor([[-3.3438, -3.1562, -2.1094,  2.9062,  4.7188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6094, -3.0156, -1.6250,  2.8438,  4.1875]], dtype=torch.bfloat16))]), logits=tensor([[-3.6094, -3.0156, -1.6250,  2.8438,  4.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6719, -2.9531, -2.4844,  2.1094,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.6719, -2.9531, -2.4844,  2.1094,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1719, -3.1406, -2.3281,  2.6562,  5.0312]], dtype=torch.bfloat16))]), logits=tensor([[-3.1719, -3.1406, -2.3281,  2.6562,  5.0312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6875, -3.0156, -1.6797,  2.9219,  4.1875]], dtype=torch.bfloat16))]), logits=tensor([[-3.6875, -3.0156, -1.6797,  2.9219,  4.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7344, -2.7188, -0.8086,  3.2969,  3.0000]], dtype=torch.bfloat16))]), logits=tensor([[-3.7344, -2.7188, -0.8086,  3.2969,  3.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6719, -3.2031, -1.6797,  3.3125,  4.2188]], dtype=torch.bfloat16))]), logits=tensor([[-3.6719, -3.2031, -1.6797,  3.3125,  4.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.6875,  0.7383,  1.3672,  0.5742, -1.4141]], dtype=torch.bfloat16))]), logits=tensor([[-1.6875,  0.7383,  1.3672,  0.5742, -1.4141]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0312, -1.8672, -1.1484,  1.8984,  2.9844]], dtype=torch.bfloat16))]), logits=tensor([[-3.0312, -1.8672, -1.1484,  1.8984,  2.9844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.0000,  1.5000,  1.7969,  0.0184, -2.4531]], dtype=torch.bfloat16))]), logits=tensor([[-1.0000,  1.5000,  1.7969,  0.0184, -2.4531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -2.9062, -1.2891,  3.1250,  3.6562]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -2.9062, -1.2891,  3.1250,  3.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0000, -2.0156, -1.3438,  1.8906,  3.2812]], dtype=torch.bfloat16))]), logits=tensor([[-3.0000, -2.0156, -1.3438,  1.8906,  3.2812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.3750,  2.4375,  0.2988, -2.2188, -2.8438]], dtype=torch.bfloat16))]), logits=tensor([[ 3.3750,  2.4375,  0.2988, -2.2188, -2.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6406, -1.7734,  0.7461,  3.0000,  1.0234]], dtype=torch.bfloat16))]), logits=tensor([[-3.6406, -1.7734,  0.7461,  3.0000,  1.0234]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8438, -2.7969, -0.8750,  3.2812,  3.2031]], dtype=torch.bfloat16))]), logits=tensor([[-3.8438, -2.7969, -0.8750,  3.2812,  3.2031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0156, -3.0781, -2.3906,  2.4531,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-3.0156, -3.0781, -2.3906,  2.4531,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6406, -2.8750, -1.0391,  3.2031,  3.3125]], dtype=torch.bfloat16))]), logits=tensor([[-3.6406, -2.8750, -1.0391,  3.2031,  3.3125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6406, -2.3594, -0.5273,  2.9844,  2.5469]], dtype=torch.bfloat16))]), logits=tensor([[-3.6406, -2.3594, -0.5273,  2.9844,  2.5469]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.1250,  2.2188,  1.2656, -1.2188, -3.0156]], dtype=torch.bfloat16))]), logits=tensor([[ 1.1250,  2.2188,  1.2656, -1.2188, -3.0156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.6094,  2.4844,  0.8281, -1.9609, -3.0625]], dtype=torch.bfloat16))]), logits=tensor([[ 2.6094,  2.4844,  0.8281, -1.9609, -3.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.9609,  2.3438,  0.9219, -1.6406, -2.9375]], dtype=torch.bfloat16))]), logits=tensor([[ 1.9609,  2.3438,  0.9219, -1.6406, -2.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.4746,  1.9844,  1.3594, -0.7227, -2.6875]], dtype=torch.bfloat16))]), logits=tensor([[ 0.4746,  1.9844,  1.3594, -0.7227, -2.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6719, -2.8281, -1.3516,  2.7344,  3.8438]], dtype=torch.bfloat16))]), logits=tensor([[-3.6719, -2.8281, -1.3516,  2.7344,  3.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.3281,  2.1406,  0.4688, -1.6797, -2.6094]], dtype=torch.bfloat16))]), logits=tensor([[ 2.3281,  2.1406,  0.4688, -1.6797, -2.6094]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6562, -2.4375, -0.7617,  2.8750,  2.8281]], dtype=torch.bfloat16))]), logits=tensor([[-3.6562, -2.4375, -0.7617,  2.8750,  2.8281]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5625, -1.5938,  0.7344,  2.8281,  0.9336]], dtype=torch.bfloat16))]), logits=tensor([[-3.5625, -1.5938,  0.7344,  2.8281,  0.9336]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8125, -2.4531, -0.4121,  3.1562,  2.5781]], dtype=torch.bfloat16))]), logits=tensor([[-3.8125, -2.4531, -0.4121,  3.1562,  2.5781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.1406,  2.4062,  0.9727, -1.7109, -3.0000]], dtype=torch.bfloat16))]), logits=tensor([[ 2.1406,  2.4062,  0.9727, -1.7109, -3.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -2.6562, -1.1094,  2.9219,  3.3906]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -2.6562, -1.1094,  2.9219,  3.3906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2500, -1.9922, -0.3984,  2.2344,  2.3125]], dtype=torch.bfloat16))]), logits=tensor([[-3.2500, -1.9922, -0.3984,  2.2344,  2.3125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.4609,  1.3281,  1.9844,  0.3066, -2.4219]], dtype=torch.bfloat16))]), logits=tensor([[-1.4609,  1.3281,  1.9844,  0.3066, -2.4219]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6875, -2.6094, -0.6758,  3.0781,  2.8750]], dtype=torch.bfloat16))]), logits=tensor([[-3.6875, -2.6094, -0.6758,  3.0781,  2.8750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.8438,  1.4062, -0.4434, -1.8984, -1.7188]], dtype=torch.bfloat16))]), logits=tensor([[ 3.8438,  1.4062, -0.4434, -1.8984, -1.7188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2969, -1.0781,  1.0625,  2.3750,  0.2793]], dtype=torch.bfloat16))]), logits=tensor([[-3.2969, -1.0781,  1.0625,  2.3750,  0.2793]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.0625,  0.8242,  2.3594,  0.8242, -2.3281]], dtype=torch.bfloat16))]), logits=tensor([[-2.0625,  0.8242,  2.3594,  0.8242, -2.3281]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1719, -3.1094, -2.2812,  2.6406,  4.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.1719, -3.1094, -2.2812,  2.6406,  4.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7344, -3.0469, -1.2656,  3.2656,  3.7188]], dtype=torch.bfloat16))]), logits=tensor([[-3.7344, -3.0469, -1.2656,  3.2656,  3.7188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0938, -2.9219, -2.3438,  2.3594,  4.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.0938, -2.9219, -2.3438,  2.3594,  4.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5625, -2.7969, -1.3672,  2.5938,  3.7969]], dtype=torch.bfloat16))]), logits=tensor([[-3.5625, -2.7969, -1.3672,  2.5938,  3.7969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -3.1406, -1.4219,  3.3125,  4.0000]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -3.1406, -1.4219,  3.3125,  4.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.1406, -0.1416,  2.9062,  2.1562]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.1406, -0.1416,  2.9062,  2.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9219, -2.9531, -2.3906,  2.2031,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.9219, -2.9531, -2.3906,  2.2031,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.4902,  1.9375,  2.0938, -0.1719, -3.0312]], dtype=torch.bfloat16))]), logits=tensor([[-0.4902,  1.9375,  2.0938, -0.1719, -3.0312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7344, -2.6875, -1.1016,  2.9844,  3.3906]], dtype=torch.bfloat16))]), logits=tensor([[-3.7344, -2.6875, -1.1016,  2.9844,  3.3906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0156, -0.8438,  0.7734,  1.7812,  0.4414]], dtype=torch.bfloat16))]), logits=tensor([[-3.0156, -0.8438,  0.7734,  1.7812,  0.4414]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4688, -1.3359,  1.1719,  2.5781,  0.4102]], dtype=torch.bfloat16))]), logits=tensor([[-3.4688, -1.3359,  1.1719,  2.5781,  0.4102]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8594, -2.6094, -0.6875,  3.1094,  2.9375]], dtype=torch.bfloat16))]), logits=tensor([[-3.8594, -2.6094, -0.6875,  3.1094,  2.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3438, -3.1094, -2.0781,  2.8125,  4.6250]], dtype=torch.bfloat16))]), logits=tensor([[-3.3438, -3.1094, -2.0781,  2.8125,  4.6250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2344, -0.8945,  1.7422,  2.1406, -0.3496]], dtype=torch.bfloat16))]), logits=tensor([[-3.2344, -0.8945,  1.7422,  2.1406, -0.3496]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.1016,  2.3750,  1.5312, -1.2656, -3.2656]], dtype=torch.bfloat16))]), logits=tensor([[ 1.1016,  2.3750,  1.5312, -1.2656, -3.2656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.2188,  2.3438,  0.2988, -2.1719, -2.7500]], dtype=torch.bfloat16))]), logits=tensor([[ 3.2188,  2.3438,  0.2988, -2.1719, -2.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.4219,  2.2031,  0.5352, -1.7500, -2.6562]], dtype=torch.bfloat16))]), logits=tensor([[ 2.4219,  2.2031,  0.5352, -1.7500, -2.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8906, -3.0312, -2.4219,  2.3125,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.8906, -3.0312, -2.4219,  2.3125,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.8594,  2.0938, -0.1367, -2.2188, -2.4062]], dtype=torch.bfloat16))]), logits=tensor([[ 3.8594,  2.0938, -0.1367, -2.2188, -2.4062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5156, -1.4688,  0.9844,  2.7812,  0.5195]], dtype=torch.bfloat16))]), logits=tensor([[-3.5156, -1.4688,  0.9844,  2.7812,  0.5195]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9688, -2.4531, -1.8828,  2.0156,  4.0938]], dtype=torch.bfloat16))]), logits=tensor([[-2.9688, -2.4531, -1.8828,  2.0156,  4.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6875, -2.6719, -1.1953,  2.8594,  3.4844]], dtype=torch.bfloat16))]), logits=tensor([[-3.6875, -2.6719, -1.1953,  2.8594,  3.4844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.6172,  2.1094,  0.8789, -1.3672, -2.6406]], dtype=torch.bfloat16))]), logits=tensor([[ 1.6172,  2.1094,  0.8789, -1.3672, -2.6406]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.9688,  2.1719, -0.0913, -2.3125, -2.5469]], dtype=torch.bfloat16))]), logits=tensor([[ 3.9688,  2.1719, -0.0913, -2.3125, -2.5469]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -2.1719, -0.5508,  2.7500,  2.4531]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -2.1719, -0.5508,  2.7500,  2.4531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1562, -3.0469, -2.2188,  2.6875,  4.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.1562, -3.0469, -2.2188,  2.6875,  4.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5000, -2.4688, -0.7617,  2.7656,  2.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.5000, -2.4688, -0.7617,  2.7656,  2.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.7852,  1.9688,  1.1094, -0.9141, -2.5156]], dtype=torch.bfloat16))]), logits=tensor([[ 0.7852,  1.9688,  1.1094, -0.9141, -2.5156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3438, -1.2109,  1.2422,  2.5938,  0.1533]], dtype=torch.bfloat16))]), logits=tensor([[-3.3438, -1.2109,  1.2422,  2.5938,  0.1533]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8438, -2.5625, -0.4336,  3.3281,  2.5781]], dtype=torch.bfloat16))]), logits=tensor([[-3.8438, -2.5625, -0.4336,  3.3281,  2.5781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1406, -2.9844, -2.2812,  2.4062,  4.9375]], dtype=torch.bfloat16))]), logits=tensor([[-3.1406, -2.9844, -2.2812,  2.4062,  4.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.9688,  1.2578, -0.4902, -1.8984, -1.6719]], dtype=torch.bfloat16))]), logits=tensor([[ 3.9688,  1.2578, -0.4902, -1.8984, -1.6719]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8125, -2.6719, -2.0312,  1.9609,  4.4062]], dtype=torch.bfloat16))]), logits=tensor([[-2.8125, -2.6719, -2.0312,  1.9609,  4.4062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -2.3594, -0.8516,  2.7969,  2.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -2.3594, -0.8516,  2.7969,  2.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6406, -2.6875, -0.5859,  3.3438,  2.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.6406, -2.6875, -0.5859,  3.3438,  2.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5625, -1.4141,  0.7930,  2.7500,  0.7148]], dtype=torch.bfloat16))]), logits=tensor([[-3.5625, -1.4141,  0.7930,  2.7500,  0.7148]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5156, -1.3984,  1.0781,  2.7500,  0.4551]], dtype=torch.bfloat16))]), logits=tensor([[-3.5156, -1.3984,  1.0781,  2.7500,  0.4551]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6406, -2.8594, -2.4531,  1.9766,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.6406, -2.8594, -2.4531,  1.9766,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.2031,  1.5938,  2.2656,  0.1982, -2.9219]], dtype=torch.bfloat16))]), logits=tensor([[-1.2031,  1.5938,  2.2656,  0.1982, -2.9219]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6562, -1.8359,  0.6758,  2.9688,  1.2031]], dtype=torch.bfloat16))]), logits=tensor([[-3.6562, -1.8359,  0.6758,  2.9688,  1.2031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.1094,  2.3125,  1.4375, -1.1719, -3.1406]], dtype=torch.bfloat16))]), logits=tensor([[ 1.1094,  2.3125,  1.4375, -1.1719, -3.1406]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7656e+00, -1.8997e-03,  1.8281e+00,  1.5391e+00, -1.1797e+00]],\n",
       "        dtype=torch.bfloat16))]), logits=tensor([[-2.7656e+00, -1.8997e-03,  1.8281e+00,  1.5391e+00, -1.1797e+00]],\n",
       "        dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -1.7422,  0.5430,  2.8750,  1.1328]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -1.7422,  0.5430,  2.8750,  1.1328]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0938, -0.9414,  0.6406,  1.8125,  0.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.0938, -0.9414,  0.6406,  1.8125,  0.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6875, -1.5000,  0.9219,  2.8438,  0.7344]], dtype=torch.bfloat16))]), logits=tensor([[-3.6875, -1.5000,  0.9219,  2.8438,  0.7344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4531, -2.6406, -1.3359,  2.5938,  3.6875]], dtype=torch.bfloat16))]), logits=tensor([[-3.4531, -2.6406, -1.3359,  2.5938,  3.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0312, -0.9883,  0.9648,  2.1562,  0.1221]], dtype=torch.bfloat16))]), logits=tensor([[-3.0312, -0.9883,  0.9648,  2.1562,  0.1221]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1875, -3.1562, -2.2500,  2.7188,  4.8750]], dtype=torch.bfloat16))]), logits=tensor([[-3.1875, -3.1562, -2.2500,  2.7188,  4.8750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2656, -3.1562, -2.2500,  2.6875,  4.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.2656, -3.1562, -2.2500,  2.6875,  4.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.5938,  2.1562,  0.3672, -1.8203, -2.5469]], dtype=torch.bfloat16))]), logits=tensor([[ 2.5938,  2.1562,  0.3672, -1.8203, -2.5469]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6094, -3.0156, -1.2578,  3.2031,  3.6406]], dtype=torch.bfloat16))]), logits=tensor([[-3.6094, -3.0156, -1.2578,  3.2031,  3.6406]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0312, -1.0312,  0.5000,  2.1250,  0.5820]], dtype=torch.bfloat16))]), logits=tensor([[-3.0312, -1.0312,  0.5000,  2.1250,  0.5820]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4531, -2.9375, -1.6094,  2.8906,  3.9531]], dtype=torch.bfloat16))]), logits=tensor([[-3.4531, -2.9375, -1.6094,  2.8906,  3.9531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.1089,  2.1094,  1.7969, -0.6211, -2.9844]], dtype=torch.bfloat16))]), logits=tensor([[ 0.1089,  2.1094,  1.7969, -0.6211, -2.9844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.4375,  0.6914,  2.0938,  0.3574, -2.2656]], dtype=torch.bfloat16))]), logits=tensor([[-1.4375,  0.6914,  2.0938,  0.3574, -2.2656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8438, -2.2031,  0.3555,  3.2969,  1.7109]], dtype=torch.bfloat16))]), logits=tensor([[-3.8438, -2.2031,  0.3555,  3.2969,  1.7109]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1406, -3.0000, -2.0000,  2.4219,  4.8438]], dtype=torch.bfloat16))]), logits=tensor([[-3.1406, -3.0000, -2.0000,  2.4219,  4.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2500, -2.6875, -1.7734,  2.2344,  4.2812]], dtype=torch.bfloat16))]), logits=tensor([[-3.2500, -2.6875, -1.7734,  2.2344,  4.2812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8594, -3.0156, -2.3594,  2.3125,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-2.8594, -3.0156, -2.3594,  2.3125,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.0781,  2.3906,  0.4023, -2.0781, -2.8438]], dtype=torch.bfloat16))]), logits=tensor([[ 3.0781,  2.3906,  0.4023, -2.0781, -2.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6250, -2.9531, -1.5469,  3.1250,  3.9219]], dtype=torch.bfloat16))]), logits=tensor([[-3.6250, -2.9531, -1.5469,  3.1250,  3.9219]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.9375,  0.8984,  2.0156,  0.7773, -2.0938]], dtype=torch.bfloat16))]), logits=tensor([[-1.9375,  0.8984,  2.0156,  0.7773, -2.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -1.4688,  0.7852,  2.5781,  0.8867]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -1.4688,  0.7852,  2.5781,  0.8867]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -2.5781, -1.0547,  2.7969,  3.2500]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -2.5781, -1.0547,  2.7969,  3.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8750, -3.0312, -2.4375,  2.2969,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.8750, -3.0312, -2.4375,  2.2969,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4688, -2.8438, -2.4844,  1.8672,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.4688, -2.8438, -2.4844,  1.8672,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8438, -2.9062, -2.4062,  2.1094,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.8438, -2.9062, -2.4062,  2.1094,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5938, -2.6719, -0.9922,  2.8594,  3.2656]], dtype=torch.bfloat16))]), logits=tensor([[-3.5938, -2.6719, -0.9922,  2.8594,  3.2656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5938, -2.9062, -2.4844,  2.0000,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.5938, -2.9062, -2.4844,  2.0000,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2969, -0.8906,  1.2422,  2.3750, -0.0742]], dtype=torch.bfloat16))]), logits=tensor([[-3.2969, -0.8906,  1.2422,  2.3750, -0.0742]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1875, -3.0469, -2.1875,  2.6719,  4.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.1875, -3.0469, -2.1875,  2.6719,  4.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0469, -0.5430,  1.7031,  2.1250, -0.8008]], dtype=torch.bfloat16))]), logits=tensor([[-3.0469, -0.5430,  1.7031,  2.1250, -0.8008]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.9297,  2.0312,  1.1641, -0.9648, -2.7031]], dtype=torch.bfloat16))]), logits=tensor([[ 0.9297,  2.0312,  1.1641, -0.9648, -2.7031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8750, -2.4688, -0.4746,  3.0312,  2.7188]], dtype=torch.bfloat16))]), logits=tensor([[-3.8750, -2.4688, -0.4746,  3.0312,  2.7188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.6875,  1.1875,  2.1094,  0.5898, -2.3906]], dtype=torch.bfloat16))]), logits=tensor([[-1.6875,  1.1875,  2.1094,  0.5898, -2.3906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9062, -3.0000, -2.3594,  2.2500,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.9062, -3.0000, -2.3594,  2.2500,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7969, -2.6562, -0.6719,  3.2656,  2.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.7969, -2.6562, -0.6719,  3.2656,  2.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4219, -2.8125, -2.5000,  1.8359,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.4219, -2.8125, -2.5000,  1.8359,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0312, -3.0469, -2.3594,  2.4062,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-3.0312, -3.0469, -2.3594,  2.4062,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5000, -1.6719,  0.8320,  2.9375,  0.8555]], dtype=torch.bfloat16))]), logits=tensor([[-3.5000, -1.6719,  0.8320,  2.9375,  0.8555]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1406, -2.6094, -1.8750,  2.2031,  4.2500]], dtype=torch.bfloat16))]), logits=tensor([[-3.1406, -2.6094, -1.8750,  2.2031,  4.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8281, -2.9844, -2.4531,  2.2031,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.8281, -2.9844, -2.4531,  2.2031,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -1.5000,  0.9570,  2.7969,  0.6641]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -1.5000,  0.9570,  2.7969,  0.6641]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3750, -1.3203,  0.4707,  2.3906,  0.9805]], dtype=torch.bfloat16))]), logits=tensor([[-3.3750, -1.3203,  0.4707,  2.3906,  0.9805]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2031, -2.9844, -2.1250,  2.5000,  4.7188]], dtype=torch.bfloat16))]), logits=tensor([[-3.2031, -2.9844, -2.1250,  2.5000,  4.7188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7031, -2.6719, -1.0156,  3.0781,  3.2344]], dtype=torch.bfloat16))]), logits=tensor([[-3.7031, -2.6719, -1.0156,  3.0781,  3.2344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9375, -0.8711,  0.8359,  2.0469,  0.1572]], dtype=torch.bfloat16))]), logits=tensor([[-2.9375, -0.8711,  0.8359,  2.0469,  0.1572]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7969, -0.1602,  1.4453,  1.4062, -0.5938]], dtype=torch.bfloat16))]), logits=tensor([[-2.7969, -0.1602,  1.4453,  1.4062, -0.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9375, -3.0469, -2.3750,  2.3594,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-2.9375, -3.0469, -2.3750,  2.3594,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.8594,  1.1406,  2.3594,  0.6797, -2.5938]], dtype=torch.bfloat16))]), logits=tensor([[-1.8594,  1.1406,  2.3594,  0.6797, -2.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2188, -1.7578, -0.5859,  2.0469,  2.4375]], dtype=torch.bfloat16))]), logits=tensor([[-3.2188, -1.7578, -0.5859,  2.0469,  2.4375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.0312,  2.4219,  0.4570, -2.0781, -2.8594]], dtype=torch.bfloat16))]), logits=tensor([[ 3.0312,  2.4219,  0.4570, -2.0781, -2.8594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.3438,  0.4727,  1.9375,  1.1641, -1.7266]], dtype=torch.bfloat16))]), logits=tensor([[-2.3438,  0.4727,  1.9375,  1.1641, -1.7266]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -2.1094,  0.1748,  3.1250,  1.7656]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -2.1094,  0.1748,  3.1250,  1.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5156, -2.8281, -2.4688,  1.8906,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.5156, -2.8281, -2.4688,  1.8906,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9219, -3.0781, -2.4062,  2.3906,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.9219, -3.0781, -2.4062,  2.3906,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4688, -1.3828,  0.6680,  2.4531,  0.9297]], dtype=torch.bfloat16))]), logits=tensor([[-3.4688, -1.3828,  0.6680,  2.4531,  0.9297]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.8672,  1.1641,  2.3594,  0.6250, -2.5781]], dtype=torch.bfloat16))]), logits=tensor([[-1.8672,  1.1641,  2.3594,  0.6250, -2.5781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1875, -3.0625, -2.2500,  2.6250,  4.7812]], dtype=torch.bfloat16))]), logits=tensor([[-3.1875, -3.0625, -2.2500,  2.6250,  4.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4219, -2.8906, -2.5156,  1.9062,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.4219, -2.8906, -2.5156,  1.9062,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.4531, -0.4258,  3.2188,  2.5156]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.4531, -0.4258,  3.2188,  2.5156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1562, -3.1562, -2.2188,  2.7344,  4.8438]], dtype=torch.bfloat16))]), logits=tensor([[-3.1562, -3.1562, -2.2188,  2.7344,  4.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7031, -2.4844, -0.7617,  3.0312,  2.8906]], dtype=torch.bfloat16))]), logits=tensor([[-3.7031, -2.4844, -0.7617,  3.0312,  2.8906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7031, -1.7188,  0.6953,  2.8281,  1.1953]], dtype=torch.bfloat16))]), logits=tensor([[-3.7031, -1.7188,  0.6953,  2.8281,  1.1953]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -1.8125,  0.7070,  2.9062,  1.1172]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -1.8125,  0.7070,  2.9062,  1.1172]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.9062,  2.1094,  0.2139, -1.9219, -2.4688]], dtype=torch.bfloat16))]), logits=tensor([[ 2.9062,  2.1094,  0.2139, -1.9219, -2.4688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8906, -2.9844, -2.4062,  2.2500,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.8906, -2.9844, -2.4062,  2.2500,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9688, -3.0625, -2.4062,  2.3906,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.9688, -3.0625, -2.4062,  2.3906,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8750, -0.2305,  1.1797,  1.3438, -0.1855]], dtype=torch.bfloat16))]), logits=tensor([[-2.8750, -0.2305,  1.1797,  1.3438, -0.1855]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7969, -2.6875, -0.5781,  3.1875,  2.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.7969, -2.6875, -0.5781,  3.1875,  2.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8125, -1.9141,  0.3750,  3.0469,  1.4688]], dtype=torch.bfloat16))]), logits=tensor([[-3.8125, -1.9141,  0.3750,  3.0469,  1.4688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3906, -1.9766, -0.6914,  2.0469,  2.7969]], dtype=torch.bfloat16))]), logits=tensor([[-3.3906, -1.9766, -0.6914,  2.0469,  2.7969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7031, -0.7734,  0.2520,  1.5391,  0.8242]], dtype=torch.bfloat16))]), logits=tensor([[-2.7031, -0.7734,  0.2520,  1.5391,  0.8242]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2188, -1.0625,  0.9922,  2.3906,  0.2285]], dtype=torch.bfloat16))]), logits=tensor([[-3.2188, -1.0625,  0.9922,  2.3906,  0.2285]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4219, -3.0625, -1.9375,  2.9219,  4.4062]], dtype=torch.bfloat16))]), logits=tensor([[-3.4219, -3.0625, -1.9375,  2.9219,  4.4062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.0234,  2.0156,  1.0859, -1.0078, -2.6719]], dtype=torch.bfloat16))]), logits=tensor([[ 1.0234,  2.0156,  1.0859, -1.0078, -2.6719]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.2539,  1.2266,  0.9258, -0.2490, -1.8984]], dtype=torch.bfloat16))]), logits=tensor([[-0.2539,  1.2266,  0.9258, -0.2490, -1.8984]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.5469, -0.4648,  3.2344,  2.5781]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.5469, -0.4648,  3.2344,  2.5781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -2.9375, -1.7500,  2.8594,  4.2500]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -2.9375, -1.7500,  2.8594,  4.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.5156,  2.3750,  0.2324, -2.2500, -2.7812]], dtype=torch.bfloat16))]), logits=tensor([[ 3.5156,  2.3750,  0.2324, -2.2500, -2.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -1.8594,  0.3789,  2.8438,  1.4141]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -1.8594,  0.3789,  2.8438,  1.4141]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7812, -2.2188,  0.2266,  3.2656,  1.7656]], dtype=torch.bfloat16))]), logits=tensor([[-3.7812, -2.2188,  0.2266,  3.2656,  1.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2188, -3.1094, -2.1562,  2.5781,  4.8438]], dtype=torch.bfloat16))]), logits=tensor([[-3.2188, -3.1094, -2.1562,  2.5781,  4.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7188, -2.8281, -1.2578,  3.0000,  3.6719]], dtype=torch.bfloat16))]), logits=tensor([[-3.7188, -2.8281, -1.2578,  3.0000,  3.6719]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6719, -2.4531, -0.5859,  2.7344,  2.8125]], dtype=torch.bfloat16))]), logits=tensor([[-3.6719, -2.4531, -0.5859,  2.7344,  2.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6719, -1.7969,  0.4316,  2.8906,  1.2969]], dtype=torch.bfloat16))]), logits=tensor([[-3.6719, -1.7969,  0.4316,  2.8906,  1.2969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.8906,  2.0625, -0.1895, -2.2500, -2.4219]], dtype=torch.bfloat16))]), logits=tensor([[ 3.8906,  2.0625, -0.1895, -2.2500, -2.4219]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.9141,  0.5234,  1.1719,  0.8086, -1.0703]], dtype=torch.bfloat16))]), logits=tensor([[-1.9141,  0.5234,  1.1719,  0.8086, -1.0703]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.8867,  1.2812,  1.3672, -0.0033, -1.8672]], dtype=torch.bfloat16))]), logits=tensor([[-0.8867,  1.2812,  1.3672, -0.0033, -1.8672]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2656, -0.9102,  1.3984,  2.3438, -0.2305]], dtype=torch.bfloat16))]), logits=tensor([[-3.2656, -0.9102,  1.3984,  2.3438, -0.2305]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.0625,  2.3125,  0.9297, -1.6406, -2.9062]], dtype=torch.bfloat16))]), logits=tensor([[ 2.0625,  2.3125,  0.9297, -1.6406, -2.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3281, -3.1562, -1.9531,  2.6875,  4.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.3281, -3.1562, -1.9531,  2.6875,  4.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5938, -2.8438, -1.4922,  2.7344,  3.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.5938, -2.8438, -1.4922,  2.7344,  3.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7812, -2.3438, -0.3750,  2.9844,  2.5312]], dtype=torch.bfloat16))]), logits=tensor([[-3.7812, -2.3438, -0.3750,  2.9844,  2.5312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.8984,  0.9258,  1.9844,  0.7227, -2.1250]], dtype=torch.bfloat16))]), logits=tensor([[-1.8984,  0.9258,  1.9844,  0.7227, -2.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.9688,  1.4297, -0.4395, -1.9531, -1.7891]], dtype=torch.bfloat16))]), logits=tensor([[ 3.9688,  1.4297, -0.4395, -1.9531, -1.7891]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9062, -2.9844, -2.4062,  2.2344,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.9062, -2.9844, -2.4062,  2.2344,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5312, -2.8438, -2.4531,  1.9062,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.5312, -2.8438, -2.4531,  1.9062,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9688, -3.0469, -2.3750,  2.3750,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-2.9688, -3.0469, -2.3750,  2.3750,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.9688,  2.3281,  1.4922, -1.2109, -3.1875]], dtype=torch.bfloat16))]), logits=tensor([[ 0.9688,  2.3281,  1.4922, -1.2109, -3.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7969, -2.9844, -2.4219,  2.2031,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.7969, -2.9844, -2.4219,  2.2031,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.7656,  2.2812,  0.5117, -1.9219, -2.7656]], dtype=torch.bfloat16))]), logits=tensor([[ 2.7656,  2.2812,  0.5117, -1.9219, -2.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -2.3438, -0.8398,  2.7500,  2.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -2.3438, -0.8398,  2.7500,  2.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -3.0312, -0.9570,  3.5625,  3.3281]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -3.0312, -0.9570,  3.5625,  3.3281]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8750, -0.1328,  1.8438,  1.6172, -1.0547]], dtype=torch.bfloat16))]), logits=tensor([[-2.8750, -0.1328,  1.8438,  1.6172, -1.0547]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.5312,  0.6445,  1.0156,  0.4863, -1.0703]], dtype=torch.bfloat16))]), logits=tensor([[-1.5312,  0.6445,  1.0156,  0.4863, -1.0703]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.0781,  2.1406,  0.6758, -1.5625, -2.7344]], dtype=torch.bfloat16))]), logits=tensor([[ 2.0781,  2.1406,  0.6758, -1.5625, -2.7344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7188, -2.8438, -2.4844,  2.0312,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.7188, -2.8438, -2.4844,  2.0312,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.9180,  1.1094, -0.1050, -0.8711, -1.1641]], dtype=torch.bfloat16))]), logits=tensor([[ 0.9180,  1.1094, -0.1050, -0.8711, -1.1641]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.3125,  0.2471,  1.4219,  1.1719, -1.0938]], dtype=torch.bfloat16))]), logits=tensor([[-2.3125,  0.2471,  1.4219,  1.1719, -1.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6719, -1.6953,  0.7148,  2.9531,  0.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.6719, -1.6953,  0.7148,  2.9531,  0.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1562, -3.0469, -2.2344,  2.5156,  4.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.1562, -3.0469, -2.2344,  2.5156,  4.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7344, -2.9219, -2.4375,  2.0156,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.7344, -2.9219, -2.4375,  2.0156,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1406, -3.1250, -2.3281,  2.6250,  5.0312]], dtype=torch.bfloat16))]), logits=tensor([[-3.1406, -3.1250, -2.3281,  2.6250,  5.0312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.9766,  0.7500,  2.3438,  0.7891, -2.3125]], dtype=torch.bfloat16))]), logits=tensor([[-1.9766,  0.7500,  2.3438,  0.7891, -2.3125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6250, -0.0408,  1.8281,  1.5859, -1.2969]], dtype=torch.bfloat16))]), logits=tensor([[-2.6250, -0.0408,  1.8281,  1.5859, -1.2969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.8906,  1.2031, -0.5156, -1.8359, -1.6172]], dtype=torch.bfloat16))]), logits=tensor([[ 3.8906,  1.2031, -0.5156, -1.8359, -1.6172]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.5156,  2.3281,  0.1318, -2.2344, -2.7031]], dtype=torch.bfloat16))]), logits=tensor([[ 3.5156,  2.3281,  0.1318, -2.2344, -2.7031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3438, -2.9219, -1.9453,  2.7812,  4.3438]], dtype=torch.bfloat16))]), logits=tensor([[-3.3438, -2.9219, -1.9453,  2.7812,  4.3438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9219, -3.0625, -2.4062,  2.3750,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.9219, -3.0625, -2.4062,  2.3750,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6250, -2.8750, -2.4844,  2.0000,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.6250, -2.8750, -2.4844,  2.0000,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4844, -3.1250, -1.9219,  2.8750,  4.5312]], dtype=torch.bfloat16))]), logits=tensor([[-3.4844, -3.1250, -1.9219,  2.8750,  4.5312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8438, -2.5625, -0.3164,  3.4219,  2.4688]], dtype=torch.bfloat16))]), logits=tensor([[-3.8438, -2.5625, -0.3164,  3.4219,  2.4688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -3.1406, -1.7812,  3.0469,  4.2500]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -3.1406, -1.7812,  3.0469,  4.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.5156,  2.3281,  0.6641, -1.8438, -2.8438]], dtype=torch.bfloat16))]), logits=tensor([[ 2.5156,  2.3281,  0.6641, -1.8438, -2.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.9219,  1.1875, -0.5078, -1.8516, -1.6250]], dtype=torch.bfloat16))]), logits=tensor([[ 3.9219,  1.1875, -0.5078, -1.8516, -1.6250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4531, -2.7812, -0.8945,  2.9844,  3.1250]], dtype=torch.bfloat16))]), logits=tensor([[-3.4531, -2.7812, -0.8945,  2.9844,  3.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -2.9375, -1.1094,  3.2656,  3.5000]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -2.9375, -1.1094,  3.2656,  3.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3906, -3.2344, -1.9219,  3.1250,  4.5312]], dtype=torch.bfloat16))]), logits=tensor([[-3.3906, -3.2344, -1.9219,  3.1250,  4.5312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -2.7656, -0.5625,  3.4219,  2.7969]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -2.7656, -0.5625,  3.4219,  2.7969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.0703,  2.2031,  1.3047, -1.1406, -3.0000]], dtype=torch.bfloat16))]), logits=tensor([[ 1.0703,  2.2031,  1.3047, -1.1406, -3.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.3438, -2.6406, -2.3125,  1.6875,  4.9062]], dtype=torch.bfloat16))]), logits=tensor([[-2.3438, -2.6406, -2.3125,  1.6875,  4.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7031, -2.9531, -2.4844,  2.1094,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.7031, -2.9531, -2.4844,  2.1094,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0469, -2.8438, -1.9375,  2.2969,  4.5000]], dtype=torch.bfloat16))]), logits=tensor([[-3.0469, -2.8438, -1.9375,  2.2969,  4.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2188, -2.8594, -1.8047,  2.5938,  4.1875]], dtype=torch.bfloat16))]), logits=tensor([[-3.2188, -2.8594, -1.8047,  2.5938,  4.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5000, -1.3828,  1.1016,  2.7969,  0.3926]], dtype=torch.bfloat16))]), logits=tensor([[-3.5000, -1.3828,  1.1016,  2.7969,  0.3926]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -3.0625, -1.8906,  2.8750,  4.4062]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -3.0625, -1.8906,  2.8750,  4.4062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.3125,  0.4199,  2.0469,  1.0938, -1.7578]], dtype=torch.bfloat16))]), logits=tensor([[-2.3125,  0.4199,  2.0469,  1.0938, -1.7578]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6250, -1.7500,  0.8750,  2.9844,  0.8516]], dtype=torch.bfloat16))]), logits=tensor([[-3.6250, -1.7500,  0.8750,  2.9844,  0.8516]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3438, -3.0625, -1.9219,  2.8125,  4.3438]], dtype=torch.bfloat16))]), logits=tensor([[-3.3438, -3.0625, -1.9219,  2.8125,  4.3438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -2.9375, -1.5156,  2.8594,  3.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -2.9375, -1.5156,  2.8594,  3.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.1157,  1.3203,  0.6055, -0.5664, -1.5938]], dtype=torch.bfloat16))]), logits=tensor([[ 0.1157,  1.3203,  0.6055, -0.5664, -1.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8906, -2.3906, -0.4609,  3.0625,  2.6562]], dtype=torch.bfloat16))]), logits=tensor([[-3.8906, -2.3906, -0.4609,  3.0625,  2.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.4453,  1.2500,  1.8672,  0.4609, -2.3281]], dtype=torch.bfloat16))]), logits=tensor([[-1.4453,  1.2500,  1.8672,  0.4609, -2.3281]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6562, -2.9531, -2.4531,  2.1250,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.6562, -2.9531, -2.4531,  2.1250,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5469, -2.7188, -1.1875,  2.9375,  3.3750]], dtype=torch.bfloat16))]), logits=tensor([[-3.5469, -2.7188, -1.1875,  2.9375,  3.3750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3438, -3.1406, -2.1094,  2.8281,  4.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.3438, -3.1406, -2.1094,  2.8281,  4.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2500, -2.9375, -2.0312,  2.4531,  4.5625]], dtype=torch.bfloat16))]), logits=tensor([[-3.2500, -2.9375, -2.0312,  2.4531,  4.5625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6094, -1.3984,  0.8867,  2.6562,  0.7578]], dtype=torch.bfloat16))]), logits=tensor([[-3.6094, -1.3984,  0.8867,  2.6562,  0.7578]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.2188,  2.4062,  0.3887, -2.1406, -2.8594]], dtype=torch.bfloat16))]), logits=tensor([[ 3.2188,  2.4062,  0.3887, -2.1406, -2.8594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.2500,  0.6094,  1.7812,  0.9414, -1.5312]], dtype=torch.bfloat16))]), logits=tensor([[-2.2500,  0.6094,  1.7812,  0.9414, -1.5312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.6875,  2.2031,  0.0056, -2.2344, -2.5625]], dtype=torch.bfloat16))]), logits=tensor([[ 3.6875,  2.2031,  0.0056, -2.2344, -2.5625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.3281,  0.2441,  1.4062,  0.9961, -0.9531]], dtype=torch.bfloat16))]), logits=tensor([[-2.3281,  0.2441,  1.4062,  0.9961, -0.9531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6719, -2.6094, -0.7969,  2.8438,  3.0156]], dtype=torch.bfloat16))]), logits=tensor([[-3.6719, -2.6094, -0.7969,  2.8438,  3.0156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1094, -1.9922, -1.1094,  1.8594,  3.1719]], dtype=torch.bfloat16))]), logits=tensor([[-3.1094, -1.9922, -1.1094,  1.8594,  3.1719]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.4531,  1.2969,  2.0469,  0.3457, -2.4688]], dtype=torch.bfloat16))]), logits=tensor([[-1.4531,  1.2969,  2.0469,  0.3457, -2.4688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7812, -2.5000, -0.7461,  2.9688,  2.8906]], dtype=torch.bfloat16))]), logits=tensor([[-3.7812, -2.5000, -0.7461,  2.9688,  2.8906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1406, -1.8281, -0.7070,  1.8047,  2.5938]], dtype=torch.bfloat16))]), logits=tensor([[-3.1406, -1.8281, -0.7070,  1.8047,  2.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9062, -0.6758,  0.9805,  1.9453, -0.0332]], dtype=torch.bfloat16))]), logits=tensor([[-2.9062, -0.6758,  0.9805,  1.9453, -0.0332]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.9453,  1.0859,  2.2656,  0.5938, -2.3750]], dtype=torch.bfloat16))]), logits=tensor([[-1.9453,  1.0859,  2.2656,  0.5938, -2.3750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.2559,  2.0938,  2.1094, -0.3945, -3.2500]], dtype=torch.bfloat16))]), logits=tensor([[-0.2559,  2.0938,  2.1094, -0.3945, -3.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.4609,  0.7227,  0.9961,  0.5078, -1.2344]], dtype=torch.bfloat16))]), logits=tensor([[-1.4609,  0.7227,  0.9961,  0.5078, -1.2344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1094, -3.0781, -2.2812,  2.4688,  5.0938]], dtype=torch.bfloat16))]), logits=tensor([[-3.1094, -3.0781, -2.2812,  2.4688,  5.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.1904,  2.0469,  1.9453, -0.4316, -3.0312]], dtype=torch.bfloat16))]), logits=tensor([[-0.1904,  2.0469,  1.9453, -0.4316, -3.0312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -3.0938, -1.5469,  3.1875,  4.0938]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -3.0938, -1.5469,  3.1875,  4.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7656, -0.4941,  1.0781,  1.7969, -0.2969]], dtype=torch.bfloat16))]), logits=tensor([[-2.7656, -0.4941,  1.0781,  1.7969, -0.2969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4688, -1.7734,  0.0258,  2.3750,  1.8594]], dtype=torch.bfloat16))]), logits=tensor([[-3.4688, -1.7734,  0.0258,  2.3750,  1.8594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2812, -1.4609,  0.7070,  2.6875,  0.6914]], dtype=torch.bfloat16))]), logits=tensor([[-3.2812, -1.4609,  0.7070,  2.6875,  0.6914]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.4375,  2.3906,  0.2256, -2.2188, -2.7969]], dtype=torch.bfloat16))]), logits=tensor([[ 3.4375,  2.3906,  0.2256, -2.2188, -2.7969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.8906,  2.3750,  0.4512, -2.0469, -2.8281]], dtype=torch.bfloat16))]), logits=tensor([[ 2.8906,  2.3750,  0.4512, -2.0469, -2.8281]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7812, -3.0781, -1.3906,  3.2969,  3.8906]], dtype=torch.bfloat16))]), logits=tensor([[-3.7812, -3.0781, -1.3906,  3.2969,  3.8906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7812, -2.5000, -0.6289,  3.1250,  2.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.7812, -2.5000, -0.6289,  3.1250,  2.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7969, -2.9062, -2.3750,  2.0938,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.7969, -2.9062, -2.3750,  2.0938,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 4.0938,  1.7344, -0.3301, -2.1406, -2.1250]], dtype=torch.bfloat16))]), logits=tensor([[ 4.0938,  1.7344, -0.3301, -2.1406, -2.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.6250,  0.9219, -0.5586, -1.6406, -1.3594]], dtype=torch.bfloat16))]), logits=tensor([[ 3.6250,  0.9219, -0.5586, -1.6406, -1.3594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.1016,  1.5781,  2.0312,  0.1396, -2.6562]], dtype=torch.bfloat16))]), logits=tensor([[-1.1016,  1.5781,  2.0312,  0.1396, -2.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -2.9844, -1.7031,  2.9375,  4.1250]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -2.9844, -1.7031,  2.9375,  4.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9531, -2.9531, -2.3906,  2.2969,  5.0938]], dtype=torch.bfloat16))]), logits=tensor([[-2.9531, -2.9531, -2.3906,  2.2969,  5.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6562, -2.1562, -0.3086,  2.9844,  2.2344]], dtype=torch.bfloat16))]), logits=tensor([[-3.6562, -2.1562, -0.3086,  2.9844,  2.2344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0000, -2.9531, -2.3750,  2.2500,  5.0938]], dtype=torch.bfloat16))]), logits=tensor([[-3.0000, -2.9531, -2.3750,  2.2500,  5.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.1406,  1.8516,  2.5000, -0.1157, -3.2344]], dtype=torch.bfloat16))]), logits=tensor([[-1.1406,  1.8516,  2.5000, -0.1157, -3.2344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5938, -2.3594, -0.5625,  2.8750,  2.6250]], dtype=torch.bfloat16))]), logits=tensor([[-3.5938, -2.3594, -0.5625,  2.8750,  2.6250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6406, -0.2910,  1.6094,  1.7031, -0.9258]], dtype=torch.bfloat16))]), logits=tensor([[-2.6406, -0.2910,  1.6094,  1.7031, -0.9258]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4688, -2.0312, -0.7617,  2.4531,  2.6875]], dtype=torch.bfloat16))]), logits=tensor([[-3.4688, -2.0312, -0.7617,  2.4531,  2.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4531, -1.1953,  1.1719,  2.5469,  0.2461]], dtype=torch.bfloat16))]), logits=tensor([[-3.4531, -1.1953,  1.1719,  2.5469,  0.2461]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2031, -3.1719, -2.2812,  2.7031,  5.0312]], dtype=torch.bfloat16))]), logits=tensor([[-3.2031, -3.1719, -2.2812,  2.7031,  5.0312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.2656,  0.4570,  2.3750,  1.0234, -2.1094]], dtype=torch.bfloat16))]), logits=tensor([[-2.2656,  0.4570,  2.3750,  1.0234, -2.1094]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.4375,  2.3438,  0.8086, -1.8203, -2.9219]], dtype=torch.bfloat16))]), logits=tensor([[ 2.4375,  2.3438,  0.8086, -1.8203, -2.9219]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7344, -1.9062,  0.4883,  3.0000,  1.3516]], dtype=torch.bfloat16))]), logits=tensor([[-3.7344, -1.9062,  0.4883,  3.0000,  1.3516]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.5312,  2.0469, -0.1045, -2.1094, -2.2969]], dtype=torch.bfloat16))]), logits=tensor([[ 3.5312,  2.0469, -0.1045, -2.1094, -2.2969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5000, -1.2656,  0.8398,  2.5469,  0.6602]], dtype=torch.bfloat16))]), logits=tensor([[-3.5000, -1.2656,  0.8398,  2.5469,  0.6602]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7812, -2.4375, -0.1001,  3.3125,  2.2031]], dtype=torch.bfloat16))]), logits=tensor([[-3.7812, -2.4375, -0.1001,  3.3125,  2.2031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.6875,  2.4844,  0.7812, -1.9766, -3.0469]], dtype=torch.bfloat16))]), logits=tensor([[ 2.6875,  2.4844,  0.7812, -1.9766, -3.0469]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8906, -3.0156, -2.3906,  2.3125,  5.0938]], dtype=torch.bfloat16))]), logits=tensor([[-2.8906, -3.0156, -2.3906,  2.3125,  5.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7969, -1.8828,  0.4707,  3.0156,  1.3906]], dtype=torch.bfloat16))]), logits=tensor([[-3.7969, -1.8828,  0.4707,  3.0156,  1.3906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.3828,  2.4844,  1.5156, -1.4297, -3.3594]], dtype=torch.bfloat16))]), logits=tensor([[ 1.3828,  2.4844,  1.5156, -1.4297, -3.3594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3906, -1.4297,  1.2578,  2.7344,  0.2832]], dtype=torch.bfloat16))]), logits=tensor([[-3.3906, -1.4297,  1.2578,  2.7344,  0.2832]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4531, -1.2031, -0.8867,  1.2188,  2.2500]], dtype=torch.bfloat16))]), logits=tensor([[-2.4531, -1.2031, -0.8867,  1.2188,  2.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8281, -3.1094, -1.2109,  3.3750,  3.7344]], dtype=torch.bfloat16))]), logits=tensor([[-3.8281, -3.1094, -1.2109,  3.3750,  3.7344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8125, -2.5000, -0.2402,  3.3594,  2.3750]], dtype=torch.bfloat16))]), logits=tensor([[-3.8125, -2.5000, -0.2402,  3.3594,  2.3750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3750, -2.7969, -1.6406,  2.6406,  3.9375]], dtype=torch.bfloat16))]), logits=tensor([[-3.3750, -2.7969, -1.6406,  2.6406,  3.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2500, -3.0000, -2.0781,  2.4688,  4.7812]], dtype=torch.bfloat16))]), logits=tensor([[-3.2500, -3.0000, -2.0781,  2.4688,  4.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3125, -2.9531, -1.8828,  2.7656,  4.2500]], dtype=torch.bfloat16))]), logits=tensor([[-3.3125, -2.9531, -1.8828,  2.7656,  4.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6719, -0.1084,  1.9922,  1.3516, -1.1094]], dtype=torch.bfloat16))]), logits=tensor([[-2.6719, -0.1084,  1.9922,  1.3516, -1.1094]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.7344,  1.0234, -0.5195, -1.7188, -1.4766]], dtype=torch.bfloat16))]), logits=tensor([[ 3.7344,  1.0234, -0.5195, -1.7188, -1.4766]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3125, -0.9648,  1.5000,  2.3906, -0.1865]], dtype=torch.bfloat16))]), logits=tensor([[-3.3125, -0.9648,  1.5000,  2.3906, -0.1865]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7031, -0.0830,  1.8984,  1.6406, -1.2812]], dtype=torch.bfloat16))]), logits=tensor([[-2.7031, -0.0830,  1.8984,  1.6406, -1.2812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2812, -3.1406, -2.1406,  2.7500,  4.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.2812, -3.1406, -2.1406,  2.7500,  4.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4531, -2.5312, -1.0781,  2.5312,  3.3125]], dtype=torch.bfloat16))]), logits=tensor([[-3.4531, -2.5312, -1.0781,  2.5312,  3.3125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8906, -2.9375, -0.9023,  3.4062,  3.3125]], dtype=torch.bfloat16))]), logits=tensor([[-3.8906, -2.9375, -0.9023,  3.4062,  3.3125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9219, -2.6719, -2.3281,  2.0625,  4.7500]], dtype=torch.bfloat16))]), logits=tensor([[-2.9219, -2.6719, -2.3281,  2.0625,  4.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5469, -2.4062, -0.0869,  3.2500,  2.1094]], dtype=torch.bfloat16))]), logits=tensor([[-3.5469, -2.4062, -0.0869,  3.2500,  2.1094]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3750, -3.1719, -2.0938,  2.9531,  4.6562]], dtype=torch.bfloat16))]), logits=tensor([[-3.3750, -3.1719, -2.0938,  2.9531,  4.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -2.7969, -1.4375,  2.8906,  3.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -2.7969, -1.4375,  2.8906,  3.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2500, -3.1406, -2.2344,  2.7031,  4.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.2500, -3.1406, -2.2344,  2.7031,  4.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3438, -1.3750,  0.4805,  2.3281,  1.0234]], dtype=torch.bfloat16))]), logits=tensor([[-3.3438, -1.3750,  0.4805,  2.3281,  1.0234]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7188, -2.7969, -0.8984,  3.3281,  3.0781]], dtype=torch.bfloat16))]), logits=tensor([[-3.7188, -2.7969, -0.8984,  3.3281,  3.0781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.6406,  1.1953,  2.1250,  0.4551, -2.3906]], dtype=torch.bfloat16))]), logits=tensor([[-1.6406,  1.1953,  2.1250,  0.4551, -2.3906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5938, -2.9375, -2.5000,  2.0469,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.5938, -2.9375, -2.5000,  2.0469,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.3965,  2.0000,  1.4688, -0.6758, -2.7812]], dtype=torch.bfloat16))]), logits=tensor([[ 0.3965,  2.0000,  1.4688, -0.6758, -2.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1406, -3.1250, -2.2500,  2.6406,  4.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.1406, -3.1250, -2.2500,  2.6406,  4.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8125, -2.8594, -2.4062,  2.1094,  5.0000]], dtype=torch.bfloat16))]), logits=tensor([[-2.8125, -2.8594, -2.4062,  2.1094,  5.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.9141,  2.2656,  0.9141, -1.5625, -2.8438]], dtype=torch.bfloat16))]), logits=tensor([[ 1.9141,  2.2656,  0.9141, -1.5625, -2.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3594, -2.7344, -1.6719,  2.4219,  4.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.3594, -2.7344, -1.6719,  2.4219,  4.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.3281,  1.5234,  2.1562,  0.2061, -2.6719]], dtype=torch.bfloat16))]), logits=tensor([[-1.3281,  1.5234,  2.1562,  0.2061, -2.6719]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.2188, -0.1152,  0.4785,  1.0000,  0.0098]], dtype=torch.bfloat16))]), logits=tensor([[-2.2188, -0.1152,  0.4785,  1.0000,  0.0098]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.6562,  2.2656,  0.4414, -1.8672, -2.7031]], dtype=torch.bfloat16))]), logits=tensor([[ 2.6562,  2.2656,  0.4414, -1.8672, -2.7031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3125, -2.6875, -1.5391,  2.2500,  4.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.3125, -2.6875, -1.5391,  2.2500,  4.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1406, -3.1250, -2.3438,  2.5781,  5.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.1406, -3.1250, -2.3438,  2.5781,  5.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -2.9219, -1.5156,  2.9844,  3.8906]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -2.9219, -1.5156,  2.9844,  3.8906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6250, -2.8594, -2.4375,  2.0000,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.6250, -2.8594, -2.4375,  2.0000,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.3750,  0.5781,  2.0625,  0.9414, -1.7656]], dtype=torch.bfloat16))]), logits=tensor([[-2.3750,  0.5781,  2.0625,  0.9414, -1.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7812, -0.3262,  1.5859,  1.7656, -0.8633]], dtype=torch.bfloat16))]), logits=tensor([[-2.7812, -0.3262,  1.5859,  1.7656, -0.8633]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3906, -1.2188,  0.4492,  2.1250,  1.0703]], dtype=torch.bfloat16))]), logits=tensor([[-3.3906, -1.2188,  0.4492,  2.1250,  1.0703]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.4688,  2.0312,  0.6602, -1.3828, -2.4375]], dtype=torch.bfloat16))]), logits=tensor([[ 1.4688,  2.0312,  0.6602, -1.3828, -2.4375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.0864,  2.0781,  1.8438, -0.5625, -3.0156]], dtype=torch.bfloat16))]), logits=tensor([[ 0.0864,  2.0781,  1.8438, -0.5625, -3.0156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8125, -2.5781, -0.5508,  3.0938,  2.8281]], dtype=torch.bfloat16))]), logits=tensor([[-3.8125, -2.5781, -0.5508,  3.0938,  2.8281]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.8359,  2.2031,  1.4297, -1.0078, -3.0000]], dtype=torch.bfloat16))]), logits=tensor([[ 0.8359,  2.2031,  1.4297, -1.0078, -3.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.6992,  1.8203,  1.9844, -0.1543, -2.8281]], dtype=torch.bfloat16))]), logits=tensor([[-0.6992,  1.8203,  1.9844, -0.1543, -2.8281]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8750, -3.0312, -2.4219,  2.2969,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.8750, -3.0312, -2.4219,  2.2969,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8281, -0.2637,  1.7656,  1.7969, -1.0234]], dtype=torch.bfloat16))]), logits=tensor([[-2.8281, -0.2637,  1.7656,  1.7969, -1.0234]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7500, -2.9219, -2.4531,  2.1094,  5.2500]], dtype=torch.bfloat16))]), logits=tensor([[-2.7500, -2.9219, -2.4531,  2.1094,  5.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0312, -3.0625, -2.3281,  2.4062,  5.0938]], dtype=torch.bfloat16))]), logits=tensor([[-3.0312, -3.0625, -2.3281,  2.4062,  5.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3750, -3.2031, -2.0938,  2.9219,  4.7188]], dtype=torch.bfloat16))]), logits=tensor([[-3.3750, -3.2031, -2.0938,  2.9219,  4.7188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 4.1875,  1.7500, -0.3184, -2.1875, -2.1719]], dtype=torch.bfloat16))]), logits=tensor([[ 4.1875,  1.7500, -0.3184, -2.1875, -2.1719]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9844, -3.0156, -2.3438,  2.2969,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.9844, -3.0156, -2.3438,  2.2969,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8438, -2.5156, -0.2773,  3.1875,  2.4844]], dtype=torch.bfloat16))]), logits=tensor([[-3.8438, -2.5156, -0.2773,  3.1875,  2.4844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3750, -1.0859,  1.4766,  2.5312, -0.1230]], dtype=torch.bfloat16))]), logits=tensor([[-3.3750, -1.0859,  1.4766,  2.5312, -0.1230]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4219, -2.7969, -1.8047,  2.5000,  4.2500]], dtype=torch.bfloat16))]), logits=tensor([[-3.4219, -2.7969, -1.8047,  2.5000,  4.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -3.0469, -1.3750,  3.1406,  3.7969]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -3.0469, -1.3750,  3.1406,  3.7969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6562, -3.1562, -1.8203,  3.0000,  4.4688]], dtype=torch.bfloat16))]), logits=tensor([[-3.6562, -3.1562, -1.8203,  3.0000,  4.4688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4219, -2.8281, -2.4688,  1.8438,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.4219, -2.8281, -2.4688,  1.8438,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -2.7500, -1.6328,  2.5938,  4.0938]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -2.7500, -1.6328,  2.5938,  4.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0312, -2.9375, -2.1719,  2.2656,  4.9375]], dtype=torch.bfloat16))]), logits=tensor([[-3.0312, -2.9375, -2.1719,  2.2656,  4.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.9141,  2.5000,  1.3047, -1.7031, -3.2500]], dtype=torch.bfloat16))]), logits=tensor([[ 1.9141,  2.5000,  1.3047, -1.7031, -3.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8438, -2.6406, -0.3555,  3.3281,  2.6562]], dtype=torch.bfloat16))]), logits=tensor([[-3.8438, -2.6406, -0.3555,  3.3281,  2.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -2.7188, -1.2422,  2.8594,  3.5469]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -2.7188, -1.2422,  2.8594,  3.5469]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.1953,  2.1250,  1.1172, -1.1562, -2.7969]], dtype=torch.bfloat16))]), logits=tensor([[ 1.1953,  2.1250,  1.1172, -1.1562, -2.7969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6562, -2.5156, -0.5586,  3.1406,  2.6562]], dtype=torch.bfloat16))]), logits=tensor([[-3.6562, -2.5156, -0.5586,  3.1406,  2.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.3906,  0.8984, -0.5391, -1.5234, -1.2188]], dtype=torch.bfloat16))]), logits=tensor([[ 3.3906,  0.8984, -0.5391, -1.5234, -1.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6562, -2.8125, -2.4375,  1.9609,  5.0938]], dtype=torch.bfloat16))]), logits=tensor([[-2.6562, -2.8125, -2.4375,  1.9609,  5.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9688, -0.4121,  1.7969,  1.9844, -0.9336]], dtype=torch.bfloat16))]), logits=tensor([[-2.9688, -0.4121,  1.7969,  1.9844, -0.9336]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2969, -3.0156, -1.9219,  2.5781,  4.5000]], dtype=torch.bfloat16))]), logits=tensor([[-3.2969, -3.0156, -1.9219,  2.5781,  4.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5625, -2.6875, -2.4375,  1.7656,  5.0312]], dtype=torch.bfloat16))]), logits=tensor([[-2.5625, -2.6875, -2.4375,  1.7656,  5.0312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8594, -0.1416,  1.7656,  1.4141, -0.9414]], dtype=torch.bfloat16))]), logits=tensor([[-2.8594, -0.1416,  1.7656,  1.4141, -0.9414]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7969, -2.9688, -2.4375,  2.1719,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.7969, -2.9688, -2.4375,  2.1719,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2344, -2.8750, -2.1094,  2.3906,  4.5938]], dtype=torch.bfloat16))]), logits=tensor([[-3.2344, -2.8750, -2.1094,  2.3906,  4.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6719, -3.2031, -1.5547,  3.2344,  4.1562]], dtype=torch.bfloat16))]), logits=tensor([[-3.6719, -3.2031, -1.5547,  3.2344,  4.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -2.8594, -0.9180,  3.3125,  3.2188]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -2.8594, -0.9180,  3.3125,  3.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5156, -0.3965,  0.5234,  1.1562,  0.3750]], dtype=torch.bfloat16))]), logits=tensor([[-2.5156, -0.3965,  0.5234,  1.1562,  0.3750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6562, -2.0781, -0.3887,  2.6562,  2.3594]], dtype=torch.bfloat16))]), logits=tensor([[-3.6562, -2.0781, -0.3887,  2.6562,  2.3594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.9258,  2.3438,  1.6328, -1.1484, -3.2969]], dtype=torch.bfloat16))]), logits=tensor([[ 0.9258,  2.3438,  1.6328, -1.1484, -3.2969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2500, -3.1562, -2.1562,  2.6719,  4.8125]], dtype=torch.bfloat16))]), logits=tensor([[-3.2500, -3.1562, -2.1562,  2.6719,  4.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7969, -2.3594,  0.1021,  3.3594,  1.9766]], dtype=torch.bfloat16))]), logits=tensor([[-3.7969, -2.3594,  0.1021,  3.3594,  1.9766]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8906, -3.0469, -2.3906,  2.3125,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.8906, -3.0469, -2.3906,  2.3125,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -3.2188, -1.9922,  3.0469,  4.5938]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -3.2188, -1.9922,  3.0469,  4.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7344, -2.9219, -2.4219,  2.0156,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.7344, -2.9219, -2.4219,  2.0156,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.8203,  0.8867,  1.9453,  0.6328, -2.0781]], dtype=torch.bfloat16))]), logits=tensor([[-1.8203,  0.8867,  1.9453,  0.6328, -2.0781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1562, -3.1094, -2.2969,  2.5625,  5.0000]], dtype=torch.bfloat16))]), logits=tensor([[-3.1562, -3.1094, -2.2969,  2.5625,  5.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4844,  0.3301,  2.0469,  1.3203, -1.7266]], dtype=torch.bfloat16))]), logits=tensor([[-2.4844,  0.3301,  2.0469,  1.3203, -1.7266]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -3.1875, -1.7422,  3.2500,  4.2500]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -3.1875, -1.7422,  3.2500,  4.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6719, -2.9062, -2.4688,  2.0312,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.6719, -2.9062, -2.4688,  2.0312,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.8906,  2.4219,  0.5586, -2.0469, -2.9062]], dtype=torch.bfloat16))]), logits=tensor([[ 2.8906,  2.4219,  0.5586, -2.0469, -2.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2812, -1.2109,  0.9961,  2.5156,  0.3242]], dtype=torch.bfloat16))]), logits=tensor([[-3.2812, -1.2109,  0.9961,  2.5156,  0.3242]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3594, -1.0000,  1.1641,  2.3438,  0.1143]], dtype=torch.bfloat16))]), logits=tensor([[-3.3594, -1.0000,  1.1641,  2.3438,  0.1143]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.8672,  1.0859,  2.1406,  0.5781, -2.2969]], dtype=torch.bfloat16))]), logits=tensor([[-1.8672,  1.0859,  2.1406,  0.5781, -2.2969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.4531,  2.1250,  0.9766, -1.2812, -2.7344]], dtype=torch.bfloat16))]), logits=tensor([[ 1.4531,  2.1250,  0.9766, -1.2812, -2.7344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5156, -2.7969, -2.4531,  1.8594,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-2.5156, -2.7969, -2.4531,  1.8594,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.2812,  2.4375,  0.2930, -2.2188, -2.8281]], dtype=torch.bfloat16))]), logits=tensor([[ 3.2812,  2.4375,  0.2930, -2.2188, -2.8281]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5625, -2.7500, -1.1172,  2.7344,  3.5312]], dtype=torch.bfloat16))]), logits=tensor([[-3.5625, -2.7500, -1.1172,  2.7344,  3.5312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6250, -2.9062, -2.4688,  2.0312,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.6250, -2.9062, -2.4688,  2.0312,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8125, -2.9688, -2.4219,  2.1875,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.8125, -2.9688, -2.4219,  2.1875,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1875, -3.0938, -2.2656,  2.5781,  5.0000]], dtype=torch.bfloat16))]), logits=tensor([[-3.1875, -3.0938, -2.2656,  2.5781,  5.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6094, -1.6484,  0.8711,  2.9219,  0.8125]], dtype=torch.bfloat16))]), logits=tensor([[-3.6094, -1.6484,  0.8711,  2.9219,  0.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.9766,  1.6797,  2.0625,  0.0913, -2.7812]], dtype=torch.bfloat16))]), logits=tensor([[-0.9766,  1.6797,  2.0625,  0.0913, -2.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3750, -1.1953,  0.8750,  2.3281,  0.5898]], dtype=torch.bfloat16))]), logits=tensor([[-3.3750, -1.1953,  0.8750,  2.3281,  0.5898]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.9688,  2.0781,  1.2109, -0.9453, -2.8906]], dtype=torch.bfloat16))]), logits=tensor([[ 0.9688,  2.0781,  1.2109, -0.9453, -2.8906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4844, -3.0938, -1.5391,  3.2344,  3.9844]], dtype=torch.bfloat16))]), logits=tensor([[-3.4844, -3.0938, -1.5391,  3.2344,  3.9844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -3.0312, -1.1562,  3.3906,  3.5938]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -3.0312, -1.1562,  3.3906,  3.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0625, -0.8594,  1.0859,  2.1562, -0.0405]], dtype=torch.bfloat16))]), logits=tensor([[-3.0625, -0.8594,  1.0859,  2.1562, -0.0405]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.2812,  0.4922,  1.8047,  0.9414, -1.4219]], dtype=torch.bfloat16))]), logits=tensor([[-2.2812,  0.4922,  1.8047,  0.9414, -1.4219]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8438, -3.0000, -2.4375,  2.2969,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.8438, -3.0000, -2.4375,  2.2969,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8750, -3.0312, -2.4219,  2.2656,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.8750, -3.0312, -2.4219,  2.2656,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7656, -0.9258, -0.0095,  1.5000,  1.2344]], dtype=torch.bfloat16))]), logits=tensor([[-2.7656, -0.9258, -0.0095,  1.5000,  1.2344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.5703,  1.4141,  2.5156,  0.2812, -2.8750]], dtype=torch.bfloat16))]), logits=tensor([[-1.5703,  1.4141,  2.5156,  0.2812, -2.8750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7188, -2.9375, -1.4688,  3.0469,  3.8906]], dtype=torch.bfloat16))]), logits=tensor([[-3.7188, -2.9375, -1.4688,  3.0469,  3.8906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.3906,  2.3906,  1.4297, -1.3594, -3.2344]], dtype=torch.bfloat16))]), logits=tensor([[ 1.3906,  2.3906,  1.4297, -1.3594, -3.2344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4688, -1.3516,  1.0234,  2.4844,  0.5508]], dtype=torch.bfloat16))]), logits=tensor([[-3.4688, -1.3516,  1.0234,  2.4844,  0.5508]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.6094,  2.1094,  0.2461, -1.8047, -2.4531]], dtype=torch.bfloat16))]), logits=tensor([[ 2.6094,  2.1094,  0.2461, -1.8047, -2.4531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9219, -2.9844, -2.4219,  2.2188,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-2.9219, -2.9844, -2.4219,  2.2188,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7344, -2.9531, -2.4531,  2.0938,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.7344, -2.9531, -2.4531,  2.0938,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4062, -3.1562, -2.0625,  2.9844,  4.5625]], dtype=torch.bfloat16))]), logits=tensor([[-3.4062, -3.1562, -2.0625,  2.9844,  4.5625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.8594,  1.9062, -0.2598, -2.1406, -2.2031]], dtype=torch.bfloat16))]), logits=tensor([[ 3.8594,  1.9062, -0.2598, -2.1406, -2.2031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6562, -2.5156, -0.4434,  3.1875,  2.5156]], dtype=torch.bfloat16))]), logits=tensor([[-3.6562, -2.5156, -0.4434,  3.1875,  2.5156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8594, -2.3906, -0.2314,  3.1406,  2.3906]], dtype=torch.bfloat16))]), logits=tensor([[-3.8594, -2.3906, -0.2314,  3.1406,  2.3906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8281, -3.0156, -1.3125,  3.1406,  3.8594]], dtype=torch.bfloat16))]), logits=tensor([[-3.8281, -3.0156, -1.3125,  3.1406,  3.8594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1406, -3.1250, -2.3125,  2.6875,  4.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.1406, -3.1250, -2.3125,  2.6875,  4.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.4199,  1.9766,  2.1406, -0.3398, -3.3906]], dtype=torch.bfloat16))]), logits=tensor([[-0.4199,  1.9766,  2.1406, -0.3398, -3.3906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6875, -2.9531, -2.5000,  2.1406,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.6875, -2.9531, -2.5000,  2.1406,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.1562,  2.2812,  0.2773, -2.0781, -2.6875]], dtype=torch.bfloat16))]), logits=tensor([[ 3.1562,  2.2812,  0.2773, -2.0781, -2.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.3281,  0.1367,  0.7930,  0.8164, -0.2754]], dtype=torch.bfloat16))]), logits=tensor([[-2.3281,  0.1367,  0.7930,  0.8164, -0.2754]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -1.5078,  0.8906,  2.7344,  0.7539]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -1.5078,  0.8906,  2.7344,  0.7539]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.7812,  1.1797, -0.5195, -1.7734, -1.5625]], dtype=torch.bfloat16))]), logits=tensor([[ 3.7812,  1.1797, -0.5195, -1.7734, -1.5625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5156, -2.7969, -2.4219,  1.8047,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.5156, -2.7969, -2.4219,  1.8047,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4375, -1.7656,  0.5547,  2.6094,  1.2109]], dtype=torch.bfloat16))]), logits=tensor([[-3.4375, -1.7656,  0.5547,  2.6094,  1.2109]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.1719,  2.3750,  0.3242, -2.1406, -2.7656]], dtype=torch.bfloat16))]), logits=tensor([[ 3.1719,  2.3750,  0.3242, -2.1406, -2.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1562, -3.1250, -2.1875,  2.7188,  4.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.1562, -3.1250, -2.1875,  2.7188,  4.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3750, -3.1562, -2.1094,  2.8594,  4.7812]], dtype=torch.bfloat16))]), logits=tensor([[-3.3750, -3.1562, -2.1094,  2.8594,  4.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.7617,  1.9922,  2.4062, -0.1377, -3.3594]], dtype=torch.bfloat16))]), logits=tensor([[-0.7617,  1.9922,  2.4062, -0.1377, -3.3594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7188, -2.9062, -2.4844,  2.0312,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.7188, -2.9062, -2.4844,  2.0312,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -1.8359,  0.4473,  2.9062,  1.3047]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -1.8359,  0.4473,  2.9062,  1.3047]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0000, -0.8320,  1.0234,  2.1250,  0.0190]], dtype=torch.bfloat16))]), logits=tensor([[-3.0000, -0.8320,  1.0234,  2.1250,  0.0190]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2969, -1.4453,  1.0312,  2.5781,  0.5469]], dtype=torch.bfloat16))]), logits=tensor([[-3.2969, -1.4453,  1.0312,  2.5781,  0.5469]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6094, -2.9844, -1.5312,  2.9062,  4.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.6094, -2.9844, -1.5312,  2.9062,  4.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.8906,  1.0703,  2.3438,  0.5508, -2.4062]], dtype=torch.bfloat16))]), logits=tensor([[-1.8906,  1.0703,  2.3438,  0.5508, -2.4062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.2598,  2.2188,  1.9062, -0.6992, -3.2656]], dtype=torch.bfloat16))]), logits=tensor([[ 0.2598,  2.2188,  1.9062, -0.6992, -3.2656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4844, -3.1875, -1.7266,  3.2188,  4.3750]], dtype=torch.bfloat16))]), logits=tensor([[-3.4844, -3.1875, -1.7266,  3.2188,  4.3750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0312, -3.0938, -2.3906,  2.4844,  5.0938]], dtype=torch.bfloat16))]), logits=tensor([[-3.0312, -3.0938, -2.3906,  2.4844,  5.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.1719,  0.0981,  0.9102,  0.9727, -0.5078]], dtype=torch.bfloat16))]), logits=tensor([[-2.1719,  0.0981,  0.9102,  0.9727, -0.5078]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5000, -3.0781, -1.8672,  2.9219,  4.3750]], dtype=torch.bfloat16))]), logits=tensor([[-3.5000, -3.0781, -1.8672,  2.9219,  4.3750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7812, -0.1187,  1.8047,  1.6875, -1.1641]], dtype=torch.bfloat16))]), logits=tensor([[-2.7812, -0.1187,  1.8047,  1.6875, -1.1641]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4844, -3.0625, -1.3672,  3.3906,  3.7188]], dtype=torch.bfloat16))]), logits=tensor([[-3.4844, -3.0625, -1.3672,  3.3906,  3.7188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9844, -3.0156, -2.3906,  2.3750,  5.0938]], dtype=torch.bfloat16))]), logits=tensor([[-2.9844, -3.0156, -2.3906,  2.3750,  5.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 4.0312,  1.8281, -0.2793, -2.1406, -2.1875]], dtype=torch.bfloat16))]), logits=tensor([[ 4.0312,  1.8281, -0.2793, -2.1406, -2.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9688, -2.9844, -2.4375,  2.3281,  5.0625]], dtype=torch.bfloat16))]), logits=tensor([[-2.9688, -2.9844, -2.4375,  2.3281,  5.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6875, -2.1562, -0.0679,  3.1562,  1.9531]], dtype=torch.bfloat16))]), logits=tensor([[-3.6875, -2.1562, -0.0679,  3.1562,  1.9531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.7188,  2.1406, -0.0312, -2.2031, -2.4688]], dtype=torch.bfloat16))]), logits=tensor([[ 3.7188,  2.1406, -0.0312, -2.2031, -2.4688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5156, -2.7969, -1.5547,  2.7500,  3.8750]], dtype=torch.bfloat16))]), logits=tensor([[-3.5156, -2.7969, -1.5547,  2.7500,  3.8750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2188, -2.9688, -2.1719,  2.5156,  4.7188]], dtype=torch.bfloat16))]), logits=tensor([[-3.2188, -2.9688, -2.1719,  2.5156,  4.7188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7812, -2.5312, -0.5273,  3.0312,  2.7656]], dtype=torch.bfloat16))]), logits=tensor([[-3.7812, -2.5312, -0.5273,  3.0312,  2.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4062,  0.3223,  1.8047,  1.2656, -1.4688]], dtype=torch.bfloat16))]), logits=tensor([[-2.4062,  0.3223,  1.8047,  1.2656, -1.4688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.4004,  1.9766,  1.4453, -0.6953, -2.7031]], dtype=torch.bfloat16))]), logits=tensor([[ 0.4004,  1.9766,  1.4453, -0.6953, -2.7031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5000, -3.0781, -1.8359,  2.8750,  4.3750]], dtype=torch.bfloat16))]), logits=tensor([[-3.5000, -3.0781, -1.8359,  2.8750,  4.3750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6875, -3.0312, -1.4844,  2.9062,  4.1250]], dtype=torch.bfloat16))]), logits=tensor([[-3.6875, -3.0312, -1.4844,  2.9062,  4.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6562, -2.9375, -1.2578,  3.1406,  3.6250]], dtype=torch.bfloat16))]), logits=tensor([[-3.6562, -2.9375, -1.2578,  3.1406,  3.6250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8438, -2.7656, -0.8203,  3.1094,  3.2031]], dtype=torch.bfloat16))]), logits=tensor([[-3.8438, -2.7656, -0.8203,  3.1094,  3.2031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.9844, -2.4531, -0.2461,  3.3438,  2.4688]], dtype=torch.bfloat16))]), logits=tensor([[-3.9844, -2.4531, -0.2461,  3.3438,  2.4688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7188, -2.9688, -2.4688,  2.1406,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.7188, -2.9688, -2.4688,  2.1406,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6875, -3.1250, -1.3984,  3.2969,  3.8906]], dtype=torch.bfloat16))]), logits=tensor([[-3.6875, -3.1250, -1.3984,  3.2969,  3.8906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6406, -1.9297,  0.2109,  2.9219,  1.5703]], dtype=torch.bfloat16))]), logits=tensor([[-3.6406, -1.9297,  0.2109,  2.9219,  1.5703]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2031, -1.6328, -0.2930,  2.1875,  1.9531]], dtype=torch.bfloat16))]), logits=tensor([[-3.2031, -1.6328, -0.2930,  2.1875,  1.9531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4375, -1.7109,  0.1279,  2.2031,  1.7656]], dtype=torch.bfloat16))]), logits=tensor([[-3.4375, -1.7109,  0.1279,  2.2031,  1.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7344, -2.9375, -2.4375,  2.0938,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.7344, -2.9375, -2.4375,  2.0938,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.2969,  1.5547,  2.1719,  0.1611, -2.6719]], dtype=torch.bfloat16))]), logits=tensor([[-1.2969,  1.5547,  2.1719,  0.1611, -2.6719]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2656, -2.8906, -1.7578,  2.5312,  4.2188]], dtype=torch.bfloat16))]), logits=tensor([[-3.2656, -2.8906, -1.7578,  2.5312,  4.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2031, -3.0469, -2.0312,  2.5938,  4.6875]], dtype=torch.bfloat16))]), logits=tensor([[-3.2031, -3.0469, -2.0312,  2.5938,  4.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9062, -3.0156, -2.3906,  2.2812,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.9062, -3.0156, -2.3906,  2.2812,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7344, -2.1562, -0.2471,  3.0000,  2.2344]], dtype=torch.bfloat16))]), logits=tensor([[-3.7344, -2.1562, -0.2471,  3.0000,  2.2344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.3281,  0.3828,  1.6484,  1.0938, -1.3203]], dtype=torch.bfloat16))]), logits=tensor([[-2.3281,  0.3828,  1.6484,  1.0938, -1.3203]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2812, -2.0938, -1.1797,  2.1094,  3.2188]], dtype=torch.bfloat16))]), logits=tensor([[-3.2812, -2.0938, -1.1797,  2.1094,  3.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -3.0938, -1.3984,  3.2188,  3.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -3.0938, -1.3984,  3.2188,  3.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6250, -3.0312, -1.6562,  3.0156,  4.1562]], dtype=torch.bfloat16))]), logits=tensor([[-3.6250, -3.0312, -1.6562,  3.0156,  4.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7500, -2.1875, -1.6094,  1.6953,  3.6094]], dtype=torch.bfloat16))]), logits=tensor([[-2.7500, -2.1875, -1.6094,  1.6953,  3.6094]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5156, -2.9062, -1.5547,  2.9688,  3.8438]], dtype=torch.bfloat16))]), logits=tensor([[-3.5156, -2.9062, -1.5547,  2.9688,  3.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.0938, -1.8750, -1.4375,  1.1641,  3.2344]], dtype=torch.bfloat16))]), logits=tensor([[-2.0938, -1.8750, -1.4375,  1.1641,  3.2344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2969, -3.1094, -2.1875,  2.7031,  4.8125]], dtype=torch.bfloat16))]), logits=tensor([[-3.2969, -3.1094, -2.1875,  2.7031,  4.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0625, -3.0000, -2.3438,  2.4062,  5.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.0625, -3.0000, -2.3438,  2.4062,  5.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.3438,  2.2500,  0.6875, -1.7500, -2.7812]], dtype=torch.bfloat16))]), logits=tensor([[ 2.3438,  2.2500,  0.6875, -1.7500, -2.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1562, -2.8594, -1.9688,  2.3906,  4.4375]], dtype=torch.bfloat16))]), logits=tensor([[-3.1562, -2.8594, -1.9688,  2.3906,  4.4375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.3301,  2.3594,  2.0625, -0.8047, -3.5469]], dtype=torch.bfloat16))]), logits=tensor([[ 0.3301,  2.3594,  2.0625, -0.8047, -3.5469]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3281, -1.2578,  0.8242,  2.4688,  0.6289]], dtype=torch.bfloat16))]), logits=tensor([[-3.3281, -1.2578,  0.8242,  2.4688,  0.6289]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6719, -1.9375,  0.3613,  3.1094,  1.4062]], dtype=torch.bfloat16))]), logits=tensor([[-3.6719, -1.9375,  0.3613,  3.1094,  1.4062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1562, -3.1094, -2.3125,  2.5625,  5.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.1562, -3.1094, -2.3125,  2.5625,  5.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0156, -1.9453, -1.0156,  1.8594,  2.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.0156, -1.9453, -1.0156,  1.8594,  2.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6406, -0.0442,  1.5469,  1.5234, -1.0234]], dtype=torch.bfloat16))]), logits=tensor([[-2.6406, -0.0442,  1.5469,  1.5234, -1.0234]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4844, -1.7891,  0.5312,  2.8750,  1.1172]], dtype=torch.bfloat16))]), logits=tensor([[-3.4844, -1.7891,  0.5312,  2.8750,  1.1172]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6875, -0.3027,  1.0547,  1.4141, -0.2793]], dtype=torch.bfloat16))]), logits=tensor([[-2.6875, -0.3027,  1.0547,  1.4141, -0.2793]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -3.0000, -1.6406,  3.0312,  4.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -3.0000, -1.6406,  3.0312,  4.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6250, -2.8750, -2.4062,  1.9531,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.6250, -2.8750, -2.4062,  1.9531,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.6562,  2.5000,  1.4062, -1.5781, -3.2969]], dtype=torch.bfloat16))]), logits=tensor([[ 1.6562,  2.5000,  1.4062, -1.5781, -3.2969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.6094,  1.3594,  2.3438,  0.4180, -2.7188]], dtype=torch.bfloat16))]), logits=tensor([[-1.6094,  1.3594,  2.3438,  0.4180, -2.7188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.9219,  2.4688,  1.2188, -1.6797, -3.1719]], dtype=torch.bfloat16))]), logits=tensor([[ 1.9219,  2.4688,  1.2188, -1.6797, -3.1719]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.1562, -0.0422,  0.4043,  0.7422,  0.1465]], dtype=torch.bfloat16))]), logits=tensor([[-2.1562, -0.0422,  0.4043,  0.7422,  0.1465]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.0625,  2.2188,  0.2471, -2.0156, -2.5938]], dtype=torch.bfloat16))]), logits=tensor([[ 3.0625,  2.2188,  0.2471, -2.0156, -2.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 4.0625,  1.3438, -0.4707, -1.9766, -1.7891]], dtype=torch.bfloat16))]), logits=tensor([[ 4.0625,  1.3438, -0.4707, -1.9766, -1.7891]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.3750,  2.3281,  0.7539, -1.7812, -2.8594]], dtype=torch.bfloat16))]), logits=tensor([[ 2.3750,  2.3281,  0.7539, -1.7812, -2.8594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2656, -1.3906,  0.2490,  2.1094,  1.2734]], dtype=torch.bfloat16))]), logits=tensor([[-3.2656, -1.3906,  0.2490,  2.1094,  1.2734]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7969, -2.8750, -2.3594,  2.0781,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-2.7969, -2.8750, -2.3594,  2.0781,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2031, -3.0469, -2.1875,  2.5000,  4.9375]], dtype=torch.bfloat16))]), logits=tensor([[-3.2031, -3.0469, -2.1875,  2.5000,  4.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4375, -3.1875, -2.0312,  2.9219,  4.6562]], dtype=torch.bfloat16))]), logits=tensor([[-3.4375, -3.1875, -2.0312,  2.9219,  4.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1875, -3.0625, -2.1875,  2.5156,  4.9375]], dtype=torch.bfloat16))]), logits=tensor([[-3.1875, -3.0625, -2.1875,  2.5156,  4.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8125, -2.6875, -0.5820,  3.2969,  2.9219]], dtype=torch.bfloat16))]), logits=tensor([[-3.8125, -2.6875, -0.5820,  3.2969,  2.9219]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5625, -2.4688, -1.0000,  2.8281,  3.1094]], dtype=torch.bfloat16))]), logits=tensor([[-3.5625, -2.4688, -1.0000,  2.8281,  3.1094]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0781, -3.0156, -2.3125,  2.4531,  5.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.0781, -3.0156, -2.3125,  2.4531,  5.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7188, -2.6406, -0.6953,  3.2969,  2.7969]], dtype=torch.bfloat16))]), logits=tensor([[-3.7188, -2.6406, -0.6953,  3.2969,  2.7969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8281, -3.0000, -2.4688,  2.2188,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.8281, -3.0000, -2.4688,  2.2188,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3594, -2.8438, -1.7188,  2.6562,  4.1875]], dtype=torch.bfloat16))]), logits=tensor([[-3.3594, -2.8438, -1.7188,  2.6562,  4.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8281, -3.0000, -2.4531,  2.2656,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.8281, -3.0000, -2.4531,  2.2656,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3438, -3.1406, -1.8516,  2.8906,  4.4688]], dtype=torch.bfloat16))]), logits=tensor([[-3.3438, -3.1406, -1.8516,  2.8906,  4.4688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.9922, -0.3887,  0.0208,  0.8828,  0.6016]], dtype=torch.bfloat16))]), logits=tensor([[-1.9922, -0.3887,  0.0208,  0.8828,  0.6016]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7344, -2.8906, -2.4062,  2.0156,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.7344, -2.8906, -2.4062,  2.0156,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.7969,  2.1875,  0.8750, -1.4766, -2.7656]], dtype=torch.bfloat16))]), logits=tensor([[ 1.7969,  2.1875,  0.8750, -1.4766, -2.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.1387,  1.6172,  1.0312, -0.5273, -2.1250]], dtype=torch.bfloat16))]), logits=tensor([[ 0.1387,  1.6172,  1.0312, -0.5273, -2.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5625, -0.1582,  1.1875,  1.3594, -0.5078]], dtype=torch.bfloat16))]), logits=tensor([[-2.5625, -0.1582,  1.1875,  1.3594, -0.5078]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2656, -2.4844, -1.2031,  2.3281,  3.4375]], dtype=torch.bfloat16))]), logits=tensor([[-3.2656, -2.4844, -1.2031,  2.3281,  3.4375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.3906,  1.9922, -0.1299, -2.0469, -2.2656]], dtype=torch.bfloat16))]), logits=tensor([[ 3.3906,  1.9922, -0.1299, -2.0469, -2.2656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8125, -2.9062, -2.3750,  2.1250,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.8125, -2.9062, -2.3750,  2.1250,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.6094,  1.8438,  2.0625, -0.2100, -2.9219]], dtype=torch.bfloat16))]), logits=tensor([[-0.6094,  1.8438,  2.0625, -0.2100, -2.9219]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.3125,  0.6250,  2.0469,  0.9375, -1.8047]], dtype=torch.bfloat16))]), logits=tensor([[-2.3125,  0.6250,  2.0469,  0.9375, -1.8047]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0781, -3.1250, -2.3125,  2.6094,  5.0312]], dtype=torch.bfloat16))]), logits=tensor([[-3.0781, -3.1250, -2.3125,  2.6094,  5.0312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.5938,  2.4375,  0.6797, -1.9766, -2.9062]], dtype=torch.bfloat16))]), logits=tensor([[ 2.5938,  2.4375,  0.6797, -1.9766, -2.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.2031,  0.6211,  2.2969,  1.0312, -2.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.2031,  0.6211,  2.2969,  1.0312, -2.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6250, -2.2656,  0.1021,  3.2344,  1.8359]], dtype=torch.bfloat16))]), logits=tensor([[-3.6250, -2.2656,  0.1021,  3.2344,  1.8359]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7188, -3.0000, -1.2266,  3.2188,  3.6250]], dtype=torch.bfloat16))]), logits=tensor([[-3.7188, -3.0000, -1.2266,  3.2188,  3.6250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6094, -3.0469, -1.6719,  2.9062,  4.3125]], dtype=torch.bfloat16))]), logits=tensor([[-3.6094, -3.0469, -1.6719,  2.9062,  4.3125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.7656,  2.2500, -0.0100, -2.2812, -2.6094]], dtype=torch.bfloat16))]), logits=tensor([[ 3.7656,  2.2500, -0.0100, -2.2812, -2.6094]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6250, -2.9219, -1.3906,  3.0156,  3.8125]], dtype=torch.bfloat16))]), logits=tensor([[-3.6250, -2.9219, -1.3906,  3.0156,  3.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5156, -2.0469, -0.4062,  2.4844,  2.3906]], dtype=torch.bfloat16))]), logits=tensor([[-3.5156, -2.0469, -0.4062,  2.4844,  2.3906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3906, -3.0625, -2.0469,  2.7656,  4.5938]], dtype=torch.bfloat16))]), logits=tensor([[-3.3906, -3.0625, -2.0469,  2.7656,  4.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.8906,  2.4219,  0.5430, -2.0469, -2.9062]], dtype=torch.bfloat16))]), logits=tensor([[ 2.8906,  2.4219,  0.5430, -2.0469, -2.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6719, -2.9844, -1.0469,  3.4062,  3.3594]], dtype=torch.bfloat16))]), logits=tensor([[-3.6719, -2.9844, -1.0469,  3.4062,  3.3594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.7031,  0.9688, -0.5508, -1.6875, -1.4219]], dtype=torch.bfloat16))]), logits=tensor([[ 3.7031,  0.9688, -0.5508, -1.6875, -1.4219]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8750, -2.7969, -0.7383,  3.3594,  3.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.8750, -2.7969, -0.7383,  3.3594,  3.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.5469,  2.1250, -0.0664, -2.1562, -2.4375]], dtype=torch.bfloat16))]), logits=tensor([[ 3.5469,  2.1250, -0.0664, -2.1562, -2.4375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9375, -3.0469, -2.4219,  2.3906,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-2.9375, -3.0469, -2.4219,  2.3906,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4219,  0.2695,  1.8594,  1.3516, -1.5547]], dtype=torch.bfloat16))]), logits=tensor([[-2.4219,  0.2695,  1.8594,  1.3516, -1.5547]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5938, -3.0469, -1.7422,  3.0469,  4.2188]], dtype=torch.bfloat16))]), logits=tensor([[-3.5938, -3.0469, -1.7422,  3.0469,  4.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6875, -2.9219, -1.1797,  3.1875,  3.5000]], dtype=torch.bfloat16))]), logits=tensor([[-3.6875, -2.9219, -1.1797,  3.1875,  3.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3906, -3.0625, -1.9609,  2.6875,  4.6250]], dtype=torch.bfloat16))]), logits=tensor([[-3.3906, -3.0625, -1.9609,  2.6875,  4.6250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5469, -3.1250, -1.7734,  3.0781,  4.2812]], dtype=torch.bfloat16))]), logits=tensor([[-3.5469, -3.1250, -1.7734,  3.0781,  4.2812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4531, -3.0781, -1.8203,  2.8125,  4.4062]], dtype=torch.bfloat16))]), logits=tensor([[-3.4531, -3.0781, -1.8203,  2.8125,  4.4062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0625, -1.1719,  0.6367,  2.1719,  0.6250]], dtype=torch.bfloat16))]), logits=tensor([[-3.0625, -1.1719,  0.6367,  2.1719,  0.6250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4688, -3.1875, -2.0000,  2.9219,  4.6562]], dtype=torch.bfloat16))]), logits=tensor([[-3.4688, -3.1875, -2.0000,  2.9219,  4.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5156, -2.8750, -1.5312,  2.6094,  4.0938]], dtype=torch.bfloat16))]), logits=tensor([[-3.5156, -2.8750, -1.5312,  2.6094,  4.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.5938, -0.3145,  3.2656,  2.5625]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.5938, -0.3145,  3.2656,  2.5625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4219, -2.4688, -1.3359,  2.2812,  3.6562]], dtype=torch.bfloat16))]), logits=tensor([[-3.4219, -2.4688, -1.3359,  2.2812,  3.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.4609,  2.2031,  1.0625, -1.3203, -2.7969]], dtype=torch.bfloat16))]), logits=tensor([[ 1.4609,  2.2031,  1.0625, -1.3203, -2.7969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0312, -0.4062,  1.6797,  1.8828, -0.7383]], dtype=torch.bfloat16))]), logits=tensor([[-3.0312, -0.4062,  1.6797,  1.8828, -0.7383]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.9922,  0.4531,  1.3516,  0.8203, -1.1875]], dtype=torch.bfloat16))]), logits=tensor([[-1.9922,  0.4531,  1.3516,  0.8203, -1.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.4531,  2.3594,  0.2129, -2.2031, -2.7656]], dtype=torch.bfloat16))]), logits=tensor([[ 3.4531,  2.3594,  0.2129, -2.2031, -2.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6250, -2.1406, -0.3535,  2.4531,  2.4531]], dtype=torch.bfloat16))]), logits=tensor([[-3.6250, -2.1406, -0.3535,  2.4531,  2.4531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1719, -0.6875,  1.4375,  1.9688, -0.2197]], dtype=torch.bfloat16))]), logits=tensor([[-3.1719, -0.6875,  1.4375,  1.9688, -0.2197]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7656, -2.9375, -2.4375,  2.0781,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.7656, -2.9375, -2.4375,  2.0781,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4844, -2.3438, -0.7422,  2.7500,  2.7656]], dtype=torch.bfloat16))]), logits=tensor([[-3.4844, -2.3438, -0.7422,  2.7500,  2.7656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7812, -2.8750, -2.4062,  2.0781,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-2.7812, -2.8750, -2.4062,  2.0781,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8750, -2.9844, -2.3906,  2.2500,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.8750, -2.9844, -2.3906,  2.2500,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7188, -2.6875, -1.0469,  3.0000,  3.2812]], dtype=torch.bfloat16))]), logits=tensor([[-3.7188, -2.6875, -1.0469,  3.0000,  3.2812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0625, -0.4590,  1.6719,  1.9688, -0.7227]], dtype=torch.bfloat16))]), logits=tensor([[-3.0625, -0.4590,  1.6719,  1.9688, -0.7227]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1094, -2.7500, -2.0938,  2.2969,  4.5000]], dtype=torch.bfloat16))]), logits=tensor([[-3.1094, -2.7500, -2.0938,  2.2969,  4.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2656, -3.0781, -2.0469,  2.6094,  4.6562]], dtype=torch.bfloat16))]), logits=tensor([[-3.2656, -3.0781, -2.0469,  2.6094,  4.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4688, -2.7969, -2.5156,  1.8203,  5.2500]], dtype=torch.bfloat16))]), logits=tensor([[-2.4688, -2.7969, -2.5156,  1.8203,  5.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0312, -0.8633,  1.3594,  2.0156, -0.1113]], dtype=torch.bfloat16))]), logits=tensor([[-3.0312, -0.8633,  1.3594,  2.0156, -0.1113]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.6875,  2.1094,  0.2891, -1.8594, -2.4844]], dtype=torch.bfloat16))]), logits=tensor([[ 2.6875,  2.1094,  0.2891, -1.8594, -2.4844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -2.3281, -0.3535,  2.8125,  2.4531]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -2.3281, -0.3535,  2.8125,  2.4531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4375,  0.2500,  1.5625,  1.2656, -1.1484]], dtype=torch.bfloat16))]), logits=tensor([[-2.4375,  0.2500,  1.5625,  1.2656, -1.1484]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -2.5469, -0.3652,  3.2500,  2.5312]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -2.5469, -0.3652,  3.2500,  2.5312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.3594,  1.4375,  2.0469,  0.2773, -2.5156]], dtype=torch.bfloat16))]), logits=tensor([[-1.3594,  1.4375,  2.0469,  0.2773, -2.5156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1250, -2.8594, -2.1250,  2.2656,  4.7812]], dtype=torch.bfloat16))]), logits=tensor([[-3.1250, -2.8594, -2.1250,  2.2656,  4.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0938, -0.8594,  1.1250,  2.1562,  0.0145]], dtype=torch.bfloat16))]), logits=tensor([[-3.0938, -0.8594,  1.1250,  2.1562,  0.0145]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2188, -3.1875, -2.2656,  2.7188,  4.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.2188, -3.1875, -2.2656,  2.7188,  4.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3125, -3.0469, -1.9844,  2.7656,  4.5312]], dtype=torch.bfloat16))]), logits=tensor([[-3.3125, -3.0469, -1.9844,  2.7656,  4.5312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.9531,  1.2344, -0.4883, -1.8906, -1.6797]], dtype=torch.bfloat16))]), logits=tensor([[ 3.9531,  1.2344, -0.4883, -1.8906, -1.6797]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2031, -3.0938, -2.1719,  2.5781,  4.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.2031, -3.0938, -2.1719,  2.5781,  4.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7188, -2.9375, -2.5000,  2.1094,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.7188, -2.9375, -2.5000,  2.1094,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5469, -2.7969, -1.3828,  2.8438,  3.6562]], dtype=torch.bfloat16))]), logits=tensor([[-3.5469, -2.7969, -1.3828,  2.8438,  3.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9844, -3.0469, -2.3125,  2.3281,  5.0938]], dtype=torch.bfloat16))]), logits=tensor([[-2.9844, -3.0469, -2.3125,  2.3281,  5.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.2002,  2.1250,  1.7734, -0.6484, -3.0469]], dtype=torch.bfloat16))]), logits=tensor([[ 0.2002,  2.1250,  1.7734, -0.6484, -3.0469]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.9375, -2.7344, -0.6797,  3.3906,  3.0000]], dtype=torch.bfloat16))]), logits=tensor([[-3.9375, -2.7344, -0.6797,  3.3906,  3.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4219, -1.3203,  0.8867,  2.5781,  0.5352]], dtype=torch.bfloat16))]), logits=tensor([[-3.4219, -1.3203,  0.8867,  2.5781,  0.5352]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5625, -2.9375, -1.4531,  3.0000,  3.7812]], dtype=torch.bfloat16))]), logits=tensor([[-3.5625, -2.9375, -1.4531,  3.0000,  3.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6250, -2.8438, -1.4688,  2.8750,  3.8125]], dtype=torch.bfloat16))]), logits=tensor([[-3.6250, -2.8438, -1.4688,  2.8750,  3.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5781, -1.0312, -0.4277,  1.3047,  1.6562]], dtype=torch.bfloat16))]), logits=tensor([[-2.5781, -1.0312, -0.4277,  1.3047,  1.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6406, -1.6875, -0.7695,  1.5078,  2.5000]], dtype=torch.bfloat16))]), logits=tensor([[-2.6406, -1.6875, -0.7695,  1.5078,  2.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6562, -3.1094, -1.6016,  3.0625,  4.1562]], dtype=torch.bfloat16))]), logits=tensor([[-3.6562, -3.1094, -1.6016,  3.0625,  4.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6875, -3.1406, -1.6562,  3.2188,  4.2188]], dtype=torch.bfloat16))]), logits=tensor([[-3.6875, -3.1406, -1.6562,  3.2188,  4.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5781, -3.1719, -1.8984,  3.0000,  4.5000]], dtype=torch.bfloat16))]), logits=tensor([[-3.5781, -3.1719, -1.8984,  3.0000,  4.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3906, -1.2031,  1.3672,  2.6406,  0.0189]], dtype=torch.bfloat16))]), logits=tensor([[-3.3906, -1.2031,  1.3672,  2.6406,  0.0189]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.7969,  2.2188, -0.0679, -2.2812, -2.5625]], dtype=torch.bfloat16))]), logits=tensor([[ 3.7969,  2.2188, -0.0679, -2.2812, -2.5625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5625, -2.9062, -2.5000,  1.9688,  5.2500]], dtype=torch.bfloat16))]), logits=tensor([[-2.5625, -2.9062, -2.5000,  1.9688,  5.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.2031,  2.2812,  0.8320, -1.6953, -2.8594]], dtype=torch.bfloat16))]), logits=tensor([[ 2.2031,  2.2812,  0.8320, -1.6953, -2.8594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -3.1562, -1.9375,  2.8594,  4.6875]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -3.1562, -1.9375,  2.8594,  4.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.2188,  0.6406,  2.2500,  0.8945, -1.9844]], dtype=torch.bfloat16))]), logits=tensor([[-2.2188,  0.6406,  2.2500,  0.8945, -1.9844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0469, -3.0938, -2.2656,  2.4219,  5.0312]], dtype=torch.bfloat16))]), logits=tensor([[-3.0469, -3.0938, -2.2656,  2.4219,  5.0312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3750, -3.0781, -2.1562,  2.7188,  4.8438]], dtype=torch.bfloat16))]), logits=tensor([[-3.3750, -3.0781, -2.1562,  2.7188,  4.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8125, -2.7969, -1.0859,  3.1719,  3.4375]], dtype=torch.bfloat16))]), logits=tensor([[-3.8125, -2.7969, -1.0859,  3.1719,  3.4375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7344, -2.2344,  0.1289,  3.2188,  1.8750]], dtype=torch.bfloat16))]), logits=tensor([[-3.7344, -2.2344,  0.1289,  3.2188,  1.8750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8438, -2.6875, -0.5273,  3.3750,  2.8125]], dtype=torch.bfloat16))]), logits=tensor([[-3.8438, -2.6875, -0.5273,  3.3750,  2.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5625, -3.1875, -1.8203,  3.1094,  4.4062]], dtype=torch.bfloat16))]), logits=tensor([[-3.5625, -3.1875, -1.8203,  3.1094,  4.4062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7344, -2.7969, -1.1797,  3.0625,  3.5156]], dtype=torch.bfloat16))]), logits=tensor([[-3.7344, -2.7969, -1.1797,  3.0625,  3.5156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4375, -2.2031, -0.5781,  2.3750,  2.7031]], dtype=torch.bfloat16))]), logits=tensor([[-3.4375, -2.2031, -0.5781,  2.3750,  2.7031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5312,  0.0938,  1.9844,  1.4531, -1.5234]], dtype=torch.bfloat16))]), logits=tensor([[-2.5312,  0.0938,  1.9844,  1.4531, -1.5234]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1250, -3.0312, -2.2656,  2.4375,  5.0312]], dtype=torch.bfloat16))]), logits=tensor([[-3.1250, -3.0312, -2.2656,  2.4375,  5.0312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3125, -0.8320,  1.7188,  2.2969, -0.4453]], dtype=torch.bfloat16))]), logits=tensor([[-3.3125, -0.8320,  1.7188,  2.2969, -0.4453]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.2969,  0.6328,  2.1719,  0.9727, -1.9609]], dtype=torch.bfloat16))]), logits=tensor([[-2.2969,  0.6328,  2.1719,  0.9727, -1.9609]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.9219,  2.1562, -0.0708, -2.2969, -2.5156]], dtype=torch.bfloat16))]), logits=tensor([[ 3.9219,  2.1562, -0.0708, -2.2969, -2.5156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.1504,  1.1094,  0.1436, -0.5742, -0.9766]], dtype=torch.bfloat16))]), logits=tensor([[ 0.1504,  1.1094,  0.1436, -0.5742, -0.9766]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.4922,  2.3750,  1.4453, -1.3594, -3.2812]], dtype=torch.bfloat16))]), logits=tensor([[ 1.4922,  2.3750,  1.4453, -1.3594, -3.2812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3125, -2.6406, -1.5938,  2.5156,  3.8125]], dtype=torch.bfloat16))]), logits=tensor([[-3.3125, -2.6406, -1.5938,  2.5156,  3.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4844, -2.6719, -1.2031,  2.7812,  3.4062]], dtype=torch.bfloat16))]), logits=tensor([[-3.4844, -2.6719, -1.2031,  2.7812,  3.4062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -2.3750,  0.0947,  3.3750,  1.9141]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -2.3750,  0.0947,  3.3750,  1.9141]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0625, -3.1250, -2.3438,  2.6094,  5.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.0625, -3.1250, -2.3438,  2.6094,  5.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -1.4062,  1.0078,  2.8125,  0.5078]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -1.4062,  1.0078,  2.8125,  0.5078]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7969, -2.9062, -1.1641,  3.1875,  3.6250]], dtype=torch.bfloat16))]), logits=tensor([[-3.7969, -2.9062, -1.1641,  3.1875,  3.6250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7656, -2.9375, -2.4219,  2.1250,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.7656, -2.9375, -2.4219,  2.1250,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6406, -1.7266,  0.7734,  3.0469,  0.9453]], dtype=torch.bfloat16))]), logits=tensor([[-3.6406, -1.7266,  0.7734,  3.0469,  0.9453]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.0625,  2.4375,  1.1094, -1.6953, -3.1250]], dtype=torch.bfloat16))]), logits=tensor([[ 2.0625,  2.4375,  1.1094, -1.6953, -3.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -3.0000, -1.4062,  3.1562,  3.8594]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -3.0000, -1.4062,  3.1562,  3.8594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2969, -1.1172,  1.0156,  2.3750,  0.2715]], dtype=torch.bfloat16))]), logits=tensor([[-3.2969, -1.1172,  1.0156,  2.3750,  0.2715]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.0000,  0.8438,  2.1094,  0.8359, -2.2031]], dtype=torch.bfloat16))]), logits=tensor([[-2.0000,  0.8438,  2.1094,  0.8359, -2.2031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4219, -3.1562, -2.0469,  2.8438,  4.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.4219, -3.1562, -2.0469,  2.8438,  4.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.0361,  1.7734,  1.4062, -0.5156, -2.3750]], dtype=torch.bfloat16))]), logits=tensor([[-0.0361,  1.7734,  1.4062, -0.5156, -2.3750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5469, -3.1094, -1.4453,  3.2188,  4.0000]], dtype=torch.bfloat16))]), logits=tensor([[-3.5469, -3.1094, -1.4453,  3.2188,  4.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.3750,  2.1406,  0.0649, -2.0781, -2.4688]], dtype=torch.bfloat16))]), logits=tensor([[ 3.3750,  2.1406,  0.0649, -2.0781, -2.4688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.5859,  2.0312,  0.7891, -1.3594, -2.5469]], dtype=torch.bfloat16))]), logits=tensor([[ 1.5859,  2.0312,  0.7891, -1.3594, -2.5469]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2500, -3.1562, -2.2344,  2.7188,  5.0000]], dtype=torch.bfloat16))]), logits=tensor([[-3.2500, -3.1562, -2.2344,  2.7188,  5.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.2500,  2.4219,  0.3906, -2.1719, -2.8594]], dtype=torch.bfloat16))]), logits=tensor([[ 3.2500,  2.4219,  0.3906, -2.1719, -2.8594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2031, -3.1562, -2.2500,  2.6875,  5.0312]], dtype=torch.bfloat16))]), logits=tensor([[-3.2031, -3.1562, -2.2500,  2.6875,  5.0312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2344, -1.9141, -0.6328,  2.0312,  2.5781]], dtype=torch.bfloat16))]), logits=tensor([[-3.2344, -1.9141, -0.6328,  2.0312,  2.5781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1094, -0.7422,  1.2422,  2.0781, -0.1377]], dtype=torch.bfloat16))]), logits=tensor([[-3.1094, -0.7422,  1.2422,  2.0781, -0.1377]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4219, -3.1562, -2.0000,  3.0000,  4.5625]], dtype=torch.bfloat16))]), logits=tensor([[-3.4219, -3.1562, -2.0000,  3.0000,  4.5625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3281, -3.0625, -1.9375,  2.8906,  4.5312]], dtype=torch.bfloat16))]), logits=tensor([[-3.3281, -3.0625, -1.9375,  2.8906,  4.5312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4062, -2.9375, -1.8906,  2.6719,  4.3750]], dtype=torch.bfloat16))]), logits=tensor([[-3.4062, -2.9375, -1.8906,  2.6719,  4.3750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.6406,  2.4062,  1.3438, -1.5078, -3.2188]], dtype=torch.bfloat16))]), logits=tensor([[ 1.6406,  2.4062,  1.3438, -1.5078, -3.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2656, -3.1094, -2.2188,  2.6406,  4.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.2656, -3.1094, -2.2188,  2.6406,  4.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0625, -0.7344,  0.8867,  1.7812,  0.3066]], dtype=torch.bfloat16))]), logits=tensor([[-3.0625, -0.7344,  0.8867,  1.7812,  0.3066]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3438, -3.0625, -1.9141,  2.7031,  4.5000]], dtype=torch.bfloat16))]), logits=tensor([[-3.3438, -3.0625, -1.9141,  2.7031,  4.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -3.0312, -1.8125,  2.8906,  4.3125]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -3.0312, -1.8125,  2.8906,  4.3125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7031, -2.4219,  0.1006,  3.4062,  2.0156]], dtype=torch.bfloat16))]), logits=tensor([[-3.7031, -2.4219,  0.1006,  3.4062,  2.0156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3438, -3.1406, -2.1406,  2.8125,  4.8438]], dtype=torch.bfloat16))]), logits=tensor([[-3.3438, -3.1406, -2.1406,  2.8125,  4.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4375, -2.7969, -1.6250,  2.6406,  4.0000]], dtype=torch.bfloat16))]), logits=tensor([[-3.4375, -2.7969, -1.6250,  2.6406,  4.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0469, -3.0469, -2.3594,  2.4062,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-3.0469, -3.0469, -2.3594,  2.4062,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7812, -2.8438, -2.3750,  2.0938,  5.0000]], dtype=torch.bfloat16))]), logits=tensor([[-2.7812, -2.8438, -2.3750,  2.0938,  5.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0625, -2.9375, -2.1719,  2.2656,  4.8438]], dtype=torch.bfloat16))]), logits=tensor([[-3.0625, -2.9375, -2.1719,  2.2656,  4.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7500, -2.8906, -2.4375,  2.0625,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.7500, -2.8906, -2.4375,  2.0625,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4688, -3.0469, -1.7969,  3.0312,  4.2188]], dtype=torch.bfloat16))]), logits=tensor([[-3.4688, -3.0469, -1.7969,  3.0312,  4.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 4.1250,  1.8281, -0.2832, -2.1875, -2.2656]], dtype=torch.bfloat16))]), logits=tensor([[ 4.1250,  1.8281, -0.2832, -2.1875, -2.2656]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8750, -3.0156, -2.4219,  2.2656,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-2.8750, -3.0156, -2.4219,  2.2656,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.6250,  2.3594,  0.6406, -1.8828, -2.8906]], dtype=torch.bfloat16))]), logits=tensor([[ 2.6250,  2.3594,  0.6406, -1.8828, -2.8906]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7188, -2.9062, -0.6680,  3.5938,  2.9375]], dtype=torch.bfloat16))]), logits=tensor([[-3.7188, -2.9062, -0.6680,  3.5938,  2.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8281, -2.7812, -0.8594,  3.2500,  3.2031]], dtype=torch.bfloat16))]), logits=tensor([[-3.8281, -2.7812, -0.8594,  3.2500,  3.2031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6250, -0.6016,  0.9023,  1.5625, -0.0069]], dtype=torch.bfloat16))]), logits=tensor([[-2.6250, -0.6016,  0.9023,  1.5625, -0.0069]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4062,  0.5078,  2.1719,  1.1250, -1.8828]], dtype=torch.bfloat16))]), logits=tensor([[-2.4062,  0.5078,  2.1719,  1.1250, -1.8828]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4688,  0.2158,  1.7969,  1.3047, -1.4141]], dtype=torch.bfloat16))]), logits=tensor([[-2.4688,  0.2158,  1.7969,  1.3047, -1.4141]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7656, -2.9219, -2.4062,  2.0938,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.7656, -2.9219, -2.4062,  2.0938,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7031, -2.1719,  0.1348,  3.1406,  1.8203]], dtype=torch.bfloat16))]), logits=tensor([[-3.7031, -2.1719,  0.1348,  3.1406,  1.8203]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7656, -2.7031, -0.7344,  3.0938,  3.0312]], dtype=torch.bfloat16))]), logits=tensor([[-3.7656, -2.7031, -0.7344,  3.0938,  3.0312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.7500,  1.9375, -0.1963, -2.1250, -2.2188]], dtype=torch.bfloat16))]), logits=tensor([[ 3.7500,  1.9375, -0.1963, -2.1250, -2.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8594, -2.9531, -2.4531,  2.2344,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.8594, -2.9531, -2.4531,  2.2344,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0156, -2.7344, -1.9375,  2.2344,  4.3125]], dtype=torch.bfloat16))]), logits=tensor([[-3.0156, -2.7344, -1.9375,  2.2344,  4.3125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5469, -1.7266,  0.9453,  3.0156,  0.8164]], dtype=torch.bfloat16))]), logits=tensor([[-3.5469, -1.7266,  0.9453,  3.0156,  0.8164]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4531, -3.1719, -1.9219,  3.0625,  4.4375]], dtype=torch.bfloat16))]), logits=tensor([[-3.4531, -3.1719, -1.9219,  3.0625,  4.4375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2969, -1.2031,  0.6992,  2.1406,  0.7969]], dtype=torch.bfloat16))]), logits=tensor([[-3.2969, -1.2031,  0.6992,  2.1406,  0.7969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4219, -2.8750, -1.5703,  2.8438,  3.9375]], dtype=torch.bfloat16))]), logits=tensor([[-3.4219, -2.8750, -1.5703,  2.8438,  3.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9688, -0.6836,  1.4844,  2.0312, -0.4004]], dtype=torch.bfloat16))]), logits=tensor([[-2.9688, -0.6836,  1.4844,  2.0312, -0.4004]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7812, -2.7656, -0.6133,  3.4219,  2.7969]], dtype=torch.bfloat16))]), logits=tensor([[-3.7812, -2.7656, -0.6133,  3.4219,  2.7969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1094, -3.0781, -2.2812,  2.5312,  4.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.1094, -3.0781, -2.2812,  2.5312,  4.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3594, -3.0625, -2.0938,  2.6875,  4.7188]], dtype=torch.bfloat16))]), logits=tensor([[-3.3594, -3.0625, -2.0938,  2.6875,  4.7188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1562, -3.0625, -2.2188,  2.6094,  4.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.1562, -3.0625, -2.2188,  2.6094,  4.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5312, -1.5312,  0.9023,  2.7812,  0.6641]], dtype=torch.bfloat16))]), logits=tensor([[-3.5312, -1.5312,  0.9023,  2.7812,  0.6641]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4219,  0.3555,  2.1094,  1.1953, -1.7344]], dtype=torch.bfloat16))]), logits=tensor([[-2.4219,  0.3555,  2.1094,  1.1953, -1.7344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4531, -2.1875, -0.7852,  2.7031,  2.6875]], dtype=torch.bfloat16))]), logits=tensor([[-3.4531, -2.1875, -0.7852,  2.7031,  2.6875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0938, -0.5312,  1.3594,  2.0938, -0.4043]], dtype=torch.bfloat16))]), logits=tensor([[-3.0938, -0.5312,  1.3594,  2.0938, -0.4043]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6562, -3.0625, -1.4062,  3.1875,  3.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.6562, -3.0625, -1.4062,  3.1875,  3.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2031, -3.1250, -2.1875,  2.6875,  4.8438]], dtype=torch.bfloat16))]), logits=tensor([[-3.2031, -3.1250, -2.1875,  2.6875,  4.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1562, -3.1250, -2.2969,  2.6875,  4.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.1562, -3.1250, -2.2969,  2.6875,  4.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4375, -3.1875, -1.8750,  3.0312,  4.4375]], dtype=torch.bfloat16))]), logits=tensor([[-3.4375, -3.1875, -1.8750,  3.0312,  4.4375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 2.0469,  2.3906,  1.0469, -1.6406, -3.0469]], dtype=torch.bfloat16))]), logits=tensor([[ 2.0469,  2.3906,  1.0469, -1.6406, -3.0469]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9688, -2.9844, -2.3125,  2.2812,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-2.9688, -2.9844, -2.3125,  2.2812,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5000, -1.2109,  1.1797,  2.5938,  0.2891]], dtype=torch.bfloat16))]), logits=tensor([[-3.5000, -1.2109,  1.1797,  2.5938,  0.2891]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4844,  0.2207,  1.5469,  1.1484, -1.0625]], dtype=torch.bfloat16))]), logits=tensor([[-2.4844,  0.2207,  1.5469,  1.1484, -1.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.7031,  2.1406, -0.0579, -2.1875, -2.4844]], dtype=torch.bfloat16))]), logits=tensor([[ 3.7031,  2.1406, -0.0579, -2.1875, -2.4844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7812, -2.1875,  0.3164,  3.1719,  1.7734]], dtype=torch.bfloat16))]), logits=tensor([[-3.7812, -2.1875,  0.3164,  3.1719,  1.7734]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3594, -1.7500,  0.1611,  2.5000,  1.5312]], dtype=torch.bfloat16))]), logits=tensor([[-3.3594, -1.7500,  0.1611,  2.5000,  1.5312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7344, -2.4688, -0.8594,  2.9375,  2.9844]], dtype=torch.bfloat16))]), logits=tensor([[-3.7344, -2.4688, -0.8594,  2.9375,  2.9844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2500, -2.0938, -1.0781,  1.9141,  3.2500]], dtype=torch.bfloat16))]), logits=tensor([[-3.2500, -2.0938, -1.0781,  1.9141,  3.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.7656,  2.2031, -0.0352, -2.2500, -2.5312]], dtype=torch.bfloat16))]), logits=tensor([[ 3.7656,  2.2031, -0.0352, -2.2500, -2.5312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2969, -1.3438,  0.1982,  2.0625,  1.3594]], dtype=torch.bfloat16))]), logits=tensor([[-3.2969, -1.3438,  0.1982,  2.0625,  1.3594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.5781, -2.8438, -2.4688,  1.9141,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.5781, -2.8438, -2.4688,  1.9141,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1406, -3.0938, -2.2500,  2.5312,  4.9688]], dtype=torch.bfloat16))]), logits=tensor([[-3.1406, -3.0938, -2.2500,  2.5312,  4.9688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1875, -1.6641, -0.5742,  2.1719,  2.2188]], dtype=torch.bfloat16))]), logits=tensor([[-3.1875, -1.6641, -0.5742,  2.1719,  2.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7188, -1.8125,  0.4023,  3.0312,  1.3750]], dtype=torch.bfloat16))]), logits=tensor([[-3.7188, -1.8125,  0.4023,  3.0312,  1.3750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.7422,  1.0547,  1.9297,  0.5234, -2.1562]], dtype=torch.bfloat16))]), logits=tensor([[-1.7422,  1.0547,  1.9297,  0.5234, -2.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2188, -1.4453, -0.1934,  1.9062,  1.8359]], dtype=torch.bfloat16))]), logits=tensor([[-3.2188, -1.4453, -0.1934,  1.9062,  1.8359]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.8320,  1.5703,  1.7734,  0.0057, -2.5312]], dtype=torch.bfloat16))]), logits=tensor([[-0.8320,  1.5703,  1.7734,  0.0057, -2.5312]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5469, -1.9141,  0.3906,  2.8281,  1.4141]], dtype=torch.bfloat16))]), logits=tensor([[-3.5469, -1.9141,  0.3906,  2.8281,  1.4141]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0312, -3.0469, -2.3125,  2.3281,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-3.0312, -3.0469, -2.3125,  2.3281,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0469, -3.0312, -2.3750,  2.3750,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-3.0469, -3.0312, -2.3750,  2.3750,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.7969,  2.1562, -0.0913, -2.2500, -2.5000]], dtype=torch.bfloat16))]), logits=tensor([[ 3.7969,  2.1562, -0.0913, -2.2500, -2.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8438, -3.0312, -2.4375,  2.3125,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.8438, -3.0312, -2.4375,  2.3125,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.9688, -1.2500,  3.1406,  3.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.9688, -1.2500,  3.1406,  3.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.0156,  0.9531,  2.3281,  0.6953, -2.3594]], dtype=torch.bfloat16))]), logits=tensor([[-2.0156,  0.9531,  2.3281,  0.6953, -2.3594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.1523,  1.7422,  1.2812, -0.5703, -2.4688]], dtype=torch.bfloat16))]), logits=tensor([[ 0.1523,  1.7422,  1.2812, -0.5703, -2.4688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.9375, -1.0859,  3.2969,  3.4219]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.9375, -1.0859,  3.2969,  3.4219]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.1094, -3.1250, -2.3125,  2.5938,  5.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.1094, -3.1250, -2.3125,  2.5938,  5.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6875, -2.9219, -2.4688,  2.0781,  5.2500]], dtype=torch.bfloat16))]), logits=tensor([[-2.6875, -2.9219, -2.4688,  2.0781,  5.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4688, -3.0156, -1.3906,  3.2344,  3.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.4688, -3.0156, -1.3906,  3.2344,  3.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.2188,  0.9922,  1.2188,  0.3594, -1.6250]], dtype=torch.bfloat16))]), logits=tensor([[-1.2188,  0.9922,  1.2188,  0.3594, -1.6250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9688, -3.0312, -2.3906,  2.4062,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-2.9688, -3.0312, -2.3906,  2.4062,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.3906, -2.7812, -2.4688,  1.7422,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.3906, -2.7812, -2.4688,  1.7422,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8750, -2.9688, -2.1562,  2.3281,  4.8125]], dtype=torch.bfloat16))]), logits=tensor([[-2.8750, -2.9688, -2.1562,  2.3281,  4.8125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7969, -2.9688, -2.4219,  2.1562,  5.2188]], dtype=torch.bfloat16))]), logits=tensor([[-2.7969, -2.9688, -2.4219,  2.1562,  5.2188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7500, -2.8906, -2.4219,  2.0156,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.7500, -2.8906, -2.4219,  2.0156,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7344, -1.8516,  0.3750,  2.8125,  1.5938]], dtype=torch.bfloat16))]), logits=tensor([[-3.7344, -1.8516,  0.3750,  2.8125,  1.5938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.3359,  1.2578,  1.6719,  0.2637, -2.0781]], dtype=torch.bfloat16))]), logits=tensor([[-1.3359,  1.2578,  1.6719,  0.2637, -2.0781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8594, -2.6250, -0.6133,  3.2188,  2.8594]], dtype=torch.bfloat16))]), logits=tensor([[-3.8594, -2.6250, -0.6133,  3.2188,  2.8594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7188, -3.0000, -1.2422,  3.0938,  3.7969]], dtype=torch.bfloat16))]), logits=tensor([[-3.7188, -3.0000, -1.2422,  3.0938,  3.7969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.2969,  0.4922,  2.3125,  0.9062, -1.9297]], dtype=torch.bfloat16))]), logits=tensor([[-2.2969,  0.4922,  2.3125,  0.9062, -1.9297]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.4688, -0.0508,  3.4219,  2.1250]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.4688, -0.0508,  3.4219,  2.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.7500, -2.4844, -0.1533,  3.4531,  2.2031]], dtype=torch.bfloat16))]), logits=tensor([[-3.7500, -2.4844, -0.1533,  3.4531,  2.2031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.8281, -2.8906, -0.7656,  3.4219,  3.2031]], dtype=torch.bfloat16))]), logits=tensor([[-3.8281, -2.8906, -0.7656,  3.4219,  3.2031]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5156, -1.7344, -0.1045,  2.5625,  1.7969]], dtype=torch.bfloat16))]), logits=tensor([[-3.5156, -1.7344, -0.1045,  2.5625,  1.7969]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.5781,  1.7422,  1.8438, -0.1289, -2.7188]], dtype=torch.bfloat16))]), logits=tensor([[-0.5781,  1.7422,  1.8438, -0.1289, -2.7188]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9844, -0.4414,  1.4062,  1.8984, -0.5391]], dtype=torch.bfloat16))]), logits=tensor([[-2.9844, -0.4414,  1.4062,  1.8984, -0.5391]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.0859,  2.2031,  1.3203, -1.1484, -3.0000]], dtype=torch.bfloat16))]), logits=tensor([[ 1.0859,  2.2031,  1.3203, -1.1484, -3.0000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.0938,  2.5312,  0.4883, -2.2031, -2.9531]], dtype=torch.bfloat16))]), logits=tensor([[ 3.0938,  2.5312,  0.4883, -2.2031, -2.9531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0625, -0.6016,  1.3984,  2.0000, -0.3770]], dtype=torch.bfloat16))]), logits=tensor([[-3.0625, -0.6016,  1.3984,  2.0000, -0.3770]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7969, -2.9531, -2.3750,  2.1562,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.7969, -2.9531, -2.3750,  2.1562,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.4375, -0.1147,  0.8438,  1.1797, -0.2295]], dtype=torch.bfloat16))]), logits=tensor([[-2.4375, -0.1147,  0.8438,  1.1797, -0.2295]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5938, -1.9844,  0.2969,  3.0312,  1.5000]], dtype=torch.bfloat16))]), logits=tensor([[-3.5938, -1.9844,  0.2969,  3.0312,  1.5000]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.2812,  2.5469,  0.4648, -2.2500, -2.9844]], dtype=torch.bfloat16))]), logits=tensor([[ 3.2812,  2.5469,  0.4648, -2.2500, -2.9844]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2812, -1.0781,  1.0234,  2.4375,  0.1982]], dtype=torch.bfloat16))]), logits=tensor([[-3.2812, -1.0781,  1.0234,  2.4375,  0.1982]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.1562,  1.4141,  1.8281,  0.2715, -2.4219]], dtype=torch.bfloat16))]), logits=tensor([[-1.1562,  1.4141,  1.8281,  0.2715, -2.4219]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.2031,  1.4062,  0.6797, -0.5938, -1.5781]], dtype=torch.bfloat16))]), logits=tensor([[ 0.2031,  1.4062,  0.6797, -0.5938, -1.5781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5625, -1.6172,  1.0625,  2.9844,  0.5586]], dtype=torch.bfloat16))]), logits=tensor([[-3.5625, -1.6172,  1.0625,  2.9844,  0.5586]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 0.7578,  1.7969,  0.8086, -0.9297, -2.2812]], dtype=torch.bfloat16))]), logits=tensor([[ 0.7578,  1.7969,  0.8086, -0.9297, -2.2812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5156, -3.1875, -1.8984,  2.8438,  4.6562]], dtype=torch.bfloat16))]), logits=tensor([[-3.5156, -3.1875, -1.8984,  2.8438,  4.6562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7812, -0.0289,  2.1562,  1.5156, -1.3672]], dtype=torch.bfloat16))]), logits=tensor([[-2.7812, -0.0289,  2.1562,  1.5156, -1.3672]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.0781,  2.5625,  0.5898, -2.1719, -3.0625]], dtype=torch.bfloat16))]), logits=tensor([[ 3.0781,  2.5625,  0.5898, -2.1719, -3.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.5312,  0.8828, -0.5430, -1.5781, -1.2891]], dtype=torch.bfloat16))]), logits=tensor([[ 3.5312,  0.8828, -0.5430, -1.5781, -1.2891]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3750, -1.8438, -0.1865,  2.2656,  2.0938]], dtype=torch.bfloat16))]), logits=tensor([[-3.3750, -1.8438, -0.1865,  2.2656,  2.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.6719,  2.2812,  0.0537, -2.2656, -2.6406]], dtype=torch.bfloat16))]), logits=tensor([[ 3.6719,  2.2812,  0.0537, -2.2656, -2.6406]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5469, -3.0625, -1.6250,  3.0625,  4.0938]], dtype=torch.bfloat16))]), logits=tensor([[-3.5469, -3.0625, -1.6250,  3.0625,  4.0938]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3438, -3.2031, -2.1719,  2.8438,  4.8750]], dtype=torch.bfloat16))]), logits=tensor([[-3.3438, -3.2031, -2.1719,  2.8438,  4.8750]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 1.8047,  2.2656,  1.0234, -1.4922, -2.9375]], dtype=torch.bfloat16))]), logits=tensor([[ 1.8047,  2.2656,  1.0234, -1.4922, -2.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8125, -0.1387,  1.9297,  1.7109, -1.2500]], dtype=torch.bfloat16))]), logits=tensor([[-2.8125, -0.1387,  1.9297,  1.7109, -1.2500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.8516,  0.8711,  0.5859,  0.0400, -0.9414]], dtype=torch.bfloat16))]), logits=tensor([[-0.8516,  0.8711,  0.5859,  0.0400, -0.9414]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.5469,  1.0078, -0.5391, -1.6016, -1.3047]], dtype=torch.bfloat16))]), logits=tensor([[ 3.5469,  1.0078, -0.5391, -1.6016, -1.3047]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5938, -1.6172,  0.7578,  2.8281,  0.8789]], dtype=torch.bfloat16))]), logits=tensor([[-3.5938, -1.6172,  0.7578,  2.8281,  0.8789]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.8438,  1.9688, -0.1729, -2.1562, -2.3125]], dtype=torch.bfloat16))]), logits=tensor([[ 3.8438,  1.9688, -0.1729, -2.1562, -2.3125]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6094, -2.7969, -1.4375,  2.8594,  3.7344]], dtype=torch.bfloat16))]), logits=tensor([[-3.6094, -2.7969, -1.4375,  2.8594,  3.7344]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3750, -1.1328,  0.9258,  2.2812,  0.5469]], dtype=torch.bfloat16))]), logits=tensor([[-3.3750, -1.1328,  0.9258,  2.2812,  0.5469]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6562, -2.1562,  0.3047,  3.2500,  1.5781]], dtype=torch.bfloat16))]), logits=tensor([[-3.6562, -2.1562,  0.3047,  3.2500,  1.5781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.1250,  1.5312,  2.0625,  0.2734, -2.7812]], dtype=torch.bfloat16))]), logits=tensor([[-1.1250,  1.5312,  2.0625,  0.2734, -2.7812]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.3594, -1.3750,  0.9297,  2.6562,  0.5156]], dtype=torch.bfloat16))]), logits=tensor([[-3.3594, -1.3750,  0.9297,  2.6562,  0.5156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8906, -0.4668,  1.4609,  1.8672, -0.6367]], dtype=torch.bfloat16))]), logits=tensor([[-2.8906, -0.4668,  1.4609,  1.8672, -0.6367]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5938, -1.9922,  0.1807,  3.0156,  1.6172]], dtype=torch.bfloat16))]), logits=tensor([[-3.5938, -1.9922,  0.1807,  3.0156,  1.6172]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.4688, -1.8203, -0.2354,  2.5469,  1.9531]], dtype=torch.bfloat16))]), logits=tensor([[-3.4688, -1.8203, -0.2354,  2.5469,  1.9531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.7656, -2.9844, -2.4688,  2.1875,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.7656, -2.9844, -2.4688,  2.1875,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.9062, -2.9531, -2.3594,  2.2031,  5.1562]], dtype=torch.bfloat16))]), logits=tensor([[-2.9062, -2.9531, -2.3594,  2.2031,  5.1562]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.8242,  0.5039,  0.2871,  0.0194, -0.4980]], dtype=torch.bfloat16))]), logits=tensor([[-0.8242,  0.5039,  0.2871,  0.0194, -0.4980]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8125, -2.9531, -2.3438,  2.1719,  5.1250]], dtype=torch.bfloat16))]), logits=tensor([[-2.8125, -2.9531, -2.3438,  2.1719,  5.1250]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6094, -3.0469, -1.4688,  3.1562,  3.8594]], dtype=torch.bfloat16))]), logits=tensor([[-3.6094, -3.0469, -1.4688,  3.1562,  3.8594]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-0.7305,  1.8438,  2.1250, -0.0284, -3.0156]], dtype=torch.bfloat16))]), logits=tensor([[-0.7305,  1.8438,  2.1250, -0.0284, -3.0156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2344, -1.9297, -0.7070,  2.1406,  2.5781]], dtype=torch.bfloat16))]), logits=tensor([[-3.2344, -1.9297, -0.7070,  2.1406,  2.5781]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-1.4922,  1.4141,  2.0781,  0.3223, -2.5156]], dtype=torch.bfloat16))]), logits=tensor([[-1.4922,  1.4141,  2.0781,  0.3223, -2.5156]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2188, -3.0312, -2.1250,  2.4844,  4.8438]], dtype=torch.bfloat16))]), logits=tensor([[-3.2188, -3.0312, -2.1250,  2.4844,  4.8438]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.6406, -0.0157,  1.9609,  1.5234, -1.3281]], dtype=torch.bfloat16))]), logits=tensor([[-2.6406, -0.0157,  1.9609,  1.5234, -1.3281]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5938, -2.6719, -1.1641,  2.6875,  3.4688]], dtype=torch.bfloat16))]), logits=tensor([[-3.5938, -2.6719, -1.1641,  2.6875,  3.4688]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5000, -3.1250, -1.9531,  2.9375,  4.5625]], dtype=torch.bfloat16))]), logits=tensor([[-3.5000, -3.1250, -1.9531,  2.9375,  4.5625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.6562, -3.0625, -1.3281,  3.2812,  3.7500]], dtype=torch.bfloat16))]), logits=tensor([[-3.6562, -3.0625, -1.3281,  3.2812,  3.7500]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 4.0938,  1.5625, -0.4199, -2.0469, -1.9531]], dtype=torch.bfloat16))]), logits=tensor([[ 4.0938,  1.5625, -0.4199, -2.0469, -1.9531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.9375,  1.5547, -0.3320, -2.0156, -1.9531]], dtype=torch.bfloat16))]), logits=tensor([[ 3.9375,  1.5547, -0.3320, -2.0156, -1.9531]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[ 3.0938,  2.4688,  0.4941, -2.1406, -2.9375]], dtype=torch.bfloat16))]), logits=tensor([[ 3.0938,  2.4688,  0.4941, -2.1406, -2.9375]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.0469, -0.3594,  1.7734,  1.9219, -0.9062]], dtype=torch.bfloat16))]), logits=tensor([[-3.0469, -0.3594,  1.7734,  1.9219, -0.9062]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.5000, -2.8906, -1.6875,  2.7812,  4.0625]], dtype=torch.bfloat16))]), logits=tensor([[-3.5000, -2.8906, -1.6875,  2.7812,  4.0625]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-3.2812, -0.9336,  1.4375,  2.4375, -0.2266]], dtype=torch.bfloat16))]), logits=tensor([[-3.2812, -0.9336,  1.4375,  2.4375, -0.2266]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " SequenceClassifierOutput(loss=OrderedDict([('logits', tensor([[-2.8594, -3.0156, -2.4062,  2.2344,  5.1875]], dtype=torch.bfloat16))]), logits=tensor([[-2.8594, -3.0156, -2.4062,  2.2344,  5.1875]], dtype=torch.bfloat16), hidden_states=None, attentions=None),\n",
       " ...]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def predict_step(batch: Any, batch_idx: int, dataloader_idx: int = 0) -> Any:\n",
    "    with torch.no_grad():\n",
    "        input_ids, input_mask = batch\n",
    "        return model.model(\n",
    "            input_ids, token_type_ids=None, attention_mask=input_mask\n",
    "        )\n",
    "model.predict_step = predict_step\n",
    "trainer.callbacks = [RichProgressBar()]\n",
    "test_logits = trainer.predict(model, datamodule=test_dm)\n",
    "test_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       4\n",
       "1       1\n",
       "2       3\n",
       "3       4\n",
       "4       4\n",
       "       ..\n",
       "4094    0\n",
       "4095    4\n",
       "4096    4\n",
       "4097    3\n",
       "4098    0\n",
       "Length: 4099, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = pd.Series([torch.argmax(out.logits).item() for out in test_logits])\n",
    "preds_df.to_csv('piatek_owienko_schafer.csv', header=None, index=None)\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssne_p3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
