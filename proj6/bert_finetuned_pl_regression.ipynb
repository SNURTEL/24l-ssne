{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import nltk\n",
    "import itertools\n",
    "from nltk.corpus import stopwords\n",
    "from typing import Literal, Callable\n",
    "import re\n",
    "from torch.utils.data import Dataset\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import (\n",
    "    TensorDataset,\n",
    "    DataLoader,\n",
    "    RandomSampler,\n",
    "    SequentialSampler,\n",
    "    random_split,\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall,\n",
    "    MulticlassF1Score,\n",
    "    MulticlassConfusionMatrix,\n",
    ")\n",
    "\n",
    "from torchmetrics.regression import MeanSquaredError, MeanAbsoluteError\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, RichProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_t = str | bytes | os.PathLike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 123\n",
    "pl.seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = Path(\"./data/train_data.csv\")\n",
    "NLTK_DIR = Path(\"./nltk\")\n",
    "MODEL_DIR = Path(\"./models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to nltk...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\", download_dir=NLTK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(TRAIN_PATH)\n",
    "sns.histplot(df_raw[\"rating\"])\n",
    "cls_counts = np.histogram(df_raw[\"rating\"], bins=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities.types import TRAIN_DATALOADERS\n",
    "\n",
    "\n",
    "class TextClassificationDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: Path_t,\n",
    "        tokenizer: BertTokenizer,\n",
    "        batch_size: int,\n",
    "        val_fraction: float = 0.0,\n",
    "        truncation_strategy: Literal[\"truncate\"] = \"truncate\",\n",
    "        max_seq_len: int = 512,\n",
    "        clean_fn: Callable[[str], str] = lambda x: x,\n",
    "        n_first: int | None = None  # just for testing purposes\n",
    "    ):\n",
    "        super(TextClassificationDataModule, self).__init__()\n",
    "        assert 0 <= val_fraction <= 1\n",
    "\n",
    "        self._data_path = data_path\n",
    "        self._clean_fn = clean_fn\n",
    "        self._tokenizer = tokenizer\n",
    "        self._encode_fn = partial(\n",
    "            tokenizer.encode_plus,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_seq_len,\n",
    "            truncation=True if truncation_strategy == \"truncate\" else False,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        self.val_fraction = val_fraction\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self._n_first = n_first\n",
    "\n",
    "        self._encoded: list[dict[str, Tensor]]\n",
    "        self._train: Dataset\n",
    "        self._val: Dataset\n",
    "        self._test: Dataset\n",
    "\n",
    "    def setup(self, stage: Literal[\"fit\", \"test\"]) -> None:\n",
    "        if stage == \"fit\":\n",
    "            df_raw = pd.read_csv(self._data_path)\n",
    "            ratings = df_raw[\"rating\"].values[:self._n_first]\n",
    "            dataset = TensorDataset(\n",
    "                *(\n",
    "                    torch.cat([item[k] for item in self._encoded], dim=0)\n",
    "                    for k in (\"input_ids\", \"attention_mask\")\n",
    "                ),\n",
    "                torch.tensor(ratings),\n",
    "            )\n",
    "            val_size = int(len(dataset) * self.val_fraction)\n",
    "            train_size = len(dataset) - val_size\n",
    "\n",
    "            self._train, self._val = torch.utils.data.random_split(\n",
    "                dataset, [train_size, val_size]\n",
    "            )\n",
    "\n",
    "        if stage == \"test\":\n",
    "            self._test = TensorDataset(\n",
    "                *(\n",
    "                    torch.cat([item[k] for item in self._encoded], dim=0)\n",
    "                    for k in (\"input_ids\", \"attention_mask\")\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        df_raw = pd.read_csv(self._data_path)\n",
    "        reviews = df_raw[\"review\"].apply(self._clean_fn).values[:self._n_first]\n",
    "        self._encoded = [self._encode_fn(review) for review in reviews]\n",
    "\n",
    "    def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            # self._train, batch_size=self.batch_size, pin_memory=True, sampler=WeightedRandomSampler(weights=1/cls_counts, num_samples=len(self._train), replacement=True)\n",
    "            self._train, batch_size=self.batch_size, shuffle=True, pin_memory=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self._val, batch_size=self.batch_size, shuffle=False, pin_memory=True\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self._test, batch_size=self.batch_size, shuffle=False, pin_memory=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class BertRegressorClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: BertForSequenceClassification,\n",
    "        num_classes: int,\n",
    "        lr: float,\n",
    "        weight_decay: float = 0.0,\n",
    "        warmup_steps: int = 0,\n",
    "        freeze_encoder: bool = False,\n",
    "    ):\n",
    "        super(BertRegressorClassifier, self).__init__()\n",
    "        assert model.num_labels == 1\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.model = model\n",
    "        self._lr = lr\n",
    "        self._weight_decay = weight_decay\n",
    "        self._warmup_steps = warmup_steps\n",
    "        self._freeze_encoder = freeze_encoder\n",
    "\n",
    "        if freeze_encoder:\n",
    "            for param in self.model.base_model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "        \n",
    "        self.reg_metrics = {\n",
    "            \"mse\": MeanSquaredError().to(device),\n",
    "            \"mae\": MeanAbsoluteError().to(device),\n",
    "        }\n",
    "\n",
    "        self.flat_metrics = {\n",
    "            \"accuracy\": MulticlassAccuracy(num_classes=num_classes, average=\"micro\").to(device),\n",
    "            \"precision\": MulticlassPrecision(num_classes=num_classes, average=\"micro\").to(device),\n",
    "            \"recall\": MulticlassRecall(num_classes=num_classes, average=\"micro\").to(device),\n",
    "            \"f1\": MulticlassF1Score(num_classes=num_classes, average=\"micro\").to(device),\n",
    "        }\n",
    "        self.class_metrics = {\n",
    "            \"accuracy\": MulticlassAccuracy(num_classes=num_classes, average=\"none\").to(device),\n",
    "            \"precision\": MulticlassPrecision(num_classes=num_classes, average=\"none\").to(device),\n",
    "            \"recall\": MulticlassRecall(num_classes=num_classes, average=\"none\").to(device),\n",
    "            \"f1\": MulticlassF1Score(num_classes=num_classes, average=\"none\").to(device),\n",
    "        }\n",
    "        self.confusion_matrix = MulticlassConfusionMatrix(\n",
    "            num_classes=num_classes, normalize=\"pred\"\n",
    "        ).to(device)\n",
    "\n",
    "    def configure_optimizers(self) -> Any:\n",
    "        self.trainer.fit_loop.setup_data()\n",
    "        total_devices = getattr(self.hparams, \"n_gpus\", 1) * getattr(self.hparams, \"n_nodes\", 1)\n",
    "        train_batches = len(self.trainer.train_dataloader) // total_devices\n",
    "        train_steps = (\n",
    "            self.trainer.max_epochs * train_batches\n",
    "        ) // self.trainer.accumulate_grad_batches\n",
    "        # will not work with AdamW (plus it is deprecated anyway)\n",
    "        # https://discuss.huggingface.co/t/runtimeerror-element-0-of-tensors-does-not-require-grad-and-does-not-have-a-grad-fn/47965/2\n",
    "        optimizer = Adam(self.model.parameters(), lr=self._lr, eps=1e-8, weight_decay=self._weight_decay)\n",
    "        lr_scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer=optimizer,\n",
    "            num_warmup_steps=self._warmup_steps,\n",
    "            num_training_steps=train_steps,\n",
    "        )\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: tuple[Tensor, Tensor, Tensor], batch_idx: int\n",
    "    ) -> dict[str, Tensor]:\n",
    "        input_ids, input_mask, labels = batch\n",
    "        output = self.model(\n",
    "            input_ids, token_type_ids=None, attention_mask=input_mask, labels=labels.to(torch.float)\n",
    "        )\n",
    "        loss = output.loss\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: tuple[Tensor, Tensor, Tensor], batch_idx: int\n",
    "    ) -> dict[str, Tensor]:\n",
    "        with torch.no_grad():\n",
    "            input_ids, input_mask, labels = batch\n",
    "            output = self.model(\n",
    "                input_ids, token_type_ids=None, attention_mask=input_mask, labels=labels.to(torch.float)\n",
    "            )\n",
    "            loss = output.loss\n",
    "\n",
    "            preds = output.logits.squeeze()\n",
    "            self.log(\"val_loss\", loss, prog_bar=True)\n",
    "            self.log_dict(\n",
    "                {name: metric(preds, labels) for name, metric in self.reg_metrics.items()},\n",
    "                prog_bar=True,\n",
    "            )\n",
    "            preds = preds.round().clamp(0, self.num_classes-1)\n",
    "            self.log_dict(\n",
    "                {name: metric(preds, labels) for name, metric in self.flat_metrics.items()},\n",
    "                prog_bar=True,\n",
    "            )\n",
    "            self.log_dict(\n",
    "                {\n",
    "                    f\"{name}_{c}\": v\n",
    "                    for name, metric_values in {\n",
    "                        _name: metric(preds, labels)\n",
    "                        for _name, metric in self.class_metrics.items()\n",
    "                    }.items()\n",
    "                    for c, v in enumerate(metric_values)\n",
    "                },\n",
    "                prog_bar=True,\n",
    "            )\n",
    "            self.confusion_matrix(preds, labels)\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        with torch.no_grad():\n",
    "            confusion_matrix = self.confusion_matrix.compute()\n",
    "\n",
    "            df_cm = pd.DataFrame(\n",
    "                confusion_matrix.cpu().numpy(), index=range(5), columns=range(5)\n",
    "            )\n",
    "            fig, ax = plt.subplots(figsize=(10, 7))\n",
    "            sns.heatmap(\n",
    "                df_cm,\n",
    "                ax=ax,\n",
    "                annot=True,\n",
    "                cmap=\"Greens\",\n",
    "                vmin=0,\n",
    "                vmax=1,\n",
    "                annot_kws={\"size\": 6},\n",
    "                fmt=\".3f\",\n",
    "                \n",
    "            )\n",
    "            ax.set_xlabel(\"True class\")\n",
    "            ax.set_ylabel(\"Predicted class\")\n",
    "            self.logger.experiment.add_figure(\"Confusion matrix\", fig, self.current_epoch)\n",
    "\n",
    "    def predict_step(self, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> Any:\n",
    "        with torch.no_grad():\n",
    "            input_ids, input_mask, labels = batch\n",
    "            return self.model(\n",
    "                input_ids, token_type_ids=None, attention_mask=input_mask, labels=labels\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"prajjwal1/bert-small\", do_lower_case=True, cache_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to nltk...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords', download_dir=NLTK_DIR)\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'') #Removing punctuations\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = TextClassificationDataModule(\n",
    "    data_path=Path(TRAIN_PATH),\n",
    "    tokenizer=tokenizer,\n",
    "    val_fraction=0.2,\n",
    "    batch_size=128,  # 12 for large model on 24GB\n",
    "    clean_fn=clean_text,\n",
    "    max_seq_len=512\n",
    ")\n",
    "dm.prepare_data()\n",
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-small and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertRegressorClassifier(\n",
       "  (model): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 512)\n",
       "        (token_type_embeddings): Embedding(2, 512)\n",
       "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-3): 4 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (confusion_matrix): MulticlassConfusionMatrix()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertRegressorClassifier(\n",
    "    model=BertForSequenceClassification.from_pretrained(\n",
    "        \"prajjwal1/bert-small\",\n",
    "        # \"bert-base-uncased\",\n",
    "        # \"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "        # \"bert-large-uncased\",\n",
    "        num_labels=1,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "        cache_dir=MODEL_DIR\n",
    "    ),\n",
    "    num_classes=5,\n",
    "    lr=5e-5,\n",
    "    weight_decay=1e-3,\n",
    "    warmup_steps=0,\n",
    "    freeze_encoder=False,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model            │ BertForSequenceClassification │ 28.8 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ confusion_matrix │ MulticlassConfusionMatrix     │      0 │\n",
       "└───┴──────────────────┴───────────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model            │ BertForSequenceClassification │ 28.8 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ confusion_matrix │ MulticlassConfusionMatrix     │      0 │\n",
       "└───┴──────────────────┴───────────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 28.8 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 28.8 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 115                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 28.8 M                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 28.8 M                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 115                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fb280c8afb4f0eb73f1017a7a4795c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connecto\n",
       "r.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connecto\n",
       "r.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "15 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "15 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: \n",
       "5 NaN values found in confusion matrix have been replaced with zeros.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning:\n",
       "Detected KeyboardInterrupt, attempting graceful shutdown...\n",
       "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning:\n",
       "Detected KeyboardInterrupt, attempting graceful shutdown...\n",
       "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    gradient_clip_val=1,\n",
    "    callbacks=[RichProgressBar()],\n",
    "    precision=\"bf16-mixed\",\n",
    "    val_check_interval=0.25\n",
    ")\n",
    "trainer.fit(model, datamodule=dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssne_p3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
