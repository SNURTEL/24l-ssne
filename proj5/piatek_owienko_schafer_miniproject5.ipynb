{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWqIz6BsrIZU"
   },
   "source": [
    "# SSNE Miniproject 5\n",
    "### 318703 Tomasz Owienko\n",
    "### 318718 Anna Schäfer\n",
    "### Grupa piątek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T13:42:21.556277450Z",
     "start_time": "2024-05-25T13:42:18.754900759Z"
    },
    "id": "-RiHHnHEi7Vc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, RichProgressBar\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T13:42:21.568264278Z",
     "start_time": "2024-05-25T13:42:21.558417833Z"
    },
    "id": "dF7Jzby3i-I6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 123\n",
    "pl.seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T13:42:21.568617931Z",
     "start_time": "2024-05-25T13:42:21.565777988Z"
    },
    "id": "-BCkcrW5i9kE"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T13:42:21.570914806Z",
     "start_time": "2024-05-25T13:42:21.568125041Z"
    },
    "id": "sg6Nh9CXXT4U"
   },
   "outputs": [],
   "source": [
    "VALIDATION_PERCENTAGE = 0.10\n",
    "batch_size = 32\n",
    "TRAIN_PATH = \"data/train.pkl\"\n",
    "TEST_PATH = \"data/test_no_target.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T13:42:21.630728455Z",
     "start_time": "2024-05-25T13:42:21.611116732Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VariableLenDataset(Dataset):\n",
    "    def __init__(self, in_data, target):\n",
    "        self.data = [(x, y) for x, y in zip(in_data, target)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_data, target = self.data[idx]\n",
    "        return in_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T13:42:21.641036497Z",
     "start_time": "2024-05-25T13:42:21.611635949Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "\n",
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    xx = [x.clone().detach().unsqueeze(-1) for x in xx]\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "    return (\n",
    "        xx_pad,\n",
    "        torch.tensor(yy, dtype=torch.long),\n",
    "        torch.tensor(x_lens, dtype=torch.int).cpu(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T13:42:21.662501363Z",
     "start_time": "2024-05-25T13:42:21.612002153Z"
    },
    "id": "6lhaFNeLhusm"
   },
   "outputs": [],
   "source": [
    "with open(TRAIN_PATH, \"rb\") as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "train_data = [[torch.from_numpy(t[0].astype(int)).float(), int(t[1])] for t in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T13:42:21.662962224Z",
     "start_time": "2024-05-25T13:42:21.652078819Z"
    },
    "id": "7eNmQAg1i7Yr"
   },
   "outputs": [],
   "source": [
    "dataset_length = len(train_data)\n",
    "val_size = int(dataset_length * VALIDATION_PERCENTAGE)\n",
    "train_size = dataset_length - val_size\n",
    "train_subset, val_subset = random_split(train_data, [train_size, val_size])\n",
    "\n",
    "train_dataset = VariableLenDataset(\n",
    "    [x[0] for x in train_subset], [x[1] for x in train_subset]\n",
    ")\n",
    "val_dataset = VariableLenDataset([x[0] for x in val_subset], [x[1] for x in val_subset])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=pad_collate,\n",
    "    pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=pad_collate,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228])\n"
     ]
    }
   ],
   "source": [
    "print(train_subset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2515, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train_loader = DataLoader(\n",
    "    train_subset, batch_size=32, shuffle=True, collate_fn=pad_collate\n",
    ")\n",
    "next(iter(_train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T14:00:39.081093662Z",
     "start_time": "2024-05-25T14:00:39.040736076Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ZUP8rCvCo716",
    "outputId": "537bd539-e2a7-4154-d94f-d2f2d87951b8"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.lstm.flatten_parameters()\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x, x_lens):\n",
    "        x_packed = pack_padded_sequence(\n",
    "            x, x_lens, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        out, (hn, cn) = self.lstm(x_packed)\n",
    "        # out = self.fc(out[:, -1, :])\n",
    "        out = self.fc(self.dropout(hn[-1]))\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, x_lens = batch\n",
    "        outputs = self(x, x_lens.cpu())\n",
    "        loss = self.criterion(outputs, y)\n",
    "        acc = (outputs.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, x_lens = batch\n",
    "        outputs = self(x, x_lens.cpu())\n",
    "        loss = self.criterion(outputs, y)\n",
    "        acc = (outputs.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-25T14:00:44.913436674Z"
    },
    "id": "W2TSYGhAa6i-",
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:615: UserWarning: Checkpoint directory model_checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ lstm      │ LSTM             │  331 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ fc        │ Linear           │    645 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ criterion │ CrossEntropyLoss │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ dropout   │ Dropout          │      0 │\n",
       "└───┴───────────┴──────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ lstm      │ LSTM             │  331 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ fc        │ Linear           │    645 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ criterion │ CrossEntropyLoss │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ dropout   │ Dropout          │      0 │\n",
       "└───┴───────────┴──────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 331 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 331 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 331 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 331 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354b059d214c43e3bf975e476b7ff5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connecto\n",
       "r.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connecto\n",
       "r.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connecto\n",
       "r.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/miniconda3/envs/ssne_p3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connecto\n",
       "r.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_size = train_data[0][0].shape[1] if len(train_data[0][0].shape) > 1 else 1\n",
    "hidden_size = 512\n",
    "output_size = len(set(x[1] for x in train_data))\n",
    "\n",
    "model = LSTMClassifier(input_size=1, hidden_size=128, output_size=5, num_layers=3)\n",
    "\n",
    "best_val_acc_callback = ModelCheckpoint(\n",
    "    monitor=\"val_acc\",\n",
    "    filename=\"checkpoint_best_acc-{epoch:03d}-{val_acc:.5f}\",\n",
    "    save_top_k=3,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "last_epoch_callback = ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "    monitor=\"epoch\",\n",
    "    mode=\"max\",\n",
    "    filename=\"checkpoint_last-{epoch:03d}-{train_loss:.5f}\",\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    callbacks=[best_val_acc_callback, last_epoch_callback, RichProgressBar()],\n",
    ")\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-25T13:42:23.511100156Z"
    },
    "id": "dd1xinfuEMZv"
   },
   "outputs": [],
   "source": [
    "with open(TEST_PATH, \"rb\") as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "test_data = [torch.from_numpy(t.astype(int)).float().unsqueeze(-1) for t in test_data]\n",
    "test_dataset = VariableLenDataset(test_data, [0 for _ in test_data])\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=50, shuffle=False, collate_fn=pad_collate\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "g6VO-fNxrWh5"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
